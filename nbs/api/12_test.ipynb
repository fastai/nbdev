{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2084506e-4393-41eb-8057-9406e78e4079",
   "metadata": {},
   "source": [
    "# test\n",
    "> Run unit tests on notebooks in parallel\n",
    "- order: 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e10c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import time,os,sys,traceback,contextlib, inspect\n",
    "from fastcore.basics import *\n",
    "from fastcore.imports import *\n",
    "from fastcore.foundation import *\n",
    "from fastcore.parallel import *\n",
    "from fastcore.script import *\n",
    "from fastcore.meta import delegates\n",
    "\n",
    "from nbdev.config import *\n",
    "from nbdev.doclinks import *\n",
    "from nbdev.process import NBProcessor, nb_lang\n",
    "from nbdev.frontmatter import FrontmatterProc\n",
    "\n",
    "from execnb.nbio import *\n",
    "from execnb.shell import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fa1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def test_nb(fn,  # file name of notebook to test\n",
    "            skip_flags=None,  # list of flags marking cells to skip\n",
    "            force_flags=None,  # list of flags marking cells to always run\n",
    "            do_print=False,  # print completion?\n",
    "            showerr=True,  # print errors to stderr?\n",
    "            basepath=None):  # path to add to sys.path\n",
    "    \"Execute tests in notebook in `fn` except those with `skip_flags`\"\n",
    "    if basepath: sys.path.insert(0, str(basepath))\n",
    "    if not IN_NOTEBOOK: os.environ[\"IN_TEST\"] = '1'\n",
    "    flags=set(L(skip_flags)) - set(L(force_flags))\n",
    "    nb = NBProcessor(fn, procs=FrontmatterProc, process=True).nb\n",
    "    fm = getattr(nb, 'frontmatter_', {})\n",
    "    if str2bool(fm.get('skip_exec', False)) or nb_lang(nb) != 'python': return True, 0\n",
    "\n",
    "    def _no_eval(cell):\n",
    "        if cell.cell_type != 'code': return True\n",
    "        if 'nbdev_export'+'(' in cell.source: return True\n",
    "        direc = getattr(cell, 'directives_', {}) or {}\n",
    "        if direc.get('eval:', [''])[0].lower() == 'false': return True\n",
    "        return flags & direc.keys()\n",
    "    \n",
    "    start = time.time()\n",
    "    k = CaptureShell(fn)\n",
    "    if do_print: print(f'Starting {fn}')\n",
    "    try:\n",
    "        with working_directory(fn.parent):\n",
    "            k.run_all(nb, exc_stop=True, preproc=_no_eval)\n",
    "            res = True\n",
    "    except: \n",
    "        if showerr: sys.stderr.write(k.prettytb(fname=fn)+'\\n')\n",
    "        res=False\n",
    "    if do_print: print(f'- Completed {fn}')\n",
    "    return res,time.time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc26b80-6e4e-4a16-bcde-dd4d156289e5",
   "metadata": {},
   "source": [
    "`test_nb` can test a notebook, and skip over certain flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf84ef-bce4-4531-80df-7a4e514a7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_nb = Path('../../tests/directives.ipynb')\n",
    "success,duration = test_nb(_nb, skip_flags=['notest'])\n",
    "assert success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46117f38",
   "metadata": {},
   "source": [
    "In that notebook the cell flagged *notest* raises an exception, which will be returned as a `bool`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_nb = Path('../../tests/directives.ipynb')\n",
    "success,duration = test_nb(_nb, showerr=False)\n",
    "assert not success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf1f1b-935d-4b69-ba96-827c5d7213f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _keep_file(p:Path, # filename for which to check for `indicator_fname`\n",
    "               ignore_fname:str # filename that will result in siblings being ignored\n",
    "                ) -> bool:\n",
    "    \"Returns False if `indicator_fname` is a sibling to `fname` else True\"\n",
    "    if p.exists(): return not bool(p.parent.ls().attrgot('name').filter(lambda x: x == ignore_fname))\n",
    "    else: True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef30c3-38ee-4c77-93df-c1ae4f959eb1",
   "metadata": {},
   "source": [
    "Sometimes you may wish to override one or more of the skip_flags, in which case you can use the argument `force_flags` which will remove the appropriate tag(s) from `skip_flags`.  This is useful because `skip_flags` are meant to be set in the `tst_flags` field of `settings.ini`, whereas `force_flags` are usually passed in by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc6a61-a48e-4ab1-89a9-18316ca795d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@call_parse\n",
    "@delegates(nbglob_cli)\n",
    "def nbdev_test(\n",
    "    path:str=None,  # A notebook name or glob to test\n",
    "    flags:str='',  # Space separated list of test flags to run that are normally ignored\n",
    "    n_workers:int=None,  # Number of workers\n",
    "    timing:bool=False,  # Time each notebook to see which are slow\n",
    "    do_print:bool=False, # Print start and end of each notebook\n",
    "    pause:float=0.01,  # Pause time (in seconds) between notebooks to avoid race conditions\n",
    "    ignore_fname:str='.notest', # Filename that will result in siblings being ignored\n",
    "    **kwargs):\n",
    "    \"Test in parallel notebooks matching `path`, passing along `flags`\"\n",
    "    skip_flags = get_config().tst_flags.split()\n",
    "    force_flags = flags.split()\n",
    "    files = nbglob(path, as_path=True, **kwargs)\n",
    "    files = [f.absolute() for f in sorted(files) if _keep_file(f, ignore_fname)]\n",
    "    if len(files)==0: return print('No files were eligible for testing')\n",
    "\n",
    "    if n_workers is None: n_workers = 0 if len(files)==1 else min(num_cpus(), 8)\n",
    "    if IN_NOTEBOOK: kw = {'method':'spawn'} if os.name=='nt' else {'method':'forkserver'}\n",
    "    else: kw = {}\n",
    "    wd_pth = get_config().nbs_path\n",
    "    with working_directory(wd_pth if (wd_pth and wd_pth.exists()) else os.getcwd()):\n",
    "        results = parallel(test_nb, files, skip_flags=skip_flags, force_flags=force_flags, n_workers=n_workers,\n",
    "                           basepath=get_config().config_path, pause=pause, do_print=do_print,\n",
    "                           executor=False, maxtasksperchild=1, **kw)\n",
    "    passed,times = zip(*results)\n",
    "    if all(passed): print(\"Success.\")\n",
    "    else: \n",
    "        _fence = '='*50\n",
    "        failed = '\\n\\t'.join(f.name for p,f in zip(passed,files) if not p)\n",
    "        sys.stderr.write(f\"\\nnbdev Tests Failed On The Following Notebooks:\\n{_fence}\\n\\t{failed}\\n\")\n",
    "        sys.exit(1)\n",
    "    if timing:\n",
    "        for i,t in sorted(enumerate(times), key=lambda o:o[1], reverse=True): print(f\"{files[i].name}: {int(t)} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb85960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "#|eval:false\n",
    "nbdev_test(n_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aec103-88e0-41bf-98d0-ea7019ca8680",
   "metadata": {},
   "source": [
    "You can even run `nbdev_test` in non nbdev projects, for example, you can test an individual notebook like so:\n",
    "\n",
    "```\n",
    "nbdev_test --path ../../tests/minimal.ipynb --do_print\n",
    "```\n",
    "\n",
    "Or you can test an entire directory of notebooks filtered for only those that match a regular expression:\n",
    "\n",
    "```\n",
    "nbdev_test --path ../../tests --file_re '.*test.ipynb' --do_print\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3f4db",
   "metadata": {},
   "source": [
    "## Eval -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a32f1-8884-497e-a1af-dd38c80d8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f62c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
