{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command line functions\n",
    "\n",
    "> Console commands added by the nbdev library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from nbdev.imports import *\n",
    "from nbdev.export import *\n",
    "from nbdev.sync import *\n",
    "from nbdev.merge import *\n",
    "from nbdev.export2html import *\n",
    "from nbdev.test import *\n",
    "from fastscript.fastscript import call_parse, Param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nbdev` comes with the following commands. To use any of them, you muse be in one of the subfolder of your project: they will search for the `settings.ini` recursively in the parent directory but need to accessit to be able to work. Their names all begin by nbdev so you can easily get a list with tab completion.\n",
    "- `nbdev_build_lib` builds the library from the notebooks\n",
    "- `nbdev_update_lib` propagates any change in the library back to the notebooks\n",
    "- `nbdev_diff_nbs` gives you the diff between the notebooks and the exported library\n",
    "- `nbdev_build_doc` builds the documentation from the notebooks\n",
    "- `nbdev_nb2md` to convert a notebook to a markdown file\n",
    "- `nbdev_clean_nbs` removes all superfluous metadata form the notebooks, to avoid merge conflicts\n",
    "- `nbdev_read_nbs` read all notebooks to make sure none are broken\n",
    "- `nbdev_trust_nbs` trust all notebooks (so that the HTML content is shown)\n",
    "- `nbdev_fix_merge` will fix merge conflicts in a notebook file\n",
    "- `nbdev_install_git_hooks` install the git hooks that use the last two command automatically on each commit/merge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating from notebooks to script and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def nbdev_build_lib(fname:Param(\"A notebook name or glob to convert\", str)=None):\n",
    "    \"Export notebooks matching `fname` to python modules\"\n",
    "    notebook2script(fname=fname)\n",
    "    write_tmpls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default (`fname` left to `None`), the whole library is built from the notebooks in the `lib_folder` set in your `settings.ini`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def nbdev_update_lib(fname:Param(\"A notebook name or glob to convert\", str)=None):\n",
    "    \"Propagates any change in the modules matching `fname` to the notebooks that created them\"\n",
    "    script2notebook(fname=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default (`fname` left to `None`), the whole library is treated. Note that this tool is only designed for small changes such as typo or small bug fixes. You can't add new cells in notebook from the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def nbdev_diff_nbs(): \n",
    "    \"Prints the diff between an export of the library in notebooks and the actual modules\"\n",
    "    diff_nb_script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _test_one(fname, flags=None, verbose=True):\n",
    "    print(f\"testing: {fname}\")\n",
    "    start = time.time()\n",
    "    try: \n",
    "        test_nb(fname, flags=flags)\n",
    "        return True,time.time()-start\n",
    "    except Exception as e: \n",
    "        if \"Kernel died before replying to kernel_info\" in str(e):\n",
    "            time.sleep(random.random())\n",
    "            _test_one(fname, flags=flags)\n",
    "        if verbose: print(f'Error in {fname}:\\n{e}')\n",
    "        return False,time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def nbdev_test_nbs(fname:Param(\"A notebook name or glob to convert\", str)=None,\n",
    "                   flags:Param(\"Space separated list of flags\", str)=None,\n",
    "                   n_workers:Param(\"Number of workers to use\", int)=None,\n",
    "                   verbose:Param(\"Print errors along the way\", bool)=True,\n",
    "                   timing:Param(\"Timing each notebook to see the ones are slow\", bool)=True):\n",
    "    \"Test in parallel the notebooks matching `fname`, passing along `flags`\"\n",
    "    if flags is not None: flags = flags.split(' ')\n",
    "    if fname is None: \n",
    "        files = [f for f in Config().nbs_path.glob('*.ipynb') if not f.name.startswith('_')]\n",
    "    else: files = glob.glob(fname)\n",
    "    files = [Path(f).absolute() for f in sorted(files)]\n",
    "    if len(files)==1 and n_workers is None: n_workers=0\n",
    "    # make sure we are inside the notebook folder of the project\n",
    "    os.chdir(Config().nbs_path)\n",
    "    results = parallel(_test_one, files, flags=flags, verbose=verbose, n_workers=n_workers)\n",
    "    passed,times = [r[0] for r in results],[r[1] for r in results]\n",
    "    if all(passed): print(\"All tests are passing!\")\n",
    "    else:\n",
    "        msg = \"The following notebooks failed:\\n\"\n",
    "        raise Exception(msg + '\\n'.join([f.name for p,f in zip(passed,files) if not p]))\n",
    "    if timing:\n",
    "        for i,t in sorted(enumerate(times), key=lambda o:o[1], reverse=True): \n",
    "            print(f\"Notebook {files[i].name} took {int(t)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default (`fname` left to `None`), the whole library is tested from the notebooks in the `lib_folder` set in your `settings.ini`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions complete the ones in `export2html` to fully build the documentation of your library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time,random,warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _leaf(k,v):\n",
    "    url = 'external_url' if \"http\" in v else 'url'\n",
    "    #if url=='url': v=v+'.html'\n",
    "    return {'title':k, url:v, 'output':'web,pdf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_k_names = ['folders', 'folderitems', 'subfolders', 'subfolderitems']\n",
    "def _side_dict(title, data, level=0):\n",
    "    k_name = _k_names[level]\n",
    "    level += 1\n",
    "    res = [(_side_dict(k, v, level) if isinstance(v,dict) else _leaf(k,v))\n",
    "        for k,v in data.items()]\n",
    "    return ({k_name:res} if not title\n",
    "            else res if title.startswith('empty')\n",
    "            else {'title': title, 'output':'web', k_name: res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_re_catch_title = re.compile('^title\\s*:\\s*(\\S+.*)$', re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_title(fname):\n",
    "    \"Grabs the title of html file `fname`\"\n",
    "    with open(fname, 'r') as f: code = f.read()\n",
    "    src =  _re_catch_title.search(code)\n",
    "    return fname.stem if src is None else src.groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(_get_title(Config().doc_path/'export.html'), \"Export to modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nbdev.export2html import _nb2htmlfname\n",
    "def create_default_sidebar():\n",
    "    \"Create the default sidebar for the docs website\"\n",
    "    dic = {\"Overview\": \"/\"}\n",
    "    files = [f for f in Config().nbs_path.glob('*.ipynb') if not f.name.startswith('_')]\n",
    "    fnames = [_nb2htmlfname(f) for f in sorted(files)]\n",
    "    dic.update({_get_title(f):f'/{f.stem}' for f in fnames if f.stem!='index'})\n",
    "    dic = {Config().lib_name: dic}\n",
    "    json.dump(dic, open(Config().doc_path/'sidebar.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default sidebar lists all html pages with their respective title, except the index that is named \"Overview\". To build a custom sidebar, set the flag `custom_sidebar` in your `settings.ini` to `True` then change the `sidebar.json` file in the `doc_folder` to your liking. Otherwise, the sidebar is updated at each doc build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#create_default_sidebar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_sidebar():\n",
    "    \"Making sidebar for the doc website form the content of `doc_folder/sidebar.json`\"\n",
    "    if not (Config().doc_path/'sidebar.json').exists() or Config().custom_sidebar == 'False': create_default_sidebar()\n",
    "    sidebar_d = json.load(open(Config().doc_path/'sidebar.json', 'r'))\n",
    "    res = _side_dict('Sidebar', sidebar_d)\n",
    "    res = {'entries': [res]}\n",
    "    res_s = yaml.dump(res, default_flow_style=False)\n",
    "    res_s = res_s.replace('- subfolders:', '  subfolders:').replace(' - - ', '   - ')\n",
    "    res_s = f\"\"\"\n",
    "#################################################\n",
    "### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\n",
    "#################################################\n",
    "# Instead edit {'../../sidebar.json'}\n",
    "\"\"\"+res_s\n",
    "    open(Config().doc_path/'_data/sidebars/home_sidebar.yml', 'w').write(res_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "_re_index = re.compile(r'^(?:\\d*_|)index\\.ipynb$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def make_readme():\n",
    "    \"Convert the index notebook to README.md\"\n",
    "    index_fn = None\n",
    "    for f in Config().nbs_path.glob('*.ipynb'):\n",
    "        if _re_index.match(f.name): index_fn = f\n",
    "    assert index_fn is not None, \"Could not locate index notebook\"\n",
    "    convert_md(index_fn, Config().config_file.parent, jekyll=False)\n",
    "    n = Config().config_file.parent/index_fn.with_suffix('.md').name\n",
    "    shutil.move(n, Config().config_file.parent/'README.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def nbdev_build_docs(fname:Param(\"A notebook name or glob to convert\", str)=None,\n",
    "                     force_all:Param(\"Rebuild even notebooks that haven't changed\", bool)=False,\n",
    "                     mk_readme:Param(\"Also convert the index notebook to README\", bool)=True,\n",
    "                     n_workers:Param(\"Number of workers to use\", int)=None):\n",
    "    \"Build the documentation by converting notebooks mathing `fname` to html\"\n",
    "    notebook2html(fname=fname, force_all=force_all, n_workers=n_workers)\n",
    "    if fname is None: make_sidebar()\n",
    "    if mk_readme: make_readme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default (`fname` left to `None`), the whole documentation is build from the notebooks in the `lib_folder` set in your `settings.ini`, only converting the ones that have been modified since the their corresponding html was last touched unless you pass `force_all=True`. The index is also converted to make the README file, unless you pass along `mk_readme=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def nbdev_nb2md(fname:Param(\"A notebook file name to convert\", str),\n",
    "                dest:Param(\"The destination folder\", str)='.',\n",
    "                jekyll:Param(\"To use jekyll metadata for your markdown file or not\", bool)=True,):\n",
    "    \"Convert the notebook in `fname` to a markdown file\"\n",
    "    convert_md(fname, dest, jekyll=jekyll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stripout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid pointless conflicts while working with jupyter notebooks (with different execution counts or cell metadata), it is recommended to clean the notebooks before commiting anything (done automatically if you install the git hooks with `nbdev_install_git_hooks`). The following functions are used to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def rm_execution_count(o):\n",
    "    \"Remove execution count in `o`\"\n",
    "    if 'execution_count' in o: o['execution_count'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def clean_cell_output(cell):\n",
    "    \"Remove execution count in `cell`\"\n",
    "    if 'outputs' in cell:\n",
    "        for o in cell['outputs']: rm_execution_count(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "cell_metadata_keep = [\"hide_input\"]\n",
    "nb_metadata_keep   = [\"kernelspec\", \"jekyll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def clean_cell(cell, clear_all=False):\n",
    "    \"Clen `cell` by removing superluous metadata or everything except the input if `clear_all`\"\n",
    "    rm_execution_count(cell)\n",
    "    if 'outputs' in cell:\n",
    "        if clear_all: cell['outputs'] = []\n",
    "        else:         clean_cell_output(cell)\n",
    "    cell['metadata'] = {} if clear_all else {k:v for k,v in cell['metadata'].items() if k in cell_metadata_keep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = {'cell_type': 'code',\n",
    "       'execution_count': 26,\n",
    "       'metadata': {'hide_input': True, 'meta': 23},\n",
    "       'outputs': [{'execution_count': 2, 'output': 'super'}],\n",
    "       'source': 'awesome_code'}\n",
    "tst1 = tst.copy()\n",
    "\n",
    "clean_cell(tst)\n",
    "test_eq(tst, {'cell_type': 'code',\n",
    "              'execution_count': None,\n",
    "              'metadata': {'hide_input': True},\n",
    "              'outputs': [{'execution_count': None, 'output': 'super'}],\n",
    "              'source': 'awesome_code'})\n",
    "\n",
    "clean_cell(tst1, clear_all=True)\n",
    "test_eq(tst1, {'cell_type': 'code',\n",
    "               'execution_count': None,\n",
    "               'metadata': {},\n",
    "               'outputs': [],\n",
    "               'source': 'awesome_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def clean_nb(nb, clear_all=False):\n",
    "    \"Clean `nb` from superfulous metadata, passing `clear_all` to `clean_cell`\"\n",
    "    for c in nb['cells']: clean_cell(c, clear_all=clear_all)\n",
    "    nb['metadata'] = {k:v for k,v in nb['metadata'].items() if k in nb_metadata_keep }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = {'cell_type': 'code',\n",
    "       'execution_count': 26,\n",
    "       'metadata': {'hide_input': True, 'meta': 23},\n",
    "       'outputs': [{'execution_count': 2, 'output': 'super'}],\n",
    "       'source': 'awesome_code'}\n",
    "nb = {'metadata': {'kernelspec': 'some_spec', 'jekyll': 'some_meta', 'meta': 37},\n",
    "      'cells': [tst]}\n",
    "\n",
    "clean_nb(nb)\n",
    "test_eq(nb['cells'][0], {'cell_type': 'code',\n",
    "              'execution_count': None,\n",
    "              'metadata': {'hide_input': True},\n",
    "              'outputs': [{'execution_count': None, 'output': 'super'}],\n",
    "              'source': 'awesome_code'})\n",
    "test_eq(nb['metadata'], {'kernelspec': 'some_spec', 'jekyll': 'some_meta'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import io,sys,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _print_output(nb):\n",
    "    \"Print `nb` in stdout for git things\"\n",
    "    _output_stream = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
    "    x = json.dumps(nb, sort_keys=True, indent=1, ensure_ascii=False)\n",
    "    _output_stream.write(x)\n",
    "    _output_stream.write(\"\\n\")\n",
    "    _output_stream.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def nbdev_clean_nbs(fname:Param(\"A notebook name or glob to convert\", str)=None, \n",
    "                    clear_all:Param(\"Clean all metadata and outputs\", bool)=False,\n",
    "                    disp:Param(\"Print the cleaned outputs\", bool)=False,\n",
    "                    read_input_stream:Param(\"Read input stram and not nb folder\")=False):\n",
    "    \"Clean all notebooks in `fname` to avoid merge conflicts\"\n",
    "    #Git hooks will pass the notebooks in the stdin\n",
    "    if read_input_stream and sys.stdin:\n",
    "        input_stream = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')\n",
    "        nb = json.load(input_stream)\n",
    "        clean_nb(nb, clear_all=clear_all)\n",
    "        _print_output(nb)\n",
    "        return\n",
    "    files = Config().nbs_path.glob('**/*.ipynb') if fname is None else glob.glob(fname)\n",
    "    for f in files:\n",
    "        if not str(f).endswith('.ipynb'): continue\n",
    "        nb = read_nb(f)\n",
    "        clean_nb(nb, clear_all=clear_all)\n",
    "        if disp: _print_output(nb)\n",
    "        else:\n",
    "            NotebookNotary().sign(nb)\n",
    "            nbformat.write(nb, str(f), version=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default (`fname` left to `None`), the all the notebooks in `lib_folder` are cleaned. You can opt in to fully clean the noteobok by removing every bit of metadata and the cell outputs by passing `clear_all=True`. `disp` is only used for internal use with git hooks and will print the clean notebook instead of saving it. Same for `read_input_stream` that will read the notebook from the input stream instead of the file names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def nbdev_read_nbs(fname:Param(\"A notebook name or glob to convert\", str)=None):\n",
    "    \"Check all notebooks matching `fname` can be opened\"\n",
    "    files = Config().nbs_path.glob('**/*.ipynb') if fname is None else glob.glob(fname)\n",
    "    for nb in files:\n",
    "        try: _ = read_nb(nb)\n",
    "        except Exception as e:\n",
    "            print(f\"{nb} is corrupted and can't be opened.\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default (`fname` left to `None`), the all the notebooks in `lib_folder` are checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def nbdev_trust_nbs(fname:Param(\"A notebook name or glob to convert\", str)=None,\n",
    "                    force_all:Param(\"Trust even notebooks that haven't changed\", bool)=False):\n",
    "    \"Trust noteboks matching `fname`\"\n",
    "    check_fname = Config().nbs_path/\".last_checked\"\n",
    "    last_checked = os.path.getmtime(check_fname) if check_fname.exists() else None\n",
    "    files = Config().nbs_path.glob('**/*.ipynb') if fname is None else glob.glob(fname)\n",
    "    for fn in files:\n",
    "        if last_checked and not force_all:\n",
    "            last_changed = os.path.getmtime(fn)\n",
    "            if last_changed < last_checked: continue\n",
    "        nb = read_nb(fn)\n",
    "        if not NotebookNotary().check_signature(nb): NotebookNotary().sign(nb)\n",
    "    check_fname.touch(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default (`fname` left to `None`), the all the notebooks in `lib_folder` are trusted. To speed things up, only the ones touched since the last time this command was run are trusted unless you pass along `force_all=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def nbdev_fix_merge(fname:Param(\"A notebook filename to fix\", str),\n",
    "                    fast:Param(\"Fast fix: automatically fix the merge conflicts in outputs or metadata\", bool)=True,\n",
    "                    trust_us:Param(\"Use local outputs/metadata when fast mergning\", bool)=True):\n",
    "    \"Fix merge conflicts in notebook `fname`\"\n",
    "    fix_conflicts(fname, fast=fast, trust_us=trust_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have merge conflicts after a `git pull`, the notebook file will be broken and won't open in jupyter notebook anymore. This command fixes this by changing the notebook to a proper json file again and add markdown cells to signal the conflict, you just have to open that notebook again and look for `>>>>>>>` to see those conflicts and manually fix them. The old broken file is copied with a `.ipynb.bak` extension, so is still accessible in case the merge wasn't sucessful.\n",
    "\n",
    "Moreover, if `fast=True`, conflicts in outputs and metadata will automatically be fixed by using the local version if `trust_us=True`, the remote one if `trust_us=False`. With this option, it's very likely you won't have anything to do, unless there is a real conflict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@call_parse\n",
    "def nbdev_install_git_hooks():\n",
    "    \"Install git hooks to clean/trust notebooks automatically\"\n",
    "    path = Config().config_file.parent\n",
    "    fn = path/'.git'/'hooks'/'post-merge'\n",
    "    #Trust notebooks after merge\n",
    "    with open(fn, 'w') as f:\n",
    "        f.write(\"\"\"#!/bin/bash\n",
    "echo \"Trusting notebooks\"\n",
    "nbdev_trust_nbs\n",
    "\"\"\"\n",
    "        )\n",
    "    os.chmod(fn, os.stat(fn).st_mode | stat.S_IEXEC)\n",
    "    #Clean notebooks on commit/diff\n",
    "    with open(path/'.gitconfig', 'w') as f:\n",
    "        f.write(\"\"\"# Generated by nbdev_install_git_hooks\n",
    "#\n",
    "# If you need to disable this instrumentation do:\n",
    "#\n",
    "# git config --local --unset include.path\n",
    "#\n",
    "# To restore the filter\n",
    "#\n",
    "# git config --local include.path .gitconfig\n",
    "#\n",
    "# If you see notebooks not stripped, checked the filters are applied in .gitattributes\n",
    "#\n",
    "[filter \"clean-nbs\"]\n",
    "        clean = nbdev_clean_nbs --read_input_stream True\n",
    "        smudge = cat\n",
    "        required = true\n",
    "[diff \"ipynb\"]\n",
    "        textconv = nbdev_clean_nbs --disp True --fname\n",
    "\"\"\")\n",
    "    cmd = \"git config --local include.path ../.gitconfig\"\n",
    "    print(f\"Executing: {cmd}\")\n",
    "    result = subprocess.run(cmd.split(), shell=False, check=False, stderr=subprocess.PIPE)\n",
    "    if result.returncode == 0:\n",
    "        print(\"Success: hooks are installed and repo's .gitconfig is now trusted\")\n",
    "    else:\n",
    "        print(\"Failed to trust repo's .gitconfig\")\n",
    "        if result.stderr: print(f\"Error: {result.stderr.decode('utf-8')}\")\n",
    "    with open(Config().nbs_path/'.gitattributes', 'w') as f:\n",
    "        f.write(\"\"\"**/*.ipynb filter=clean-nbs\n",
    "**/*.ipynb diff=ipynb\n",
    "\"\"\"\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command install git hooks to make sure notebooks are cleaned before you commit them to GitHub and automatically trusted at each merge. To be more specific, this creates:\n",
    "- an executable '.git/hooks/post-merge' file that contains the command `nbdev_trust_nbs`\n",
    "- a `.gitconfig` file that uses `nbev_clean_nbs` has a filter/diff on all notebook files inside `nbs_folder` and a `.gitattributes` file generated in this folder (copy this file in other folders where you might have notebooks you want cleaned as well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_export.ipynb.\n",
      "Converted 01_sync.ipynb.\n",
      "Converted 02_showdoc.ipynb.\n",
      "Converted 03_export2html.ipynb.\n",
      "Converted 04_test.ipynb.\n",
      "Converted 05_merge.ipynb.\n",
      "Converted 06_cli.ipynb.\n",
      "Converted 99_search.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
