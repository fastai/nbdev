[
  {
    "objectID": "explanations/docs.html",
    "href": "explanations/docs.html",
    "title": "Docs Website",
    "section": "",
    "text": "There are two mediums in which you can author documentation in nbdev:\n\nJupyter Notebooks\nQuarto Markdown (.qmd)\n\nFor most cases, you will use Jupyter Notebooks. However, you may choose to author a document in Quarto Markdown if there is no code on that particular page. When in doubt, we recommend using notebooks as they are more versatile.\nIn the case of notebooks, nbdev pre-processes them to add, remove or change the content before passing it to Quarto. In some cases, nbdev even executes certain cells in order to render the documentation properly. The mechanics of this are discussed in the Notebook Processor section below.\nFor markdown files, Quarto renders these directly.\n\n\n\nNbdev does special pre-processing on notebooks based on the following:\n\nDirectives: Directives are special comments that allow you to perform operations on cells. For example, the comment #|hide allows you to hide cell inputs and outputs. You can read more about directives on this page. Directives that are unique to nbdev and not supported by Quarto are removed from the notebook before being passed to Quarto.\nFront Matter: Front matter allows you to specify document-level options so you don’t have to repeat them on each cell. (Similarly, _quarto.yml allows you to specify project-level options.) You can read more about Quarto front-matter here.\n\nThe directives and front-matter are used by a Processing Pipeline to transform notebooks. Many of these pre-processing steps are defined in nbdev.processors, which are then run by nbdev.process.NBProcessor. Some of these pre-processing steps involve running code (with execnb) in order to dynamically render API documentation. This process is explained in the How show_doc works section below.\nWhen generating your docs site, the intermediate output of these pre-processed notebooks and other quarto project files are saved into a directory named _proc/ at the root of your repo. You can inspect the _proc/ directory in order to debug or understand how notebooks are pre-processed.\n\n\n\nQuarto is the mechanism nbdev uses to generate web pages from notebooks. It is useful to visit the Quarto docs and understand how it works. nbdev automatically generates the Quarto configuration files _quarto.yml and sidebar.yml for you.\nYou can override any settings in _quarto.yml by defining a custom.yml file. This is explained further in the Customizing Quarto section. We explain how to customize your sidebar in the Customizing The Sidebar section.\n\n\n\nQuarto has a built-in static site generator that will generate HTML, Javascript and CSS files. These files will be placed in the doc_path directory as specified in your project’s settings.ini file, which is _docs/ by default.",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Docs Website"
    ]
  },
  {
    "objectID": "explanations/docs.html#concepts",
    "href": "explanations/docs.html#concepts",
    "title": "Docs Website",
    "section": "",
    "text": "There are two mediums in which you can author documentation in nbdev:\n\nJupyter Notebooks\nQuarto Markdown (.qmd)\n\nFor most cases, you will use Jupyter Notebooks. However, you may choose to author a document in Quarto Markdown if there is no code on that particular page. When in doubt, we recommend using notebooks as they are more versatile.\nIn the case of notebooks, nbdev pre-processes them to add, remove or change the content before passing it to Quarto. In some cases, nbdev even executes certain cells in order to render the documentation properly. The mechanics of this are discussed in the Notebook Processor section below.\nFor markdown files, Quarto renders these directly.\n\n\n\nNbdev does special pre-processing on notebooks based on the following:\n\nDirectives: Directives are special comments that allow you to perform operations on cells. For example, the comment #|hide allows you to hide cell inputs and outputs. You can read more about directives on this page. Directives that are unique to nbdev and not supported by Quarto are removed from the notebook before being passed to Quarto.\nFront Matter: Front matter allows you to specify document-level options so you don’t have to repeat them on each cell. (Similarly, _quarto.yml allows you to specify project-level options.) You can read more about Quarto front-matter here.\n\nThe directives and front-matter are used by a Processing Pipeline to transform notebooks. Many of these pre-processing steps are defined in nbdev.processors, which are then run by nbdev.process.NBProcessor. Some of these pre-processing steps involve running code (with execnb) in order to dynamically render API documentation. This process is explained in the How show_doc works section below.\nWhen generating your docs site, the intermediate output of these pre-processed notebooks and other quarto project files are saved into a directory named _proc/ at the root of your repo. You can inspect the _proc/ directory in order to debug or understand how notebooks are pre-processed.\n\n\n\nQuarto is the mechanism nbdev uses to generate web pages from notebooks. It is useful to visit the Quarto docs and understand how it works. nbdev automatically generates the Quarto configuration files _quarto.yml and sidebar.yml for you.\nYou can override any settings in _quarto.yml by defining a custom.yml file. This is explained further in the Customizing Quarto section. We explain how to customize your sidebar in the Customizing The Sidebar section.\n\n\n\nQuarto has a built-in static site generator that will generate HTML, Javascript and CSS files. These files will be placed in the doc_path directory as specified in your project’s settings.ini file, which is _docs/ by default.",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Docs Website"
    ]
  },
  {
    "objectID": "explanations/docs.html#overview",
    "href": "explanations/docs.html#overview",
    "title": "Docs Website",
    "section": "Overview",
    "text": "Overview\nBelow is a diagram on how these concepts fit together.",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Docs Website"
    ]
  },
  {
    "objectID": "explanations/docs.html#customizing-quarto",
    "href": "explanations/docs.html#customizing-quarto",
    "title": "Docs Website",
    "section": "Customizing Quarto",
    "text": "Customizing Quarto\nYou can create a custom.yml file in the same location as your _quarto.yml file to override any values in _quarto.yml. For example, assume your _quarto.yml file looks contains this:\n\nwebsite:\n  title: \"nbdev\"\n  site-url: \"https://nbdev.fast.ai/\"\n  description: \"Create delightful software with Jupyter Notebooks\"\n  twitter-card: true\n  open-graph: true\n  repo-branch: master\n  repo-url: \"https://github.com/fastai/nbdev\"\n  repo-actions: [issue]\n  navbar:\n    background: primary\n    search: true\n    right:\n      - icon: github\n        href: \"https://github.com/fastai/nbdev\"\n  sidebar:\n    style: \"floating\"\n\nLet’s assume you want to customize your sidebar navigation options such that instead of “floating” for sidebar.style, you wanted your navbar to be “docked”. Additionally, lets assume you want a different background color using the sidebar.background field which is not in the configuration above.\nTo accomplish these tasks, you would create a custom.yml in the same location as _quarto.yml with these contents:\n\nwebsite:\n  sidebar:\n      style: \"docked\"\n      background: \"dark\"\n\n\n\n\n\n\n\nNote\n\n\n\nYou can also set custom_quarto_yml = True in settings.ini if you wish to edit _quarto.yml directly instead of overriding settings in custom.yml.\n\n\n\nCustomizing The Sidebar\nBy default nbdev automatically generates sidebar.yml, which specifies the tree structure of your sidebar. nbdev infers the tree structure by inspecting the directory structure containing your source files. You can see an example of this by inspecting the folder structure of the notebooks directory in nbdev and the corresponding left-hand sidebar on this website. Leading numbers in filenames and directories are ignored when naming elements of the sidebar (which you can see examples of in this project’s notebooks directory).\nTo customize the sidebar, you must set custom_sidebar = true in settings.ini. This will prevent nbdev from regenerating this file every time the docs are re-built. This way, you an edit this file directly instead of overriding the sidebar with custom.yml.",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Docs Website"
    ]
  },
  {
    "objectID": "explanations/docs.html#how-show_doc-works",
    "href": "explanations/docs.html#how-show_doc-works",
    "title": "Docs Website",
    "section": "How show_doc works",
    "text": "How show_doc works\nWhen your documention website is built, all functions and classes you export to source code will be automatically documented with show_doc. This function outputs a summary of the symbol, showing its signature, docstring, and parameters. For instance, if you have this function:\n\ndef say_gday(\n    greeting:str=\"G'day\",  # Greeting to use\n    strine:bool=True,      # Use incomprehensible Aussie accent?\n    dropbears:bool=False): # Also warn about drop-bears?\n    \"Says g'day, the classic Aussie greeting\"\n    ...\n\nThis is how it’s rendered in the documentation, by automatically generating a temporary cell containing:\n\nshow_doc(say_gday)\n\n\nsay_gday\n\n say_gday (greeting:str=\"G'day\", strine:bool=True, dropbears:bool=False)\n\nSays g’day, the classic Aussie greeting\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngreeting\nstr\nG’day\nGreeting to use\n\n\nstrine\nbool\nTrue\nUse incomprehensible Aussie accent?\n\n\ndropbears\nbool\nFalse\nAlso warn about drop-bears?\n\n\n\n\n\nBecause this is done automatically any time you build your docs (including automatically by continuous integration), your documentation will always contain current information about your code.\nYou can also document code that’s not created in a notebook, by using show_doc with imported code. For instance, if we wanted to document release_conda, we can import it and call show_doc(release_conda):\n\nfrom nbdev.release import release_conda\nshow_doc(release_conda)\n\nsource\n\nrelease_conda\n\n release_conda (path:str='conda', do_build:&lt;function bool_arg&gt;=True,\n                build_args:str='', skip_upload:&lt;function\n                store_true&gt;=False, mambabuild:&lt;function store_true&gt;=False,\n                upload_user:str=None)\n\nCreate a meta.yaml file ready to be built into a package, and optionally build and upload it\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nconda\nPath where package will be created\n\n\ndo_build\nbool_arg\nTrue\nRun conda build step\n\n\nbuild_args\nstr\n\nAdditional args (as str) to send to conda build\n\n\nskip_upload\nstore_true\nFalse\nSkip anaconda upload step\n\n\nmambabuild\nstore_true\nFalse\nUse mambabuild (requires boa)\n\n\nupload_user\nstr\nNone\nOptional user to upload package to\n\n\n\n\n\n\nAutomatic Cell Execution\nWhen your documentation is built, all your manually added show_doc cells are run automatically. nbdev also executes all cells containing an import statement, and all exported cells – that way we can be sure that the symbol used in your show_doc cell is available.\nWe don’t, however, execute any other cells. That’s because you wouldn’t want to wait for your entire notebook to run just to build your docs; for instance, your docs might demonstrate training a model which takes hours to complete!\nThis leads to an important rule when authoring nbdev notebooks:\n\n\n\n\n\n\nWarning\n\n\n\nDo not mix import statements (or calls to show_doc) with other code in a single cell. If you do, all the code in that cell will be executed every time you build your docs, which might lead to errors (since not all previous cells will have been executed.\nInstead, put your imports in separate cells, and calls to show_doc should contain only that one line of code – the show_doc call.\n\n\nNote that nbdev automatically hides the actual show_doc(...) line of code. So your users only see the output.\n\nForcing Cells To Execute\nSometimes you may want to execute additional cells beyond what is automatically executed by nbdev. For instance, on our Getting Started page we show a list of all nbdev commands, automatically generated with nbdev_help. We want this page to always have the most up to date list of commands and docs, so we want it to always execute when the docs are rendered. To do that, add the following directive to the top of a cell:\n#| exec_doc\nAlternatively, you can get nbdev to automatically execute all cells when rendering your docs, by adding the following to your notebook frontmatter:\n---\nexec_all: true\n---\n\n\nSkipping Execution\nLikewise, you can instruct nbdev to not execute any cells when rendering your docs with the following front matter:\n---\nskip_showdoc: true\n---\nOr ignore execution for a specific cell with this directive:\n#|eval: false\n\n\n\nWhy use show_doc?\nMany Python developers use sphinx autodoc to automatically document a whole module all at once. Whilst this can work reasonably well, we think there are huge benefits for both developers and users in using nbdev’s approach instead\nThe premise of nbdev’s approach is that your documentation is important enough to be worth you taking the time to think carefully though each thing you want to show your users, what examples you’re going to provide, maybe adding some images to explain more complex ideas, and so forth. Jupyter provides a terrific environment for creating just these kinds of documents. For instance, with Jupyter you can:\n\nPaste images directly from your clipboard into a cell\nInsert code and have it executed and the results displayed to users\nCreate a hierarchy of headings to help structure your page\n…and much more.\n\nWith show_doc, you can insert automatically-updated API details for your library anywhere in a page. That means that you get to decide exactly how your page should look, and what information is provided where. You don’t have to limit yourself to the limits of ASCII art for diagrams, and can include full end-to-end code walk-through of the processes your users will be following.",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Docs Website"
    ]
  },
  {
    "objectID": "explanations/docs.html#previewing-your-site-locally",
    "href": "explanations/docs.html#previewing-your-site-locally",
    "title": "Docs Website",
    "section": "Previewing Your Site Locally",
    "text": "Previewing Your Site Locally\nYou can preview your docs anytime by running nbdev_preview. While in preview mode, you can make updates to notebooks and it will be reflected (after a small delay) in your browser.",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Docs Website"
    ]
  },
  {
    "objectID": "explanations/docs.html#deploying-docs-with-github-actions",
    "href": "explanations/docs.html#deploying-docs-with-github-actions",
    "title": "Docs Website",
    "section": "Deploying Docs With GitHub Actions",
    "text": "Deploying Docs With GitHub Actions\nIf your nbdev project lives in GitHub, we include automation that deploys your documentation site for you on GitHub Pages.\nnbdev comes bundled with a workflow file that enables this automation. This workflow is automatically triggered whenever you change any of the content in your repo. The following GitHub Actions workflows will run to generate a docs site (in this order):\n\nDeploy to GitHub Pages: This workflow builds the docs with nbdev. This is defined in deploy.yaml and references fastai/workflows/quarto-ghp.\npages build and deployment: This is an internal built-in workflow that GitHub provides whenever GitHub pages are enabled.\n\nShould anything go wrong in your page build, you can always look at the logs of these workflows. Like other workflows, these can be found in the Actions tab of your repo:\n\n\n\n\n\nTo read more about GitHub Actions, see their docs.",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Docs Website"
    ]
  },
  {
    "objectID": "explanations/docs.html#deploying-your-docs-on-other-platforms",
    "href": "explanations/docs.html#deploying-your-docs-on-other-platforms",
    "title": "Docs Website",
    "section": "Deploying Your Docs On Other Platforms",
    "text": "Deploying Your Docs On Other Platforms\nYou can generate all of the static assets for your site (html, css, etc) by running the command nbdev_docs. After running this command, all of the files for your documentation site will be located in the _docs/ directory (the location is configurable by doc_path in settings.ini) at the root of your repository. This directory is not checked into git and is ignored by .gitignore, but you can use these files to deploy to any hosting platform you want.\nYou can also use the quarto publish command to render your docs on a wide variety of other platforms, which is discussed in the Quarto docs here. After running the command nbdev_docs, the quarto publish command must be run from the root of the _proc/ directory, which is located at the root of your repo. The built-in help of quarto publish provides a good overview of the various targets available:\n\n\n\n\n\n\nCall nbdev_proc_nbs and publish from the _proc/ directory\n\n\n\nTo use quarto publish with nbdev, you must run the nbdev_proc_nbs command to pre-process your notebooks before publishing your docs. As a reminder, nbdev_proc_nbs creates the directory _proc/ at the root of your project that Quarto uses to render your site.\nFor example, to publish a site to Netlify you can run the following command from the root of your repo:\nnbdev_proc_nbs && cd _proc && quarto publish netlify\n\n\n\n!quarto publish -h\n\n\n  Usage:   quarto publish [provider] [path]\n  Version: 1.1.75                          \n                                           \n\n  Description:\n\n    Publish a document or project. Available providers include:\n                                                               \n     - Quarto Pub (quarto-pub)                                 \n     - GitHub Pages (gh-pages)                                 \n     - RStudio Connect (connect)                               \n                                                               \n     - Netlify (netlify)                                       \n    Accounts are configured interactively during publishing.   \n    Manage/remove accounts with: quarto publish accounts       \n\n  Options:\n\n    -h, --help              - Show this help.                                     \n    --id          &lt;id&gt;      - Identifier of content to publish                    \n    --server      &lt;server&gt;  - Server to publish to                                \n    --token       &lt;token&gt;   - Access token for publising provider                 \n    --no-render             - Do not render before publishing.                    \n    --no-prompt             - Do not prompt to confirm publishing destination     \n    --no-browser            - Do not open a browser to the site after publishing  \n    --log         &lt;level&gt;   - Path to log file                                    \n    --log-level   &lt;level&gt;   - Log level (info, warning, error, critical)          \n    --log-format  &lt;format&gt;  - Log format (plain, json-stream)                     \n    --quiet                 - Suppress console output.                            \n\n  Commands:\n\n    help  [command]  - Show this help or the help of a sub-command.\n\n  Examples:\n\n    Publish project (prompt for provider):  quarto publish                                                  \n    Publish document (prompt for provider): quarto publish document.qmd                                     \n    Publish project to Netlify:             quarto publish netlify                                          \n    Publish with explicit target:           quarto publish netlify --id DA36416-F950-4647-815C-01A24233E294 \n    Publish project to GitHub Pages:        quarto publish gh-pages                                         \n    Publish project to RStudio Connect:     quarto publish connect                                          \n    Publish with explicit credentials:      quarto publish connect --server example.com --token 01A24233E294\n    Publish without confirmation prompt:    quarto publish --no-prompt                                      \n    Publish without rendering:              quarto publish --no-render                                      \n    Publish without opening browser:        quarto publish --no-browser                                     \n    Manage/remove publishing accounts:      quarto publish accounts",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Docs Website"
    ]
  },
  {
    "objectID": "explanations/index.html",
    "href": "explanations/index.html",
    "title": "Explanations",
    "section": "",
    "text": "These explanations provide background information on how nbdev is designed and how it works. They are designed to help people who want to more deeply understand the nbdev system.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nSettings.ini\n\n\nThe nbdev configuration file\n\n\n\n\nDirectives\n\n\nA cheat sheet of directives available in nbdev.\n\n\n\n\nDocs Website\n\n\nHow nbdev renders a documentation website for your project.\n\n\n\n\nWhy nbdev\n\n\nWhy we develop software with nbdev\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Get Started",
      "Explanations"
    ]
  },
  {
    "objectID": "explanations/directives.html",
    "href": "explanations/directives.html",
    "title": "Directives",
    "section": "",
    "text": "Directives are special comments that are preceded by #| that control:\nnbdev augments Quarto by providing additional directives than what are available in Quarto. All Quarto directives can be used in nbdev notebooks.\nThis cheat sheet lists all nbdev directives in addition to some Quarto directives we believe are important. We recommend consulting the quarto docs to see all of the directives available to you.\nTo clarify the origin of directives we use the following emojis:",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Directives"
    ]
  },
  {
    "objectID": "explanations/directives.html#cell-visibility",
    "href": "explanations/directives.html#cell-visibility",
    "title": "Directives",
    "section": "Cell Visibility",
    "text": "Cell Visibility\nThe following directives control cell visibility in rendered documentation:\n\n📓 #|hide\nHide cell input and output.\n\n\n\n\n\n\nExample\n\n\n\n\n\nThe following will result in the contents of the cell and it’s output from being hidden:\n#|hide\nprint('you will not see this')\nNote that using #|hide is equivalent to using the Quarto directive #|include: false:\n#|include: false\nprint('you will not see this')\nSee the quarto docs for more information about #|include.\n\n\n\n\n\n🔵 #|echo: &lt;true|false&gt;\nToggle the visibility of code-cell inputs.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|echo: false\nprint('you can see the output but not the code!')\nwhich results in:\nyou can see the output but not the code!\n\n\n\n\n\n🔵 #|output: &lt;true|false|asis&gt;\nSetting this to false hides the output of a cell. Setting this to asis renders the output as raw markdown.\n\n\n\n\n\n\nExample\n\n\n\n\n\nThe following cell will not display any output:\n#|output: false\n1 + 1\nThe following cell with #|output: asis will produce the output hello fastai rendered as markdown instead of a string:\n#|output: asis\nprint(\"`hello fastai`\")\n\n\n\n\n\n📓 #|hide_line\nHide a specific line of code in an input cell.\n\n\n\n\n\n\nExample\n\n\n\n\n\ndef _secret(): ...\n\nfor i in range(3):\n    _secret() #|hide_line\n    print(i)\nbecomes this:\n\ndef _secret(): ...\n\nfor i in range(3):\n    print(i)\n\n0\n1\n2\n\n\n\n\n\n\n\n📓 #|filter_stream &lt;keyword&gt; ...\nFilter lines containing specific keywords in cell outputs.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|filter_stream FutureWarning MultiIndex\nprint('\\n'.join(['A line', 'Foobar baz FutureWarning blah', \n                 'zig zagMultiIndex zoom', 'Another line.']))\nwill output this:\n\n\nA line\nAnother line.\n\n\n\n\n\n\n\n🔵 #|code-fold: &lt;show|true&gt;\nThe #|code-fold directive allows you to collapse code cells. When set to true, the element is collapsed by default, when set to show show the element is shown by default.\n\n\n\n\n\n\nExample\n\n\n\n\n\nWhen you set #|code-fold: true, the input cell is collapsed:\n\n\nCode\nprint('this is')\nprint('output')\nprint('that takes')\nprint('lots of vertical space')\n\n\nthis is\noutput\nthat takes\nlots of vertical space\n\n\nWhen you set #|code-fold: show the input cell is shown but still in a collapsible element:\n\n\nCode\nprint('this is')\nprint('output')\nprint('that takes')\nprint('lots of vertical space')\n\n\nthis is\noutput\nthat takes\nlots of vertical space",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Directives"
    ]
  },
  {
    "objectID": "explanations/directives.html#generating-source-code",
    "href": "explanations/directives.html#generating-source-code",
    "title": "Directives",
    "section": "Generating Source Code",
    "text": "Generating Source Code\nThe following directives control how source code is exported from code cells.\n\n📓 #|default_exp &lt;name&gt;\nNames the module where cells with the #|export directive will be exported to by default.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#| default_exp baz\n\n# In a new notebook cell:\n\n#| export\ndef my_function(): pass\nIf our package is named: bitsnbytes then we can do:\nfrom bitsnbytes.baz import my_function\nYou can define the package name by using lib_name in settings.ini.\n\n\n\n\n\n📓 #|export\nExports the items in the cell into the generated module and documentation.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|export\ndef say_hello(to:str # name of person to say hello to\n             ):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nThe above cell will get exported to the module specified by #|default_exp. These exports are automatically included in __all__ for the module. To learn how export without inclusion in __all__, see the #|exporti directive.\nFurthermore, the documentation for this function will automatically be rendered like this:\n\n\nsay_hello\n\n say_hello (to:str)\n\nSay hello to somebody\n\n\n\n\nType\nDetails\n\n\n\n\nto\nstr\nname of person to say hello to\n\n\n\nThe docs are generated from this export using show_doc. See these docs for a detailed discussion of show_doc.\n\n\n\n\n\n\n📓 #|exporti\nAn internal export. Not included in __all__ or the docs. Useful for a function that is called by other functions in this module but is not part of the public API.\nEquivalently, you can prefix your function or method with _ e.g. def _private(): pass.\n\n\n📓 #|exports\nA source export. Like #|export but in addition to showing docs via showdoc.show_doc, it also shows the source code.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|exports\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nthis will produce the following output:\n\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\n\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Directives"
    ]
  },
  {
    "objectID": "explanations/directives.html#cell-execution",
    "href": "explanations/directives.html#cell-execution",
    "title": "Directives",
    "section": "Cell Execution",
    "text": "Cell Execution\nThe following directives allow you to control how cells are executed during docs rendering and testing.\n\n📓 #|exec_doc\nEnsures that a cell is executed each time before generating docs. When a cell does not have this annotation, it is run according to the default rules described here.\n\n\n\n\n\n\nExample\n\n\n\n\n\n\ndatetime.datetime.now()\n\ndatetime.datetime(2022, 8, 18, 9, 1, 43, 907609)\n\n\nHowever with the annotation:\n#|exec_doc\ndatetime.datetime.now()\nwe can see that the time has been updated:\n\ndatetime.datetime.now()\n\ndatetime.datetime(2024, 12, 5, 19, 32, 41, 655838)\n\n\n\n\n\n\n\n🔵 #|eval: &lt;true|false&gt;\nWhen set to false, the cell is ignored during testing.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|eval: false\nraise Exception(\"I'm not raised because I'm not run\")\n\n\n\n\n\nCell execution when there is no directive\nWhen a cell has no directives, cells are run by nbdev according to the behavior described here.",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Directives"
    ]
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "nbdev is a notebook-driven development platform. Simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free!\nnbdev makes debugging and refactoring your code much easier than in traditional programming environments since you always have live objects at your fingertips. nbdev also promotes software engineering best practices because tests and documentation are first class.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "getting_started.html#install",
    "href": "getting_started.html#install",
    "title": "Getting Started",
    "section": "Install",
    "text": "Install\nnbdev works on macOS, Linux, and most Unix-style operating systems. It works on Windows under WSL, but not under cmd or Powershell.\nYou can install nbdev with pip:\npip install nbdev\n… or with conda (or mamba):\nconda install -c fastai nbdev\nNote that nbdev must be installed into the same Python environment that you use for both Jupyter and your project.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "getting_started.html#how-to-use-nbdev",
    "href": "getting_started.html#how-to-use-nbdev",
    "title": "Getting Started",
    "section": "How to use nbdev",
    "text": "How to use nbdev\nThe best way to learn how to use nbdev is to complete either the written walkthrough or video walkthrough:\n\n\nAlternatively, there’s a shortened version of the video walkthrough with coding sections sped up using the unsilence Python library – it’s 27 minutes faster, but a bit harder to follow.\nYou can also run nbdev_help from the terminal to see the full list of available commands:\n\n!nbdev_help\n\nnbdev_bump_version        Increment version in settings.ini by one\nnbdev_changelog           Create a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_clean               Clean all notebooks in `fname` to avoid merge conflicts\nnbdev_conda               Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it\nnbdev_create_config       Create a config file.\nnbdev_docs                Create Quarto docs and README.md\nnbdev_export              Export notebooks in `path` to Python modules\nnbdev_filter              A notebook filter for Quarto\nnbdev_fix                 Create working notebook from conflicted notebook `nbname`\nnbdev_help                Show help for all console scripts\nnbdev_install             Install Quarto and the current library\nnbdev_install_hooks       Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nnbdev_install_quarto      Install latest Quarto on macOS or Linux, prints instructions for Windows\nnbdev_merge               Git merge driver for notebooks\nnbdev_migrate             Convert all markdown and notebook files in `path` from v1 to v2\nnbdev_new                 Create an nbdev project.\nnbdev_prepare             Export, test, and clean notebooks, and render README if needed\nnbdev_preview             Preview docs locally\nnbdev_proc_nbs            Process notebooks in `path` for docs rendering\nnbdev_pypi                Create and upload Python package to PyPI\nnbdev_readme              Create README.md from readme_nb (index.ipynb by default)\nnbdev_release_both        Release both conda and PyPI packages\nnbdev_release_gh          Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\nnbdev_release_git         Tag and create a release in GitHub for the current version\nnbdev_requirements        Writes a `requirements.txt` file to `directory` based on settings.ini.\nnbdev_sidebar             Create sidebar.yml\nnbdev_test                Test in parallel notebooks matching `path`, passing along `flags`\nnbdev_trust               Trust notebooks matching `fname`\nnbdev_update              Propagate change in modules matching `fname` to notebooks that created them\nnbdev_update_license      Allows you to update the license of your project.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "getting_started.html#faq",
    "href": "getting_started.html#faq",
    "title": "Getting Started",
    "section": "FAQ",
    "text": "FAQ\n\nQ: What is the warning “Found a cell containing mix of imports and computations. Please use separate cells”?\nA: You should not have cells that are not exported, and contain a mix of import statements along with other code. For instance, don’t do this in a single cell:\nimport some_module\nsome_module.something()\nInstead, split this into two cells, one which does import some_module, and the other which does some_module.something().\nThe reason for this is that when we create your documentation website, we ensure that all of the signatures for functions you document are up to date, by running the imports, exported cells, and show_doc functions in your notebooks. When you mix imports with other code, that other code will be run too, which can cause errors (or at least slowdowns) when creating your website.\n\n\nQ: Why is nbdev asking for root access? How do I install Quarto without root access?\nA: When you setup your first project, nbdev will attempt to automatically download and install Quarto for you. This is the program that we use to create your documentation website.\nQuarto’s standard installation process requires root access, and nbdev will therefore ask for your root password during installation. For most people, this will work fine and everything will be handled automatically – if so, you can skip over the rest of this section, which talks about installing without root access.\nIf you need to install Quarto without root access on Linux, first cd to wherever you want to store it, then download Quarto, and type:\ndpkg -x quarto*.deb .\nmv opt/quarto ./\nrmdir opt\nmkdir -p ~/.local/bin\nln -s \"$(pwd)\"/quarto/bin/quarto ~/.local/bin\nTo use this non-root version of Quarto, you’ll need ~/.local/bin in your PATH environment variable. (Alternatively, change the ln -s step to place the symlink somewhere else in your path.)\n\n\nQ: Someone told me not to use notebooks for “serious” software development!\nA: Watch this video. Don’t worry, we still get this too, despite having used nbdev for a wide range of “very serious” software projects over the last three years, including deep learning libraries, API clients, Python language extensions, terminal user interfaces, and more!",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "getting_started.html#contributing",
    "href": "getting_started.html#contributing",
    "title": "Getting Started",
    "section": "Contributing",
    "text": "Contributing\nIf you want to contribute to nbdev, be sure to review the contributions guidelines. This project adheres to fastai’s code of conduct. By participating, you are expected to uphold this code. In general, we strive to abide by generally accepted best practices in open-source software development.\nMake sure you have nbdev’s git hooks installed by running nbdev_install_hooks in the cloned repository.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "getting_started.html#copyright",
    "href": "getting_started.html#copyright",
    "title": "Getting Started",
    "section": "Copyright",
    "text": "Copyright\nCopyright © 2019 onward fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the “License”); you may not use this project’s files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.",
    "crumbs": [
      "Get Started",
      "Getting Started"
    ]
  },
  {
    "objectID": "api/clean.html",
    "href": "api/clean.html",
    "title": "clean",
    "section": "",
    "text": "To avoid pointless conflicts while working with jupyter notebooks (with different execution counts or cell metadata), it is recommended to clean the notebooks before committing anything (done automatically if you install the git hooks with nbdev_install_hooks). The following functions are used to do that.",
    "crumbs": [
      "Get Started",
      "API",
      "clean"
    ]
  },
  {
    "objectID": "api/clean.html#trust",
    "href": "api/clean.html#trust",
    "title": "clean",
    "section": "Trust",
    "text": "Trust\n\nsource\n\nnbdev_trust\n\n nbdev_trust (fname:str=None, force_all:bool=False)\n\nTrust notebooks matching fname\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to trust\n\n\nforce_all\nbool\nFalse\nAlso trust notebooks that haven’t changed",
    "crumbs": [
      "Get Started",
      "API",
      "clean"
    ]
  },
  {
    "objectID": "api/clean.html#clean",
    "href": "api/clean.html#clean",
    "title": "clean",
    "section": "Clean",
    "text": "Clean\n\nsource\n\nclean_nb\n\n clean_nb (nb, clear_all=False, allowed_metadata_keys:list=None,\n           allowed_cell_metadata_keys:list=None, clean_ids=True)\n\nClean nb from superfluous metadata\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnb\n\n\nThe notebook to clean\n\n\nclear_all\nbool\nFalse\nRemove all cell metadata and cell outputs?\n\n\nallowed_metadata_keys\nlist\nNone\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nlist\nNone\nPreserve the list of keys in cell level metadata\n\n\nclean_ids\nbool\nTrue\nRemove ids from plaintext reprs?\n\n\n\nJupyter adds a trailing  to images in cell outputs. Vscode-jupyter does not.\nNotebooks should be brought to a common style to avoid unnecessary diffs:\n\ntest_nb = read_nb('../../tests/image.ipynb')\nassert test_nb.cells[0].outputs[0].data['image/png'][-1] == \"\\n\" # Make sure it was not converted by acccident\nclean_nb(test_nb)\nassert test_nb.cells[0].outputs[0].data['image/png'][-1] != \"\\n\"\n\nThe test notebook has metadata in both the main metadata section and contains cell level metadata in the second cell:\n\ntest_nb = read_nb('../../tests/metadata.ipynb')\n\nassert {'meta', 'jekyll', 'my_extra_key', 'my_removed_key'} &lt;= test_nb.metadata.keys()\nassert {'meta', 'hide_input', 'my_extra_cell_key', 'my_removed_cell_key'} == test_nb.cells[1].metadata.keys()\n\nAfter cleaning the notebook, all extra metadata is removed, only some keys are allowed by default:\n\nclean_nb(test_nb)\n\nassert {'jekyll', 'kernelspec'} == test_nb.metadata.keys()\nassert {'hide_input'} == test_nb.cells[1].metadata.keys()\n\nWe can preserve some additional keys at the notebook or cell levels:\n\ntest_nb = read_nb('../../tests/metadata.ipynb')\nclean_nb(test_nb, allowed_metadata_keys={'my_extra_key'}, allowed_cell_metadata_keys={'my_extra_cell_key'})\n\nassert {'jekyll', 'kernelspec', 'my_extra_key'} == test_nb.metadata.keys()\nassert {'hide_input', 'my_extra_cell_key'} == test_nb.cells[1].metadata.keys()\n\nPassing clear_all=True removes everything from the cell metadata:\n\ntest_nb = read_nb('../../tests/metadata.ipynb')\nclean_nb(test_nb, clear_all=True)\n\nassert {'jekyll', 'kernelspec'} == test_nb.metadata.keys()\ntest_eq(test_nb.cells[1].metadata, {})\n\nPassing clean_ids=True removes ids from plaintext repr outputs, to avoid notebooks whose contents change on each run since they often lead to git merge conflicts. For example:\n&lt;PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FB4F8979690&gt;\nbecomes:\n&lt;PIL.PngImagePlugin.PngImageFile image mode=L size=28x28&gt;\n\nsource\n\n\nprocess_write\n\n process_write (warn_msg, proc_nb, f_in, f_out=None, disp=False)\n\n\nsource\n\n\nnbdev_clean\n\n nbdev_clean (fname:str=None, clear_all:bool=False, disp:bool=False,\n              stdin:bool=False)\n\nClean all notebooks in fname to avoid merge conflicts\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to clean\n\n\nclear_all\nbool\nFalse\nRemove all cell metadata and cell outputs?\n\n\ndisp\nbool\nFalse\nPrint the cleaned outputs\n\n\nstdin\nbool\nFalse\nRead notebook from input stream\n\n\n\nBy default (fname left to None), all the notebooks in config.nbs_path are cleaned. You can opt in to fully clean the notebook by removing every bit of metadata and the cell outputs by passing clear_all=True.\nIf you want to keep some keys in the main notebook metadata you can set allowed_metadata_keys in settings.ini. Similarly for cell level metadata use: allowed_cell_metadata_keys. For example, to preserve both k1 and k2 at both the notebook and cell level adding the following in settings.ini:\n...\nallowed_metadata_keys = k1 k2\nallowed_cell_metadata_keys = k1 k2\n...\n\nsource\n\n\nclean_jupyter\n\n clean_jupyter (path, model, **kwargs)\n\nClean Jupyter model pre save to path\nThis cleans notebooks on-save to avoid unnecessary merge conflicts. The easiest way to install it for both Jupyter Notebook and Lab is by running nbdev_install_hooks. It works by implementing a pre_save_hook from Jupyter’s file save hook API.",
    "crumbs": [
      "Get Started",
      "API",
      "clean"
    ]
  },
  {
    "objectID": "api/clean.html#hooks",
    "href": "api/clean.html#hooks",
    "title": "clean",
    "section": "Hooks",
    "text": "Hooks\n\nsource\n\nnbdev_install_hooks\n\n nbdev_install_hooks ()\n\nInstall Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nSee clean_jupyter and nbdev_merge for more about how each hook works.",
    "crumbs": [
      "Get Started",
      "API",
      "clean"
    ]
  },
  {
    "objectID": "api/frontmatter.html",
    "href": "api/frontmatter.html",
    "title": "frontmatter",
    "section": "",
    "text": "source\n\nFrontmatterProc\n\n FrontmatterProc (nb)\n\nA YAML and formatted-markdown frontmatter processor\nYAML frontmatter can be added to notebooks in one of two ways:\n\nBy adding a raw notebook cell with --- as the first and last lines, and YAML between them, or\nA specially formatted markdown cell. The first line should be start with a single # (creating an H1 heading), and becomes the title. Then, optionally, a line beginning with &gt; (creating a quote block), which becomes the description. Finally, zero or more lines beginning with - (creating a list), each of which contains YAML. (If you already have “title” defined in frontmatter in a raw cell, then markdown cells will be ignored.)\n\nFor instance, our test notebook contains the following markdown cell:\n# a title\n&gt; A description\n- key1: value1\n- key2: value2\n- categories: [c1, c2]\nIt also contains the following raw cell:\n---\nexecute:\n  echo: false\n---\nWhen we process with FrontmatterProc, these will both be removed, and a single raw cell will be added to the top, containing the combined YAML frontmatter:\n\nnbp = NBProcessor(_test_file, procs=FrontmatterProc)\nnbp.process()\nprint(nbp.nb.cells[0].source)\n\n---\ncategories:\n- c1\n- c2\ndescription: A description\nexecute:\n  echo: false\nkey1: value1\nkey2: value2\noutput-file: docs_test.html\ntitle: a title\n\n---\n\n\n\n\nIn addition, a frontmatter_ attr will be added to the notebook, containing this information as a dict:\n\nd = nbp.nb.frontmatter_\nd\n\n{'execute': {'echo': False},\n 'title': 'a title',\n 'description': 'A description',\n 'key1': 'value1',\n 'key2': 'value2',\n 'categories': ['c1', 'c2'],\n 'output-file': 'docs_test.html'}",
    "crumbs": [
      "Get Started",
      "API",
      "frontmatter"
    ]
  },
  {
    "objectID": "api/doclinks.html",
    "href": "api/doclinks.html",
    "title": "doclinks",
    "section": "",
    "text": "source\n\n\n\n patch_name (o)\n\nIf o is decorated with patch or patch_to, return its class-prefix name\n\ndef _test_patch(code): return patch_name(ast.parse(code).body[0])\ns = \"@patch\\ndef _f(self:_T): ...\"\ntest_eq('_T._f', _test_patch(s))\n\n\ns = \"@patch_to(_T)\\ndef _g(self): ...\"\ntest_eq('_T._g', _test_patch(s))\n\n\n# Get all patched classes when patching with a union\ns = \"@patch\\ndef _f(self:_T|_U|_V): ...\"\ntest_eq(_test_patch(s), ['_T._f', '_U._f', '_V._f'])\n\n\n# _build_modidx()",
    "crumbs": [
      "Get Started",
      "API",
      "doclinks"
    ]
  },
  {
    "objectID": "api/doclinks.html#create-the-module-index",
    "href": "api/doclinks.html#create-the-module-index",
    "title": "doclinks",
    "section": "",
    "text": "source\n\n\n\n patch_name (o)\n\nIf o is decorated with patch or patch_to, return its class-prefix name\n\ndef _test_patch(code): return patch_name(ast.parse(code).body[0])\ns = \"@patch\\ndef _f(self:_T): ...\"\ntest_eq('_T._f', _test_patch(s))\n\n\ns = \"@patch_to(_T)\\ndef _g(self): ...\"\ntest_eq('_T._g', _test_patch(s))\n\n\n# Get all patched classes when patching with a union\ns = \"@patch\\ndef _f(self:_T|_U|_V): ...\"\ntest_eq(_test_patch(s), ['_T._f', '_U._f', '_V._f'])\n\n\n# _build_modidx()",
    "crumbs": [
      "Get Started",
      "API",
      "doclinks"
    ]
  },
  {
    "objectID": "api/doclinks.html#export-a-notebook",
    "href": "api/doclinks.html#export-a-notebook",
    "title": "doclinks",
    "section": "Export a notebook",
    "text": "Export a notebook\n\nsource\n\nnbglob\n\n nbglob (path=None, skip_folder_re='^[_.]', file_glob='*.ipynb',\n         skip_file_re='^[_.]', key='nbs_path', as_path=False,\n         recursive:bool=True, symlinks:bool=True, file_re:str=None,\n         folder_re:str=None, skip_file_glob:str=None,\n         func:callable=&lt;function join&gt;, ret_folders:bool=False)\n\nFind all files in a directory matching an extension given a config key.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\npathlib.Path | str\n\npath to start searching\n\n\nskip_folder_re\nstr\nNone\nSkip folders matching regex,\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex\n\n\nkey\nstr\nnbs_path\n\n\n\nas_path\nbool\nFalse\n\n\n\nrecursive\nbool\nTrue\nsearch subfolders\n\n\nsymlinks\nbool\nTrue\nfollow symlinks?\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nfunc\ncallable\njoin\nfunction to apply to each matched file\n\n\nret_folders\nbool\nFalse\nreturn folders, not just files\n\n\nReturns\nL\n\nPaths to matched files\n\n\n\n\nsource\n\n\nnbglob_cli\n\n nbglob_cli (path:str=None, symlinks:bool=False, file_glob:str='*.ipynb',\n             file_re:str=None, folder_re:str=None,\n             skip_file_glob:str=None, skip_file_re:str='^[_.]',\n             skip_folder_re:str='^[_.]')\n\nFind all files in a directory matching an extension given a config key.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_glob\nstr\n*.ipynb\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\nsource\n\n\nnbdev_export\n\n nbdev_export (path:str=None,\n               procs:&lt;tokensnamingtheexportprocessorstouse.&gt;='black_format\n               ', symlinks:bool=False, file_glob:str='*.ipynb',\n               file_re:str=None, folder_re:str=None,\n               skip_file_glob:str=None, skip_file_re:str='^[_.]',\n               skip_folder_re:str='^[_.]')\n\nExport notebooks in path to Python modules\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath or filename\n\n\nprocs\n&lt;tokens naming the export processors to use.&gt;\nblack_format\n\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_glob\nstr\n*.ipynb\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\nprocs names the optional processors you wish to run on the exported cells of your notebook.\nN.B.: the black_format processor is passed in by default. But it is a no-op, unless black_formatting=True is set in your settings.ini configuration. You can omit it from nbdev_export on the command line by passing in --procs.",
    "crumbs": [
      "Get Started",
      "API",
      "doclinks"
    ]
  },
  {
    "objectID": "api/doclinks.html#query-the-module-index",
    "href": "api/doclinks.html#query-the-module-index",
    "title": "doclinks",
    "section": "Query the module index",
    "text": "Query the module index\n\nsource\n\nNbdevLookup\n\n NbdevLookup (strip_libs=None, incl_libs=None, skip_mods=None)\n\nMapping from symbol names to docs and source URLs\nIndexing returns a link to the symbol’s docs, along with the name of the source file the source URL if available.\n\nc = NbdevLookup()\nc['nbdev.doclinks.NbdevLookup']\n\n('https://nbdev.fast.ai/api/doclinks.html#nbdevlookup',\n 'nbdev/doclinks.py',\n 'https://github.com/fastai/nbdev/blob/master/nbdev/doclinks.py')\n\n\n\nsource\n\n\nNbdevLookup.doc\n\n NbdevLookup.doc (sym)\n\nLink to docs for sym\n\nc.doc('nbdev.doclinks.NbdevLookup')\n\n'https://nbdev.fast.ai/api/doclinks.html#nbdevlookup'\n\n\nSymbol names are taken from libraries registered using the ‘nbdev’ entry point. By default, all libraries with this entry point are searched, but full symbol names (including module prefix) are required.\n\nassert c.doc('numpy.array').startswith('http')\nassert c.doc('NbdevLookup').endswith('#nbdevlookup')\nassert not c.doc('array')\n\nPass strip_libs to list libraries which should be available without requiring a module prefix.\n\nc = NbdevLookup(strip_libs=('nbdev', 'nbdev_numpy'))\nassert c.doc('array').startswith('http')\n\n\nsource\n\n\nNbdevLookup.code\n\n NbdevLookup.code (sym)\n\nLink to source code for sym\n\nNbdevLookup().code('fastcore.net.urlsend')\n\n'https://github.com/fastai/fastcore/blob/master/fastcore/net.py#LNone'\n\n\n\nsource\n\n\nNbdevLookup.linkify\n\n NbdevLookup.linkify (md)\n\n\nmd = \"\"\"This is a link to `numpy.array` and to `get_config` but not a link to `foobar`.\nAnd not a link to &lt;code&gt;dict2nb&lt;/code&gt;.\n\n    This is not a link to `get_config`\n\n```\nThis isn't a link to `get_config` either\n```\"\"\"\n\n\nprint(NbdevLookup('nbdev').linkify(md))\n\nThis is a link to [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array) and to [`get_config`](https://nbdev.fast.ai/api/config.html#get_config) but not a link to `foobar`.\nAnd not a link to &lt;code&gt;dict2nb&lt;/code&gt;.\n\n    This is not a link to `get_config`\n\n```\nThis isn't a link to `get_config` either\n```",
    "crumbs": [
      "Get Started",
      "API",
      "doclinks"
    ]
  },
  {
    "objectID": "api/export.html",
    "href": "api/export.html",
    "title": "export",
    "section": "",
    "text": "source\n\nExportModuleProc\n\n ExportModuleProc ()\n\nA processor which exports code to a module\nSpecify dest where the module(s) will be exported to, and optionally a class to use to create the module (ModuleMaker, by default).\nExported cells are stored in a dict called modules, where the keys are the modules exported to. Those without an explicit module are stored in the '#' key, which will be exported to default_exp.\n\neverything_fn = '../../tests/01_everything.ipynb'\n\nexp = ExportModuleProc()\nproc = NBProcessor(everything_fn, exp)\nproc.process()\ntest_eq(exp.default_exp, 'everything')\nassert 'print_function'  in exp.modules['#'][1].source\nassert 'h_n' in exp.in_all['some.thing'][0].source\n\n\n\nOptional export processors\n\nsource\n\n\nblack_format\n\n black_format (cell, force=False)\n\nProcessor to format code with black\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncell\n\n\nCell to format\n\n\nforce\nbool\nFalse\nTurn black formatting on regardless of settings.ini\n\n\n\n\n_cell = read_nb('../../tests/export_procs.ipynb')['cells'][0]\nblack_format(_cell, force=True)\ntest_eq(_cell.source, 'j = [1, 2, 3]')\n\n\nsource\n\n\nscrub_magics\n\n scrub_magics (cell)\n\nProcessor to remove cell magics from exported code\n\n\n\n\nDetails\n\n\n\n\ncell\nCell to format\n\n\n\nscrub_magics is a processor that scrubs the jupyter “magics” lines out of exported cells. This can be helpful when using tools like sparkmagic or just Jupyter’s builtin magics in an nbdev project.\nUsage:\nThis behavior can be enabled by passing scrub_magics into the --procs flag of the nbdev_export command. - nbdev_export --procs scrub_magics - nbdev_export --procs 'scrub_magics black_format'\nExample:\nA cell like below could export the line \"hello nbdev\" into the bar module. And the %%spark magic line would be omitted.\n%%spark\n#|export bar\n\"hello nbdev\"\nIt will export as something similar to this:\n# %% ../path/to/01_bar.ipynb 1\n\"hello nbdev\"\n\n_cell = read_nb('../../tests/export_procs.ipynb')['cells'][2]\nscrub_magics(_cell)\ntest_eq(_cell.source, '''#|export bar\n\"hello nbdev\"''')\n\n\nsource\n\n\noptional_procs\n\n optional_procs ()\n\nAn explicit list of processors that could be used by nb_export\n\n# every optional processor should be explicitly listed here\ntest_eq(optional_procs(), ['black_format', 'scrub_magics'])\n\n\n\nnb_export\n\nsource\n\n\nnb_export\n\n nb_export (nbname:str, lib_path:str=None, procs=None, name:str=None,\n            mod_maker=&lt;class 'nbdev.maker.ModuleMaker'&gt;, debug:bool=False)\n\nCreate module(s) from notebook\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnbname\nstr\n\nFilename of notebook\n\n\nlib_path\nstr\nNone\nPath to destination library. If not in a nbdev project, defaults to current directory.\n\n\nprocs\nNoneType\nNone\nProcessors to use\n\n\nname\nstr\nNone\nName of python script {name}.py to create.\n\n\nmod_maker\ntype\nModuleMaker\n\n\n\ndebug\nbool\nFalse\nDebug mode\n\n\n\nLet’s check we can import a test file:\n\nshutil.rmtree('tmp', ignore_errors=True)\nnb_export('../../tests/00_some.thing.ipynb', 'tmp')\n\ng = exec_new('import tmp.some.thing')\ntest_eq(g['tmp'].some.thing.__all__, ['a'])\ntest_eq(g['tmp'].some.thing.a, 1)\n\nWe’ll also check that our ‘everything’ file exports correctly:\n\nnb_export(everything_fn, 'tmp')\n\ng = exec_new('import tmp.everything; from tmp.everything import *')\n_alls = L(\"a b d e m n o p q\".split())\nfor s in _alls.map(\"{}_y\"): assert s in g, s\nfor s in \"c_y_nall _f_y_nall g_n h_n i_n j_n k_n l_n\".split(): assert s not in g, s\nfor s in _alls.map(\"{}_y\") + [\"c_y_nall\", \"_f_y_nall\"]: assert hasattr(g['tmp'].everything,s), s\n\nThat notebook should also export one extra function to tmp.some.thing:\n\ndel(sys.modules['tmp.some.thing']) # remove from module cache\ng = exec_new('import tmp.some.thing')\ntest_eq(g['tmp'].some.thing.__all__, ['a','h_n'])\ntest_eq(g['tmp'].some.thing.h_n(), None)\n\n\nPath('../nbdev/export.py').unlink(missing_ok=True)\nnb_export('04_export.ipynb')\n\ng = exec_new('import nbdev.export')\nassert hasattr(g['nbdev'].export, 'nb_export')",
    "crumbs": [
      "Get Started",
      "API",
      "export"
    ]
  },
  {
    "objectID": "api/migrate.html",
    "href": "api/migrate.html",
    "title": "migrate",
    "section": "",
    "text": "source",
    "crumbs": [
      "Get Started",
      "API",
      "migrate"
    ]
  },
  {
    "objectID": "api/migrate.html#convert-nbdev-v1-projects-to-nbdev-v2",
    "href": "api/migrate.html#convert-nbdev-v1-projects-to-nbdev-v2",
    "title": "migrate",
    "section": "Convert nbdev v1 projects to nbdev v2",
    "text": "Convert nbdev v1 projects to nbdev v2\n\nDirectives\nnbdev v2 directives start with a #| whereas v1 directives were comments without a pipe |.\n\n_test_dir = \"\"\"\n#default_exp\n #export\n# collapse-show\n#collapse-hide\n#collapse\n# collapse_output\nnot_dir='#export'\n# hide_input\nfoo\n# hide\n\"\"\"\ntest_eq(_repl_directives(_test_dir),\n\"\"\"\n#| default_exp\n#| export\n#| code-fold: show\n#| code-fold: true\n#| code-fold: true\n# collapse_output\nnot_dir='#export'\n#| echo: false\nfoo\n#| include: false\n\"\"\")\n\n\nsource\n\n\n_repl_v1dir\n\n _repl_v1dir (cell)\n\nReplace nbdev v1 with v2 directives.\nfor example, if any of the lines below are valid nbdev v1 directives, they replaced with a #|, but only before the first line of code:",
    "crumbs": [
      "Get Started",
      "API",
      "migrate"
    ]
  },
  {
    "objectID": "api/migrate.html#callouts",
    "href": "api/migrate.html#callouts",
    "title": "migrate",
    "section": "Callouts",
    "text": "Callouts\nIn fastpages, there was a markdown shortuct for callouts for Note, Tip, Important and Warning with block quotes (these only worked in notebooks). Since Quarto has its own callout blocks with markdown syntax, we do not implement these shortcuts in nbdev. Instead, we offer a manual conversion utility for these callouts so that you can migrate from fastpages to Quarto.\n\nsource\n\n_convert_callout\n\n _convert_callout (s)\n\nConvert nbdev v1 to v2 callouts.\nFor example, the below markdown:\n\n_callouts=\"\"\"\n## Boxes / Callouts\n\n&gt; Warning: There will be no second warning!\n\nOther text\n\n&gt; Important: Pay attention! It's important.\n\n&gt; Tip: This is my tip.\n\n&gt; Note: Take note of `this.`\n\"\"\"\n\nGets converted to:\n\n\n\n## Boxes / Callouts\n\n:::{.callout-warning}\n\nThere will be no second warning!\n\n:::\n\nOther text\n\n:::{.callout-important}\n\nPay attention! It's important.\n\n:::",
    "crumbs": [
      "Get Started",
      "API",
      "migrate"
    ]
  },
  {
    "objectID": "api/migrate.html#video-embeds",
    "href": "api/migrate.html#video-embeds",
    "title": "migrate",
    "section": "Video Embeds",
    "text": "Video Embeds\nIn fastpages, you could embed videos with a simple markdown shortcut involving a block quote with the prefix youtube:, that looked like this\n&gt; youtube: https://youtu.be/XfoYk_Z5AkI\nHowever, in Quarto you can use the video extension to embed videos.\n\nsource\n\n_convert_video\n\n _convert_video (s)\n\nReplace nbdev v1 with v2 video embeds.\n\n_videos=\"\"\"\n## Videos\n\n&gt; youtube: https://youtu.be/XfoYk_Z5AkI\n\"\"\"\n\n\nprint(_convert_video(_videos))\n\n\n## Videos\n\n\n\n\n\n\nsource\n\n\nmigrate_nb\n\n migrate_nb (path, overwrite=True)\n\nMigrate Notebooks from nbdev v1 and fastpages.\n\nsource\n\n\nmigrate_md\n\n migrate_md (path, overwrite=True)\n\nMigrate Markdown Files from fastpages.\n\nsource\n\n\nnbdev_migrate\n\n nbdev_migrate (path:str=None, no_skip:bool=False)\n\nConvert all markdown and notebook files in path from v1 to v2\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nA path or glob containing notebooks and markdown files to migrate\n\n\nno_skip\nbool\nFalse\nDo not skip directories beginning with an underscore",
    "crumbs": [
      "Get Started",
      "API",
      "migrate"
    ]
  },
  {
    "objectID": "api/sync.html",
    "href": "api/sync.html",
    "title": "sync",
    "section": "",
    "text": "The library is primarily developed in notebooks so any big changes should be made there. But sometimes, it’s easier to fix small bugs or typos in the modules directly. nbdev_update is the function that will propagate those changes back to the corresponding notebooks. Note that you can’t create new cells or reorder cells with that functionality, so your corrections should remain limited.\n\nsource\n\nabsolute_import\n\n absolute_import (name, fname, level)\n\nUnwarps a relative import in name according to fname\n\ntest_eq(absolute_import('xyz', 'nbdev', 0), 'xyz')\ntest_eq(absolute_import('', 'nbdev', 1), 'nbdev')\ntest_eq(absolute_import(None, 'nbdev', 1), 'nbdev')\ntest_eq(absolute_import('core', 'nbdev', 1), 'nbdev.core')\ntest_eq(absolute_import('core', 'nbdev/vision', 2), 'nbdev.core')  # from ..core import *\ntest_eq(absolute_import('transform', 'nbdev/vision', 1), 'nbdev.vision.transform')  # from .transform import *\ntest_eq(absolute_import('notebook.core', 'nbdev/data', 2), 'nbdev.notebook.core')  # from ..notebook.core import *\n\n\nsource\n\n\nnbdev_update\n\n nbdev_update (fname:str=None)\n\nPropagate change in modules matching fname to notebooks that created them\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA Python file name to update",
    "crumbs": [
      "Get Started",
      "API",
      "sync"
    ]
  },
  {
    "objectID": "api/config.html",
    "href": "api/config.html",
    "title": "config",
    "section": "",
    "text": "nbdev is heavily customizeable, thanks to the configuration system defined in this module. There are 2 ways to interact with nbdev’s config:\n\nIn the terminal: nbdev_create_config creates a config file (if you’re starting a new project use nbdev_new instead)\nIn your library: get_config returns a fastcore.foundation.Config object.\n\nRead on for more about how these work.\n\nsource\n\n\n\n nbdev_create_config (repo:str=None, branch:str=None, user:str=None,\n                      author:str=None, author_email:str=None,\n                      description:str=None, path:str='.',\n                      cfg_name:str='settings.ini', lib_name='%(repo)s',\n                      git_url='https://github.com/%(user)s/%(repo)s',\n                      custom_sidebar:&lt;function bool_arg&gt;=False,\n                      nbs_path:pathlib.Path='nbs',\n                      lib_path:pathlib.Path=None,\n                      doc_path:pathlib.Path='_docs', tst_flags='notest',\n                      version='0.0.1',\n                      doc_host='https://%(user)s.github.io',\n                      doc_baseurl='/%(repo)s', keywords='nbdev jupyter\n                      notebook python', license='apache2',\n                      copyright:str=None, status='3', min_python='3.7',\n                      audience='Developers', language='English',\n                      recursive:&lt;function bool_arg&gt;=True,\n                      black_formatting:&lt;function bool_arg&gt;=False,\n                      readme_nb='index.ipynb', title='%(lib_name)s',\n                      allowed_metadata_keys='',\n                      allowed_cell_metadata_keys='',\n                      jupyter_hooks:&lt;function bool_arg&gt;=False,\n                      clean_ids:&lt;function bool_arg&gt;=True,\n                      clear_all:&lt;function bool_arg&gt;=False,\n                      cell_number:&lt;function bool_arg&gt;=True,\n                      put_version_in_init:&lt;function bool_arg&gt;=True,\n                      skip_procs:str='')\n\nCreate a config file.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepo\nstr\nNone\nRepo name\n\n\nbranch\nstr\nNone\nRepo default branch\n\n\nuser\nstr\nNone\nRepo username\n\n\nauthor\nstr\nNone\nPackage author’s name\n\n\nauthor_email\nstr\nNone\nPackage author’s email address\n\n\ndescription\nstr\nNone\nShort summary of the package\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nlib_name\nstr\n%(repo)s\nPackage name\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(repo)s\nRepo URL\n\n\ncustom_sidebar\nbool_arg\nFalse\nUse a custom sidebar.yml?\n\n\nnbs_path\nPath\nnbs\nPath to notebooks\n\n\nlib_path\nPath\nNone\nPath to package root (default: repo with - replaced by _)\n\n\ndoc_path\nPath\n_docs\nPath to rendered docs\n\n\ntst_flags\nstr\nnotest\nTest flags\n\n\nversion\nstr\n0.0.1\nVersion of this release\n\n\ndoc_host\nstr\nhttps://%(user)s.github.io\nHostname for docs\n\n\ndoc_baseurl\nstr\n/%(repo)s\nBase URL for docs\n\n\nkeywords\nstr\nnbdev jupyter notebook python\nPackage keywords\n\n\nlicense\nstr\napache2\nLicense for the package\n\n\ncopyright\nstr\nNone\nCopyright for the package, defaults to ‘current_year onwards, author’\n\n\nstatus\nstr\n3\nDevelopment status PyPI classifier\n\n\nmin_python\nstr\n3.7\nMinimum Python version PyPI classifier\n\n\naudience\nstr\nDevelopers\nIntended audience PyPI classifier\n\n\nlanguage\nstr\nEnglish\nLanguage PyPI classifier\n\n\nrecursive\nbool_arg\nTrue\nInclude subfolders in notebook globs?\n\n\nblack_formatting\nbool_arg\nFalse\nFormat libraries with black?\n\n\nreadme_nb\nstr\nindex.ipynb\nNotebook to export as repo readme\n\n\ntitle\nstr\n%(lib_name)s\nQuarto website title\n\n\nallowed_metadata_keys\nstr\n\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nstr\n\nPreserve the list of keys in cell level metadata\n\n\njupyter_hooks\nbool_arg\nFalse\nRun Jupyter hooks?\n\n\nclean_ids\nbool_arg\nTrue\nRemove ids from plaintext reprs?\n\n\nclear_all\nbool_arg\nFalse\nRemove all cell metadata and cell outputs?\n\n\ncell_number\nbool_arg\nTrue\nAdd cell number to the exported file\n\n\nput_version_in_init\nbool_arg\nTrue\nAdd the version to the main init.py in nbdev_export\n\n\nskip_procs\nstr\n\nA comma-separated list of processors that you want to skip\n\n\n\nThe table above also serves as a full reference of nbdev’s settings (excluding the path and cfg_name parameters which decide where the config file is saved). For more about PyPI classifiers, see Classifiers.\nYou can create a config file by passing all of the required settings via the command line, as well as any optional settings you’d like to override, for example:\nnbdev_create_config --repo nbdev --user fastai --author fastai \\\n                    --author_email info@fast.ai --description 'A test project'\nIf you don’t provide required settings from the command line, we’ll try to to infer them from git and GitHub. Finally, you’ll be asked to manually input any required settings that we couldn’t automatically fill in.\n\nsource\n\n\n\n\n get_config (cfg_name='settings.ini', path=None)\n\nReturn nbdev config.\nSearches up from path until cfg_name is found. User settings are loaded from ~/.config/nbdev/{cfg_name}. Unspecified optional settings return defaults.\nSee nbdev_create_config for a full reference of nbdev’s settings.\n\ncfg = get_config()\n\ncfg is a fastcore Config object, so you can access keys as attributes:\n\np = Path.cwd().parent.parent\ntest_eq(cfg.lib_name, 'nbdev')\ntest_eq(cfg.git_url, 'https://github.com/fastai/nbdev')\n\nIts own path and parent are attributes too:\n\ntest_eq(cfg.config_path, p)\ntest_eq(cfg.config_file, p/'settings.ini')\n\nPaths are relative to the project:\n\ntest_eq(cfg.doc_path, p/'_docs')\ntest_eq(cfg.lib_path, p/'nbdev')\ntest_eq(cfg.nbs_path, p/'nbs')\n\nIt automatically returns defaults for keys not specified in the config file. Here we create an empty config file and access lib_path and copyright even though they weren’t explicitly defined:\n\nwith tempfile.TemporaryDirectory() as d, working_directory(d):\n    Config('.', 'test_settings.ini', {'repo': 'my-project', 'author': 'fastai', 'nbs_path': 'nbs'});\n    cfg = get_config('test_settings.ini', '.')\n    test_eq(cfg.repo, 'my-project')\n    test_eq(cfg.lib_path.name, 'my_project')\n\nIn fact, you can return a default config even if you don’t have a settings file. This is to support certain nbdev commands work outside of nbdev repos:\n\ncfg = get_config('test_settings.ini', '.')\ntest_eq(cfg.lib_path, Path('nbdev').resolve())\ntest_eq(cfg.nbs_path, Path('nbs').resolve())\n\nYou can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file (by default, although we follow the broader XDG specification). For example, you could globally disable nbdev’s Jupyter hooks by creating a user settings file with jupyter_hooks = False.\n\nsource\n\n\n\n\n config_key (c, default=None, path=True, missing_ok=None)\n\nDeprecated: use get_config().get or get_config().path instead.",
    "crumbs": [
      "Get Started",
      "API",
      "config"
    ]
  },
  {
    "objectID": "api/config.html#configuring-nbdev",
    "href": "api/config.html#configuring-nbdev",
    "title": "config",
    "section": "",
    "text": "nbdev is heavily customizeable, thanks to the configuration system defined in this module. There are 2 ways to interact with nbdev’s config:\n\nIn the terminal: nbdev_create_config creates a config file (if you’re starting a new project use nbdev_new instead)\nIn your library: get_config returns a fastcore.foundation.Config object.\n\nRead on for more about how these work.\n\nsource\n\n\n\n nbdev_create_config (repo:str=None, branch:str=None, user:str=None,\n                      author:str=None, author_email:str=None,\n                      description:str=None, path:str='.',\n                      cfg_name:str='settings.ini', lib_name='%(repo)s',\n                      git_url='https://github.com/%(user)s/%(repo)s',\n                      custom_sidebar:&lt;function bool_arg&gt;=False,\n                      nbs_path:pathlib.Path='nbs',\n                      lib_path:pathlib.Path=None,\n                      doc_path:pathlib.Path='_docs', tst_flags='notest',\n                      version='0.0.1',\n                      doc_host='https://%(user)s.github.io',\n                      doc_baseurl='/%(repo)s', keywords='nbdev jupyter\n                      notebook python', license='apache2',\n                      copyright:str=None, status='3', min_python='3.7',\n                      audience='Developers', language='English',\n                      recursive:&lt;function bool_arg&gt;=True,\n                      black_formatting:&lt;function bool_arg&gt;=False,\n                      readme_nb='index.ipynb', title='%(lib_name)s',\n                      allowed_metadata_keys='',\n                      allowed_cell_metadata_keys='',\n                      jupyter_hooks:&lt;function bool_arg&gt;=False,\n                      clean_ids:&lt;function bool_arg&gt;=True,\n                      clear_all:&lt;function bool_arg&gt;=False,\n                      cell_number:&lt;function bool_arg&gt;=True,\n                      put_version_in_init:&lt;function bool_arg&gt;=True,\n                      skip_procs:str='')\n\nCreate a config file.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepo\nstr\nNone\nRepo name\n\n\nbranch\nstr\nNone\nRepo default branch\n\n\nuser\nstr\nNone\nRepo username\n\n\nauthor\nstr\nNone\nPackage author’s name\n\n\nauthor_email\nstr\nNone\nPackage author’s email address\n\n\ndescription\nstr\nNone\nShort summary of the package\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nlib_name\nstr\n%(repo)s\nPackage name\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(repo)s\nRepo URL\n\n\ncustom_sidebar\nbool_arg\nFalse\nUse a custom sidebar.yml?\n\n\nnbs_path\nPath\nnbs\nPath to notebooks\n\n\nlib_path\nPath\nNone\nPath to package root (default: repo with - replaced by _)\n\n\ndoc_path\nPath\n_docs\nPath to rendered docs\n\n\ntst_flags\nstr\nnotest\nTest flags\n\n\nversion\nstr\n0.0.1\nVersion of this release\n\n\ndoc_host\nstr\nhttps://%(user)s.github.io\nHostname for docs\n\n\ndoc_baseurl\nstr\n/%(repo)s\nBase URL for docs\n\n\nkeywords\nstr\nnbdev jupyter notebook python\nPackage keywords\n\n\nlicense\nstr\napache2\nLicense for the package\n\n\ncopyright\nstr\nNone\nCopyright for the package, defaults to ‘current_year onwards, author’\n\n\nstatus\nstr\n3\nDevelopment status PyPI classifier\n\n\nmin_python\nstr\n3.7\nMinimum Python version PyPI classifier\n\n\naudience\nstr\nDevelopers\nIntended audience PyPI classifier\n\n\nlanguage\nstr\nEnglish\nLanguage PyPI classifier\n\n\nrecursive\nbool_arg\nTrue\nInclude subfolders in notebook globs?\n\n\nblack_formatting\nbool_arg\nFalse\nFormat libraries with black?\n\n\nreadme_nb\nstr\nindex.ipynb\nNotebook to export as repo readme\n\n\ntitle\nstr\n%(lib_name)s\nQuarto website title\n\n\nallowed_metadata_keys\nstr\n\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nstr\n\nPreserve the list of keys in cell level metadata\n\n\njupyter_hooks\nbool_arg\nFalse\nRun Jupyter hooks?\n\n\nclean_ids\nbool_arg\nTrue\nRemove ids from plaintext reprs?\n\n\nclear_all\nbool_arg\nFalse\nRemove all cell metadata and cell outputs?\n\n\ncell_number\nbool_arg\nTrue\nAdd cell number to the exported file\n\n\nput_version_in_init\nbool_arg\nTrue\nAdd the version to the main init.py in nbdev_export\n\n\nskip_procs\nstr\n\nA comma-separated list of processors that you want to skip\n\n\n\nThe table above also serves as a full reference of nbdev’s settings (excluding the path and cfg_name parameters which decide where the config file is saved). For more about PyPI classifiers, see Classifiers.\nYou can create a config file by passing all of the required settings via the command line, as well as any optional settings you’d like to override, for example:\nnbdev_create_config --repo nbdev --user fastai --author fastai \\\n                    --author_email info@fast.ai --description 'A test project'\nIf you don’t provide required settings from the command line, we’ll try to to infer them from git and GitHub. Finally, you’ll be asked to manually input any required settings that we couldn’t automatically fill in.\n\nsource\n\n\n\n\n get_config (cfg_name='settings.ini', path=None)\n\nReturn nbdev config.\nSearches up from path until cfg_name is found. User settings are loaded from ~/.config/nbdev/{cfg_name}. Unspecified optional settings return defaults.\nSee nbdev_create_config for a full reference of nbdev’s settings.\n\ncfg = get_config()\n\ncfg is a fastcore Config object, so you can access keys as attributes:\n\np = Path.cwd().parent.parent\ntest_eq(cfg.lib_name, 'nbdev')\ntest_eq(cfg.git_url, 'https://github.com/fastai/nbdev')\n\nIts own path and parent are attributes too:\n\ntest_eq(cfg.config_path, p)\ntest_eq(cfg.config_file, p/'settings.ini')\n\nPaths are relative to the project:\n\ntest_eq(cfg.doc_path, p/'_docs')\ntest_eq(cfg.lib_path, p/'nbdev')\ntest_eq(cfg.nbs_path, p/'nbs')\n\nIt automatically returns defaults for keys not specified in the config file. Here we create an empty config file and access lib_path and copyright even though they weren’t explicitly defined:\n\nwith tempfile.TemporaryDirectory() as d, working_directory(d):\n    Config('.', 'test_settings.ini', {'repo': 'my-project', 'author': 'fastai', 'nbs_path': 'nbs'});\n    cfg = get_config('test_settings.ini', '.')\n    test_eq(cfg.repo, 'my-project')\n    test_eq(cfg.lib_path.name, 'my_project')\n\nIn fact, you can return a default config even if you don’t have a settings file. This is to support certain nbdev commands work outside of nbdev repos:\n\ncfg = get_config('test_settings.ini', '.')\ntest_eq(cfg.lib_path, Path('nbdev').resolve())\ntest_eq(cfg.nbs_path, Path('nbs').resolve())\n\nYou can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file (by default, although we follow the broader XDG specification). For example, you could globally disable nbdev’s Jupyter hooks by creating a user settings file with jupyter_hooks = False.\n\nsource\n\n\n\n\n config_key (c, default=None, path=True, missing_ok=None)\n\nDeprecated: use get_config().get or get_config().path instead.",
    "crumbs": [
      "Get Started",
      "API",
      "config"
    ]
  },
  {
    "objectID": "api/config.html#helpers",
    "href": "api/config.html#helpers",
    "title": "config",
    "section": "Helpers",
    "text": "Helpers\n\nsource\n\nis_nbdev\n\n is_nbdev ()\n\n\nsource\n\n\ncreate_output\n\n create_output (txt, mime)\n\nAdd a cell output containing txt of the mime text MIME sub-type\n\nsource\n\n\nshow_src\n\n show_src (src, lang='python')\n\n\nshow_src(\"print(create_output('text', 'text/plain'))\")\n\nprint(create_output('text', 'text/plain'))",
    "crumbs": [
      "Get Started",
      "API",
      "config"
    ]
  },
  {
    "objectID": "api/config.html#exporting-a-basic-module",
    "href": "api/config.html#exporting-a-basic-module",
    "title": "config",
    "section": "Exporting a basic module",
    "text": "Exporting a basic module\n\nsource\n\nadd_init\n\n add_init (path=None)\n\nAdd __init__.py in all subdirs of path containing python files if it’s not there already.\n\nsource\n\n\nupdate_version\n\n update_version (path=None)\n\nAdd or update __version__ in the main __init__.py of the library.\nPython modules require a __init.py__ file in all directories that are modules. We assume that all directories containing a python file (including in subdirectories of any depth) is a module, and therefore add a __init__.py to each.\n\nwith tempfile.TemporaryDirectory() as d:\n    d = Path(d)\n    (d/'a/b').mkdir(parents=True)\n    (d/'a/b/f.py').touch()\n    (d/'a/c').mkdir()\n    add_init(d)\n    assert not (d/'a/c'/_init).exists(), \"Should not add init to dir without py file\"\n    for e in [d, d/'a', d/'a/b']: assert (e/_init).exists(),f\"Missing init in {e}\"\n\n\nsource\n\n\nwrite_cells\n\n write_cells (cells, hdr, file, offset=0, cell_number=True)\n\nWrite cells to file along with header hdr starting at index offset (mainly for nbdev internal use).\nThis is a simple exporter with just enough functionality to correctly export this notebook, in order to bootstrap the creation of nbdev itself.",
    "crumbs": [
      "Get Started",
      "API",
      "config"
    ]
  },
  {
    "objectID": "api/qmd.html",
    "href": "api/qmd.html",
    "title": "qmd",
    "section": "",
    "text": "source\n\nmeta\n\n meta (md, classes=None, style=None, **kwargs)\n\nA metadata section for qmd div in {}\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmd\n\n\nMarkdown to add meta to\n\n\nclasses\nNoneType\nNone\nList of CSS classes to add\n\n\nstyle\nNoneType\nNone\nDict of CSS styles to add\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\ndiv\n\n div (txt, classes=None, style=None, **kwargs)\n\nA qmd div with optional metadata section\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntxt\n\n\nMarkdown to add meta to\n\n\nclasses\nNoneType\nNone\nList of CSS classes to add\n\n\nstyle\nNoneType\nNone\nDict of CSS styles to add\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nimg\n\n img (fname, classes=None, style=None, height=None, relative=None,\n      link=False, **kwargs)\n\nA qmd image\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\n\n\nImage to link to\n\n\nclasses\nNoneType\nNone\nList of CSS classes to add\n\n\nstyle\nNoneType\nNone\nDict of CSS styles to add\n\n\nheight\nNoneType\nNone\nHeight attribute\n\n\nrelative\nNoneType\nNone\nTuple of (position,px)\n\n\nlink\nbool\nFalse\nHyperlink to this image\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nbtn\n\n btn (txt, link, classes=None, style=None, **kwargs)\n\nA qmd button\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntxt\n\n\nButton text\n\n\nlink\n\n\nButton link URL\n\n\nclasses\nNoneType\nNone\nList of CSS classes to add\n\n\nstyle\nNoneType\nNone\nDict of CSS styles to add\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\ntbl_row\n\n tbl_row (cols:list)\n\nCreate a markdown table row from cols\n\n\n\n\nType\nDetails\n\n\n\n\ncols\nlist\nAuto-stringified columns to show in the row\n\n\n\n\nsource\n\n\ntbl_sep\n\n tbl_sep (sizes:int|list=3)\n\nCreate a markdown table separator with relative column size sizes\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsizes\nint | list\n3\nList of column sizes, or single int if all sizes the same",
    "crumbs": [
      "Get Started",
      "API",
      "qmd"
    ]
  },
  {
    "objectID": "api/processors.html",
    "href": "api/processors.html",
    "title": "processors",
    "section": "",
    "text": "On this page we’ll be using this private helper to process a notebook and return the results, to simplify testing:\n\ndef _run_procs(procs=None, return_nb=False, path=_test_file):\n    nbp = NBProcessor(path, procs)\n    nbp.process()\n    if return_nb: return nbp.nb\n    return '\\n'.join([str(cell) for cell in nbp.nb.cells])\n\n\nsource\n\npopulate_language\n\n populate_language (nb)\n\nSet cell language based on NB metadata and magics\n\nsource\n\n\ninsert_warning\n\n insert_warning (nb)\n\nInsert Autogenerated Warning Into Notebook after the first cell.\nThis preprocessor inserts a warning in the markdown destination that the file is autogenerated. This warning is inserted in the second cell so we do not interfere with front matter.\n\nres = _run_procs(insert_warning)\nassert \"&lt;!-- WARNING: THIS FILE WAS AUTOGENERATED!\" in res\n\n\nL('foo', None, 'a').filter(lambda x:x == 1)\n_tstre = re.compile('a')\n\n\nsource\n\n\nadd_show_docs\n\n add_show_docs (nb)\n\nAdd show_doc cells after exported cells, unless they are already documented\n\nsource\n\n\ncell_lang\n\n cell_lang (cell)\n\n\nres = _run_procs([populate_language, add_show_docs])\nassert \"show_doc(some_func)'\" in res\nassert \"show_doc(and_another)'\" in res\nassert \"show_doc(another_func)'\" not in res\n\n\nsource\n\n\nfdiv\n\n fdiv (attrs='')\n\nCreate a fenced div markdown cell in quarto\n\na = fdiv('.py-2')\ntest_eq(a.cell_type, 'markdown')\ntest_eq(a.source, '::: {.py-2}')\n\n\nsource\n\n\nboxify\n\n boxify (cells)\n\nAdd a box around cells\n\nsource\n\n\nmv_exports\n\n mv_exports (nb)\n\nMove exports cells to after the show_doc\n\nsource\n\n\nadd_links\n\n add_links (cell)\n\nAdd links to markdown cells\n\nres = _run_procs(add_links)\nassert \"[`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array)\" in res\nassert \"[`ModuleMaker`](https://nbdev.fast.ai/api/maker.html#modulemaker) but not a link to `foobar`.\" in res\nassert \"A link in a docstring: [`ModuleMaker`](https://nbdev.fast.ai/api/maker.html#modulemaker).\" in res\nassert \"And not a link to &lt;code&gt;dict2nb&lt;/code&gt;.\" in res\n\n\nsource\n\n\nadd_fold\n\n add_fold (cell)\n\nAdd code-fold to exports cells\n\nres = _run_procs(add_fold)\nassert \"#| code-fold: show\" in res\n\nGets rid of colors that are streamed from standard out, which can interfere with static site generators:\n\nsource\n\n\nstrip_ansi\n\n strip_ansi (cell)\n\nStrip Ansi Characters.\n\nres = _run_procs(strip_ansi)\nassert not _re_ansi_escape.findall(res)\n\n\nsource\n\n\nstrip_hidden_metadata\n\n strip_hidden_metadata (cell)\n\nStrips “hidden” metadata property from code cells so it doesn’t interfere with docs rendering\n\nsource\n\n\nhide_\n\n hide_ (cell)\n\nHide cell from output\n\nres = _run_procs(hide_)\nassert 'you will not be able to see this cell at all either' not in res\n\n\nsource\n\n\nhide_line\n\n hide_line (cell)\n\nHide lines of code in code cells with the directive hide_line at the end of a line of code\n\nres = _run_procs(hide_line)\nassert r\"def show():\\n    a = 2\\n    b = 3\" not in res\nassert r\"def show():\\n    a = 2\"                in res\n\n\nsource\n\n\nfilter_stream_\n\n filter_stream_ (cell, *words)\n\nRemove output lines containing any of words in cell stream output\n\nres = _run_procs(filter_stream_)\nexp=r\"'A line\\n', 'Another line.\\n'\"\nassert exp in res\n\n\nsource\n\n\nai_magics\n\n ai_magics (cell)\n\nA preprocessor to convert AI magics to markdown\n\nres = _run_procs(ai_magics)\nassert \"'source': 'This is a test.'\" in res\n\n\nsource\n\n\nclean_magics\n\n clean_magics (cell)\n\nA preprocessor to remove cell magic commands\n\nres = _run_procs(clean_magics)\nassert \"%%\" not in res\n\n\nsource\n\n\nrm_header_dash\n\n rm_header_dash (cell)\n\nRemove headings that end with a dash -\n\nres = _run_procs(rm_header_dash)\nassert 'some words' in res\nassert 'A heading to Hide' not in res\nassert 'Yet another heading to hide' not in res\n\n\nsource\n\n\nrm_export\n\n rm_export (cell)\n\nRemove cells that are exported or hidden\n\nres = _run_procs(rm_export)\nassert 'dontshow' not in res\n\n\nsource\n\n\nclean_show_doc\n\n clean_show_doc (cell)\n\nRemove ShowDoc input cells\n\nsource\n\n\nexec_show_docs\n\n exec_show_docs (nb)\n\nExecute cells needed for show_docs output, including exported cells and imports\n\nres = _run_procs([add_show_docs, exec_show_docs])\nassert res\n\n\nsource\n\n\nFilterDefaults\n\n FilterDefaults ()\n\nOverride FilterDefaults to change which notebook processors are used",
    "crumbs": [
      "Get Started",
      "API",
      "processors"
    ]
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html",
    "href": "blog/posts/2022-11-07-spaces/index.html",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "",
    "text": "Image created with Stable Diffusion from this space\nHugging Face Spaces provides an easy ways to deploy a web app with python. Gradio is one of my favorite tools for building these web apps. For example, the cover-image for this blog post was generated with a Gradio App!1 Gradio also allows you to prototype your web apps in notebooks which allows you to iterate fast. Unfortunately, Hugging Face Spaces requires you to package your web application code as a python script named app.py.\nHowever, thanks to nbdev, you can deploy a Gradio app to Spaces from a notebook without having to refactor your code into a script! When you finish this tutorial, you will have an app that looks like this:\nThe above app allows you to lookup the size of any Hugging Face Dataset, using the Hugging Face Datasets Server API.\nAuthoring your spaces in notebooks offers a number of benefits such as the ability to:\n… All from the same environment!"
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#create-a-gradio-enabled-space-on-hugging-face",
    "href": "blog/posts/2022-11-07-spaces/index.html#create-a-gradio-enabled-space-on-hugging-face",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "1. Create a Gradio-enabled Space on Hugging Face",
    "text": "1. Create a Gradio-enabled Space on Hugging Face\nThe first step is to create a space and select the appropriate sdk (which is Gradio in this example), according to these instructions:\n\n\n\ncreate a Hugging Face Space\n\n\nAfter you are done creating the space, clone the repo locally. In this example, I ran the command git clone https://huggingface.co/spaces/hamel/hfspace_demo."
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#create-a-notebook",
    "href": "blog/posts/2022-11-07-spaces/index.html#create-a-notebook",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "2. Create A Notebook",
    "text": "2. Create A Notebook\nBefore getting started you will want to install the dependencies for this tutorial:\n!pip install git+https://github.com/fastai/nbdev.git gradio fastcore\nCreate a notebook called app.ipynb in the root of your newly cloned repo. Alternatively, download the notebook and follow along.\n\n\n\n\n\n\nDownload the notebook and follow along\n\n\n\nThis blog post is a verbose version of the “notebook” you can use to create a Gradio app. However, it can be useful to see just the code without any of the prose. A concise version of this notebook is here. I recommend taking a look at this notebook during or after you read this blog post."
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#make-an-app-with-gradio",
    "href": "blog/posts/2022-11-07-spaces/index.html#make-an-app-with-gradio",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "3. Make an app with Gradio",
    "text": "3. Make an app with Gradio\nBelow, I will create a gradio app in a notebook and show you how to deploy it to Hugging Face Spaces.\nFirst, lets import the libraries we need, which in this case are gradio and fastcore:\n#|export\nimport gradio as gr\nfrom fastcore.net import urljson, HTTPError\nNext, write the functions your gradio app will use. Because of nbdev, you can prototype and package your code all in one place. The special comment #|export marks which cells will be sent to a python script (more on this later). Note that there are only three cells in this notebook with the #|export directive.\n#|export\ndef size(repo:str):\n    \"Returns the size in GB of a HuggingFace Dataset.\"\n    url = f'https://huggingface.co/api/datasets/{repo}'\n    try: resp = urljson(f'{url}/treesize/main')\n    except HTTPError: return f'Did not find repo: {url}'\n    gb = resp['size'] / 1e9\n    return f'{gb:.2f} GB'\nsize takes as an input a Hugging Face Dataset repo and returns the total size in GB of the data.\nFor example, I can check the size of tglcourse/CelebA-faces-cropped-128 like so:\nsize(\"tglcourse/CelebA-faces-cropped-128\")\n\n'5.49 GB'\n\nYou can construct a simple UI with the gradio.interface and then call the launch method of that interface to display a preview in a notebook. This is a great way to test your app to see if it works:\n#|export\niface = gr.Interface(fn=size, inputs=gr.Text(value=\"tglcourse/CelebA-faces-cropped-128\"), outputs=\"text\")\niface.launch(height=450, width=500)\n\nRunning on local URL:  http://127.0.0.1:7861\n\nTo create a public link, set `share=True` in `launch()`.\n\n\nNote how running the launch() method in a notebook runs a webserver in the background. Below, I call the close() method to close the webserver.\n# this is only necessary in a notebook\niface.close()\n\nClosing server running on port: 7861"
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#convert-this-notebook-into-a-gradio-app",
    "href": "blog/posts/2022-11-07-spaces/index.html#convert-this-notebook-into-a-gradio-app",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "4. Convert This Notebook Into A Gradio App",
    "text": "4. Convert This Notebook Into A Gradio App\nIn order to host this code on Hugging Face Spaces, you will export parts of this notebook to a script named app.py. As a reminder, this is what the special #|export comment that you have seen in cells above do! You can export code from this notebook like so:\nfrom nbdev.export import nb_export\nnb_export('app.ipynb', lib_path='.', name='app')\n\nUnderstanding what is generated\nNotice how the contents of app.py only contain the exported cells from this notebook:\n!cat app.py\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: app.ipynb.\n\n# %% auto 0\n__all__ = ['iface', 'size']\n\n# %% app.ipynb 6\nimport gradio as gr\nfrom fastcore.net import urljson, HTTPError\n\n# %% app.ipynb 8\ndef size(repo:str):\n    \"Returns the size in GB of a HuggingFace Dataset.\"\n    url = f'https://huggingface.co/api/datasets/{repo}'\n    try: resp = urljson(f'{url}/treesize/main')\n    except HTTPError: return f'Did not find repo: {url}'\n    gb = resp['size'] / 1e9\n    return f'{gb:.2f} GB'\n\n# %% app.ipynb 12\niface = gr.Interface(fn=size, inputs=gr.Text(value=\"tglcourse/CelebA-faces-cropped-128\"), outputs=\"text\")\niface.launch(height=450, width=500)\n\n\n\nFill out requirements.txt\nYou must supply a requirements.txt file so the Gradio app knows how to build your dependencies. In this example, the only dependency other than Gradio is fastcore. You don’t need to specify Gradio itself as a dependency in requirements.txt, so our requirements.txt file has only one dependency:\n%%writefile requirements.txt\nfastcore\nWriting requirements.txt\nNote: you may want to add operating system dependencies in addition to python dependencies. You can do this via a packages.txt file as documented here."
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#launch-your-gradio-app",
    "href": "blog/posts/2022-11-07-spaces/index.html#launch-your-gradio-app",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "5. Launch Your Gradio App",
    "text": "5. Launch Your Gradio App\nTo launch your gradio app, you need to commit the changes to the Hugging Face repo:\ngit add -A; git commit -m \"Add application files\"; git push"
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#footnotes",
    "href": "blog/posts/2022-11-07-spaces/index.html#footnotes",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe prompt that generated the cover image is: “A data scientist at a computer in a futuristic city with a view of the planet Jupyter in the night sky, trending on artstation, high detail, science-fiction”↩︎"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html",
    "href": "blog/posts/2022-07-28-nbdev2/index.html",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "",
    "text": "Originally posted on the fast.ai blog"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#our-new-secret-weapon-for-productivity",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#our-new-secret-weapon-for-productivity",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "Our new secret weapon for productivity",
    "text": "Our new secret weapon for productivity\nToday we’re excited to announce that we’ve teamed up with Quarto to give nbdev superpowers. nbdev offers Python programmers a common set of tools for using Jupyter notebooks to:\n\nWrite & distribute software packages\nTest code, and\nAuthor documentation and technical articles\n\nAlthough notebooks are already widely used for once-off exploratory work, it’s less well-known that they are perfectly capable of writing quality software. In fact, we’ve used nbdev for a wide range of software projects over the last three years, including deep learning libraries, API clients, Python language extensions, terminal user interfaces, and more. We discovered that it is not only capable of writing great software but that it has also increased our productivity by 300% or more. With nbdev, developers simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free! Nbdev has allowed us to maintain and scale many open source projects. Pull requests are often accompanied by detailed documentation and tests–contributors simply write notebooks.\nThis is why we’re excited to share nbdev v2. It’s rewritten from the ground up, with much-anticipated features including:\n\nInteroperation with non-nbdev codebases for tasks like documentation\nSupport for any static site generator\nWide variety of output mediums such as blogs, papers, slides, and websites\nA faster Jupyter kernel, which also means faster tests\nCleaner and more extensible API, which supports custom directives, custom module exporters, and more"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#nbdev-in-industry",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#nbdev-in-industry",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "nbdev in industry",
    "text": "nbdev in industry\nWe have piloted nbdev at several companies. We were delighted to receive the following feedback, which fits our own experience using and developing nbdev:\n\n\n\n\n\n\nDavid Berg, on using nbdev for internal documentation at Netflix: “Prior to using nbdev, documentation was the most cumbersome aspect of our software development process… Using nbdev allows us to spend more time creating rich prose around the many code snippets guaranteeing the whole experience is robust. nbdev has turned what was once a chore into a natural extension of the notebook-based testing we were already doing.”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nErik Gaasedelen, on using nbdev in production at Lyft: “I use this in production at my company. It’s an awesome tool… nbdev streamlines everything so I can write docs, tests, and code all in one place… The packaging is also really well thought out. From my point of view it is close to a Pareto improvement over traditional Python library development.”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHugo Bowne-Anderson, on using nbdev for Outerbounds: “nbdev has transformed the way we write documentation. Gone are the days of worrying about broken code examples when our API changes or [due to] human errors associated with copying & pasting code into markdown files. The authoring experience of nbdev… [allows] us to write prose and live code in a unified interface, which allows more experimentation… On top of this, nbdev allows us to include unit tests in our documentation which mitigates the burden of maintaining the docs over time.”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRoxanna Pourzand, on using nbdev for Transform: “We’re so excited about using nbdev. Our product is technical so our resulting documentation includes a lot of code-based examples. Before nbdev, we had no way of maintaining our code examples and ensuring that it was up-to-date for both command inputs and outputs. It was all manual. With nbdev, we now have this under control in a sustainable way. Since we’ve deployed these docs, we also had a situation where we were able to identify a bug in one of our interfaces, which we found by seeing the error that was output in the documentation.”"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#whats-nbdev",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#whats-nbdev",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "What’s nbdev?",
    "text": "What’s nbdev?\nNbdev embraces the dynamic nature of python and REPL-driven development in ways that traditional IDEs and software development workflows cannot. We thoroughly discussed the motivation, history, and goals of nbdev in this initial launch post three years ago. The creator of Jupyter, Fernando Pérez, told us:\n\n[Nbdev] should be celebrated and used a lot more - I have kept a tab with your original nbdev blog post open for months in Chrome because of how often I refer to it and point others to this work\n\nIn short, nbdev embraces ideas from literate programming and exploratory programming. These paradigms have been revisited in platforms like XCode Playgrounds and languages like Smalltalk, LISP, and Mathematica. With nbdev, we sought to push these paradigms even further by enabling it for one of the most popular dynamic programming languages in the world: Python.\n\n\n\nState of the Octoverse 2021, GitHub\n\n\nEven though nbdev is most widely used in scientific computing communities due to its integration with Jupyter Notebooks, we’ve found that nbdev is well suited for a much wider range of software. We have used nbdev to write deep learning libraries, API clients, python language extensions, terminal user interfaces, and more!\nHamel: When I use nbdev, my colleagues are often astounded by how quickly I can create and distribute high-quality python packages. I consider nbdev to be a superpower that allows me to create tests and documentation without any additional friction, which makes all of my projects more maintainable. I also find writing software with nbdev to be more fun and productive as I can iterate very fast on ideas relative to more traditional software engineering workflows. Lastly, with nbdev I can also use traditional text-based IDEs if I want to, so I get the best of both worlds."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#what-we-learned-after-three-years-of-using-nbdev",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#what-we-learned-after-three-years-of-using-nbdev",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "What we learned after three years of using nbdev",
    "text": "What we learned after three years of using nbdev\nWhile nbdev was originally developed to simplify the software development workflow for various fast.ai projects, we found that users wanted to extend nbdev to:\n\nWrite and publish blog posts, books, papers, and other types of documents with Jupyter Notebooks\nDocument existing codebases not written in nbdev\nAccommodate traditional Python conventions–for those constrained in how their code is organized and formatted\nPublish content using any static site generator\n\nWhile we created projects such as fastpages and fastdoc to accomplish some of these tasks, we realized that it would be better to have a single set of flexible tools to accomplish all of them. To this end, we were extremely excited to discover Quarto, an open-source technical publishing system built on pandoc.\nHamel: The more I used nbdev for creating Python modules, the more I wanted to use it for writing blogs and documenting existing codebases. The ability to customize the way notebooks are rendered (hiding vs. showing cells, stripping output, etc.), along with the facilities for including unit tests, made it my go-to authoring tool for all technical content. I’m excited that nbdev2 unlocks all of these possibilities for everyone!"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#enter-quarto-a-pandoc-super-processor",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#enter-quarto-a-pandoc-super-processor",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "Enter Quarto: A pandoc super-processor",
    "text": "Enter Quarto: A pandoc super-processor\nQuarto is a project that enables technical publishing with support for Jupyter Notebook, VSCode, Observable, and plaintext editors. Furthermore, Quarto enables the publishing of high-quality articles, reports, websites, and blogs in HTML, PDF, ePub, PowerPoint slides, and more. Quarto is maintained by RStudio, a company with a long history of products supporting literate programming, such as RMarkdown and RStudio.\nQuarto is built on top of Pandoc, a universal document converter that supports nearly any format you can think of. Pandoc achieves this seemingly magical feat by representing documents in a common abstract syntax tree (AST) that serves as the medium through which different formats can be translated. By extension, Quarto allows you to generate content in almost any format you wish! You can use pandoc filters to modify the AST and the output format, which allows you to use any static site generator you want, and programmatically modify and generate content.\nQuarto allows you to compose pandoc filters in a processing pipeline and apply them to specific documents or entire projects. You can also distribute filters as Quarto extensions, which makes Quarto extremely customizable.\nWe also find Quarto compelling because user interfaces such as comment directives (comments that start with #|) correlate with nbdev. In fact, we even learned that nbdev inspired Quarto in this regard! In general, Quarto and nbdev share many goals, and the Quarto team has been incredibly responsive to our suggestions. For example, the ability to create notebook filters to modify notebooks before rendering. Below is a screenshot of a Jupyter notebook rendered with Quarto and nbdev.\n\n\n\n\nQuarto rendering a Jupyter notebook written with nbdev\n\n\n\nFinally, Quarto supports more programming languages than just Python and has been adding new features and fixing bugs at an impressive speed. This gives us confidence that we will be able to expand nbdev to support more use cases in the future. We discuss some of these future directions in the closing section."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#a-blazing-fast-notebook-kernel-execnb",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#a-blazing-fast-notebook-kernel-execnb",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "A blazing fast notebook kernel: execnb",
    "text": "A blazing fast notebook kernel: execnb\nA core component of nbdev is executing and testing notebooks programmatically. It is important that this notebook runner executes with minimal overhead to maintain our goal of providing a delightful developer experience. This is why we built execnb, a lightweight notebook runner for Python kernels, which executes notebooks blazingly fast. Furthermore, execnb allows parameterized execution of notebooks.\nHamel: I have been an enthusiastic user of tools like papermill that programmatically run notebooks for use-cases like creating dashboards or enabling new kinds of machine learning workflows. I believe execnb unlocks even more possibilities with its ability to inject arbitrary code at any place in a notebook, as well as the ability to pass callbacks that run before and/or after cells are executed. This opens up possibilities to create new types of workflows with notebooks that I am excited about exploring in the near future."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#towards-a-dialect-of-python-that-embraces-its-dynamic-nature",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#towards-a-dialect-of-python-that-embraces-its-dynamic-nature",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "Towards a dialect of python that embraces its dynamic nature",
    "text": "Towards a dialect of python that embraces its dynamic nature\nOne way to understand nbdev is part of an ecosystem that is designed to embrace Python’s dynamic properties for REPL-driven software engineering. Similar to Clojure, our goal is to provide tools that remove all friction from using the REPL in your programming workflow. We believe that the REPL enhances developer workflows thanks to context-sensitive auto-completion, signature inspection, and documentation–all based on the actual state of your code, and none of which are available in IDEs that depend solely on static analysis. We have found that for this reason, nbdev, with its Jupyter notebook foundation, makes programming significantly more productive and enjoyable.\nOur efforts to support REPL-driven development and literate programming are not limited to nbdev. We maintain a number of libraries that extend python to bolster this programming experience. The most notable of these libraries is fastcore, which extends Python in terms of testing, documenting code, metaprogramming, attribute helpers, enhanced representations of objects, and notebook-friendly patching. This blog post offers a gentle introduction to fastcore. In addition to literate programming, fastcore encourages conventions such as brevity and efficient use of vertical space so you can accomplish more with significantly less code. For example, below is a simple decorator that enables notebook-friendly patching:\n\n\n\n@patch decorator from fastcore\n\n\nWe believe that this combination of a new developer workflow (nbdev), Python extensions (fastcore), and associated norms form a new dialect of Python that is centered on leveraging its dynamic nature–in contrast to an ever-growing trend toward static analysis. We suspect that this dialect of Python will be more productive for programmers in many scenarios. We are framing this ecosystem as a “dialect” as it is still very much Python and is approachable by anyone who is familiar with the language. Furthermore, despite nbdev’s notebook workflow, our tools generate plaintext modules that can be navigated and edited with text-based IDEs, allowing programmers to experience the best of both worlds, if they desire.\nHamel: I believe this framing of a Python dialect is key to properly understanding what nbdev is. While it may be tempting to get stuck on specific features or technical details of nbdev, it is useful to zoom out to understand the overall intent of creating a better workflow rather than conforming too rigidly to existing ones. A good analogy is TypeScript’s relationship with JavaScript: it is an extension of an existing programming language that supports a new way of programming. I encourage you to treat nbdev in a similar fashion: be willing to try new ways of programming and observe which tradeoffs resonate with you. At the very least, I believe nbdev is a fun way to experience a different way of writing software, which will broaden your horizons about programming in general, all without having to learn an entirely new programming language!"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#the-future-of-nbdev",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#the-future-of-nbdev",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "The future of nbdev",
    "text": "The future of nbdev\nWhile we are excited about nbdev2, we believe we have only scratched the surface of what’s possible. We are considering the following features:\n\nSupporting more languages beyond Python, such as Julia, R and JavaScript\nOffering interfaces for executing parameterized notebooks that mimic Python scripts\nExtensions for more static site generators and filters\nSupporting alternate testing backends, such as pytest\nSupporting a greater number of docstring formats, such as Google-style docstrings\nMore options to use plain-text or human readable notebook backends other than JSON\n\nIf you have interesting ideas about how nbdev can be extended, please drop and chat with us on discord or post a message in the forums."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#how-you-can-get-started-with-nbdev",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#how-you-can-get-started-with-nbdev",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "How you can get started with nbdev",
    "text": "How you can get started with nbdev\nOur project’s website is at nbdev.fast.ai, where we will be posting tutorials, examples, and more documentation in the coming days."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#thank-you",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#thank-you",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "Thank You",
    "text": "Thank You\nThis new version of nbdev was a team effort by many wonderful people. We want to highlight two people who have made outstanding contributions:\n\nWasim Lorgat was instrumental across different areas, including significant contributions to fastcore, execnb, and nbdev, as well as the implementation of the new nbdev home page. With Wasim’s help, we were able to push nbdev to a new level of functionality and quality.\nJJ Allaire is not only the CEO of RStudio but also the steward of Quarto. JJ was incredibly responsive and eager to work with us on nbdev and added many features to Quarto specifically with nbdev in mind, such as notebook filters. We were also astounded by the attention to detail and the pace at which bugs are addressed. This new version of nbdev would not have been possible without JJ’s help, and we are excited to continue to work with him.\n\nWe also want to thank the amazing fastai community, notably Isaac Flath, Benjamin Warner and Zach Mueller for their tireless work on this project."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#a-conversation-with-jj-allaire",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#a-conversation-with-jj-allaire",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "A conversation with JJ Allaire",
    "text": "A conversation with JJ Allaire\nTo celebrate the launch of nbdev v2 and Quarto, Jeremy sat down with the CEO of Posit (previously known as RStudio, the company behind Quarto), JJ Allaire, to talk about software development, scientific publishing, R, Python, literate programming, and much more."
  },
  {
    "objectID": "tutorials/git_friendly_jupyter.html",
    "href": "tutorials/git_friendly_jupyter.html",
    "title": "Git-Friendly Jupyter",
    "section": "",
    "text": "Version control is essential to developing software, yet Jupyter notebooks don’t work with version control by default. nbdev solves this problem! It provides a set of hooks which enable git-friendly Jupyter notebooks in any git repo, including those that don’t use the broader nbdev system.\nTo get started, install nbdev:\nthen install hooks:\nThat’s it! Read on if you’re stuck or if you’d like to learn more about nbdev hooks and how to customise them. Check out our related blog post if you’re curious about how this feature was developed and how it works under the hood.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Git-Friendly Jupyter"
    ]
  },
  {
    "objectID": "tutorials/git_friendly_jupyter.html#quickstart-install-nbdev-hooks-for-a-repo",
    "href": "tutorials/git_friendly_jupyter.html#quickstart-install-nbdev-hooks-for-a-repo",
    "title": "Git-Friendly Jupyter",
    "section": "Quickstart: Install nbdev hooks for a repo",
    "text": "Quickstart: Install nbdev hooks for a repo\nTo start with, change directory to your current project and double-check. Don’t worry about the strange path, that’s because we’re using a temporary directory for this tutorial:\n\npwd\n\n/private/var/folders/ft/0gnvc3ts5jz4ddqtttp6tjvm0000gn/T/tmpez8nec5v/repo\n\n\nInstall nbdev:\n\npip install -Uqq nbdev\n\nInstall nbdev hooks:\n\nnbdev_install_hooks\n\nNot in a git repository, git hooks cannot be installed.\n\n\nYou’ll see the above error if you’re not in a git repo. If so, initialise a git repository:\n\ngit init\n\nInitialized empty Git repository in /private/var/folders/ft/0gnvc3ts5jz4ddqtttp6tjvm0000gn/T/tmpez8nec5v/repo/.git/\n\n\nThen try installing nbdev hooks again:\n\nnbdev_install_hooks\n\nHooks are installed.\n\n\nIf you already have a pre-save hook set in your Jupyter config file we won’t be able to safely install a new one automatically. Instead, you’ll encounter an error and will need to follow its instructions for a manual installation.\nJupyter hooks will now be installed in your user’s Jupyter config directory, and will work for all repos by default. Git hooks will only be installed in the current repo; you will need to rerun nbdev_install_hooks for each of your git repos. See configuring nbdev hooks if you’d like to customise hook behaviour, for example, to opt out of hooks in certain repos.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Git-Friendly Jupyter"
    ]
  },
  {
    "objectID": "tutorials/git_friendly_jupyter.html#what-are-nbdev-hooks",
    "href": "tutorials/git_friendly_jupyter.html#what-are-nbdev-hooks",
    "title": "Git-Friendly Jupyter",
    "section": "What are nbdev hooks?",
    "text": "What are nbdev hooks?\nnbdev provides three hooks to ease Jupyter-git integration.\n\nnbdev_merge on merging notebooks with git\nOne of the biggest complaints when working with Jupyter is that merge conflicts break notebooks. This is particularly problematic in projects with many collaborators.\n\n\n\nJupyter notebook shows the above error when opening a notebook with merge conflicts.\n\n\nOftentimes these conflicts are on metadata like cell execution counts that we don’t really care about. nbdev comes with a custom git merge driver that automatically fixes conflicting outputs and metadata, and that leaves remaining conflicts in a state that still works with Jupyter. It works in all git commands that use merge under the hood, including merge, pull, rebase, and stash.\nHere’s what the conflict looks like in Jupyter with nbdev’s merge driver:\n\n\n\n\n\n\n\nnbdev_clean on saving notebooks in Jupyter\nJupyter notebooks store a variety of metadata (including execution counts and notebook extension info) that aren’t conducive to collaborative version control systems like git. These pollute diffs in pull requests and git histories (which can make debugging harder), and tend to cause merge conflicts. For example:\n  {\n   \"cell_type\": \"code\",\n-  \"execution_count\": 1,\n+  \"execution_count\": 2,\n   \"metadata\": {\n     \"hide_input\": false\n  }\nPython’s default repr is another example, since it includes a memory address which we usually aren’t interested in:\n-&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbc11508950&gt;\n+&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbc113dbe90&gt;\nnbdev install a Jupyter hook which runs nbdev_clean to automatically clean unwanted metadata and outputs from your notebooks, including ids from default Python reprs! With nbdev hooks, the examples above would become:\n{\n  \"cell_type\": \"code\",\n  \"execution_count\": null,\n  \"metadata\": {}\n}\nand\n&lt;matplotlib.axes._subplots.AxesSubplot&gt;\n\n\nnbdev_trust after merging notebooks with git\nA side-effect of Jupyter’s security model is that widgets don’t work in collaborative repos, unless you manually “trust” notebooks after each git pull. There is a good reason behind this: since Jupyter notebooks contain HTML and JavaScript, the trust system avoids running malicious code when you open a notebook and don’t explicitly run any cells. See the official documentation for more.\nManually trusting notebooks each time is a pain. A more natural workflow would be trust a repo once-off, and all notebooks and changes thereafter. nbdev includes a git post-merge hook which runs nbdev_trust in your repo to do exactly this.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Git-Friendly Jupyter"
    ]
  },
  {
    "objectID": "tutorials/git_friendly_jupyter.html#configuring-nbdev-hooks",
    "href": "tutorials/git_friendly_jupyter.html#configuring-nbdev-hooks",
    "title": "Git-Friendly Jupyter",
    "section": "Configuring nbdev hooks",
    "text": "Configuring nbdev hooks\nThe most up-to-date reference of nbdev’s settings is in the nbdev_create_config docs. In addition, this section will guide you through a few common configurations.\nControl whether Jupyter hooks are run:\n\nGlobally enable Jupyter hooks: set jupyter_hooks = True in user settings\nGlobally disable Jupyter hooks: set jupyter_hooks = False in user settings (at ~/.config/nbdev/settings.ini)\nEnable Jupyter hooks only for selected repos: set jupyter_hooks = False in user settings and jupyter_hooks = True in selected repo settings\n\nCustomise notebook cleaning with the following settings:\n\nClean all outputs and metadata: clear_all\nPreserve certain metadata by key: allowed_metadata_keys and allowed_cell_metadata_keys\nClean ids from default Python reprs: clean_ids\n\nAll of the above can be customised per-user and per-repo.\nControl whether git hooks are run:\nSince git hooks are installed per-repo they’ll only run in repos where you manually nbdev_install_hooks. If you change your mind later, you can uninstall git hooks by following the instructions in the .gitconfig file created in your repo.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Git-Friendly Jupyter"
    ]
  },
  {
    "objectID": "tutorials/qmd_intro.html",
    "href": "tutorials/qmd_intro.html",
    "title": "Qmd Documents",
    "section": "",
    "text": "Qmd documents are Markdown documents, but with loads of extra functionality provided by Quarto and Pandoc. nbdev uses Quarto to render its pages (with some extra functionality), and Quarto uses Pandoc to render its pages (with some extra functionality). Every markdown cell in an nbdev notebook is treated as qmd, and nbdev can publish plain qmd text files, and qmd RenderScripts. Therefore, it’s a good idea to be familiar with the main features of qmd.\nJust like with RenderScripts, you can use hot/live reloading with plain qmd text files – so as soon as you save the file, you’ll see the new output in your web browser (assuming you’ve got nbdev_preview running).",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Qmd Documents"
    ]
  },
  {
    "objectID": "tutorials/qmd_intro.html#computations",
    "href": "tutorials/qmd_intro.html#computations",
    "title": "Qmd Documents",
    "section": "Computations",
    "text": "Computations\nYou can generate data-driven documents using qmd files. For instance, consider this table (also shown in the RenderScript tutorial for comparison), containing a list of the people with testimonials on nbdev’s home page:\n\n\n\n\n\n\n\n\n\nName\nPosition\n\n\n\n\n\nChris Lattner\nInventor of Swift and LLVM\n\n\n\nFernando Pérez\nCreator of Jupyter\n\n\n\nDavid Berg\nSoftware Engineer, Netflix\n\n\n\nErik Gaasedelen\nSoftware Engineer, Lyft\n\n\n\nRoxanna Pourzand\nProduct Manager, Transform\n\n\n\nHugo Bowne-Anderson\nHead of Developer Relations, Outerbounds\n\n\n\nThe table above is generated using an embedded qmd computation block from the following python list:\n\ntestimonials = [\n    ('chris-lattner.png', 'Chris Lattner', 'Inventor of Swift and LLVM'),\n    ('fernando-pérez.jpeg', 'Fernando Pérez', 'Creator of Jupyter'),\n    ('david-berg.jpeg', 'David Berg', 'Software Engineer, Netflix'),\n    ('erik-gaasedelen.jpeg', 'Erik Gaasedelen', 'Software Engineer, Lyft'),\n    ('roxanna-pourzand.jpeg', 'Roxanna Pourzand', 'Product Manager, Transform'),\n    ('hugo-bowne-anderson.jpeg', 'Hugo Bowne-Anderson', 'Head of Developer Relations, Outerbounds')\n]\n\nJust like in the RenderScript example, to produce the table from this python list, the following four lines of code are used:\nprint(qmd.tbl_row(['','Name','Position']))\nprint(qmd.tbl_sep([1,3,4]))\nfor fname,name,position in testimonials:\n    print(qmd.tbl_row([im(fname, 60), name, position]))\nFor data-driven documents such as this one, we add the following to the YAML frontmatter, which hides the code used to produce outputs, and also does not add any extra formatting to outputs:\n---\nexecute:\n  echo: false\n  output: asis\n---\nCompare the source code of the RenderScript example and of the current page to see how computations are used in RenderScripts compared to plain qmd text files. We find that we like to use Notebooks for most pages we build, since they’ve got so much helpful functionality (such as pasting images directly into cells). We use RenderScripts for complex web pages like the nbdev home page, and qmd files for pages that are mainly markdown and don’t need any notebook functionality.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Qmd Documents"
    ]
  },
  {
    "objectID": "tutorials/qmd_intro.html#formatting",
    "href": "tutorials/qmd_intro.html#formatting",
    "title": "Qmd Documents",
    "section": "Formatting",
    "text": "Formatting\nIn addition to the standard markdown formatting, Quarto qmd adds many additional features. Look at the full quarto docs to see everything it can do – we’ll just highlight a few of our favorites here.\n\nDivs and classes\nYou can create HTML divs, by surrounding lines with :::. Divs can include classes by placing {.classname} after the opening :::. Here’s an example:\n::: {.border}\nThis content can be styled with a border\n:::\nThis is how that’s rendered:\n\nThis content can be styled with a border\n\nYou might be wondering where that border class comes from… Quarto comes with support for Bootstrap 5 and Bootswatch themes so there’s lots of classes available you can use in your documents. Remember, all notebook markdown cells are also considered qmd, and can also use all the formatting tricks discussed in this section.\n\n\nCallouts\nA special kind of block you can use is the callout block. Here’s an example:\n:::{.callout-note}\nNote that there are five types of callouts, including:\n`note`, `warning`, `important`, `tip`, and `caution`.\n:::\n…and here’s how it’s rendered:\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\nImages\nYou can add images (quarto calls them figures to your document, along with captions, and you can even arrange them into layouts. Here’s an example:\n::: {layout-ncol=3}\n![Jupyter](/images/jupyter.svg)\n\n![Vscode](/images/vscode.svg)\n\n![Git](/images/git.svg)\n:::\n\n\n\n\n\n\n\n\n\nJupyter\n\n\n\n\n\n\n\nVscode\n\n\n\n\n\n\n\nGit",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Qmd Documents"
    ]
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Click through to any of these tutorials to get started with nbdev’s features.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nEnd-To-End Walkthrough\n\n\nA step-by-step guide to using nbdev\n\n\n\n\nNotebook Best Practices\n\n\nHow to write great nbdev notebooks\n\n\n\n\nQmd Documents\n\n\nIntroduction to qmd – markdown on steroids\n\n\n\n\nRenderScripts\n\n\nIntroduction to RenderScripts – create web pages using python\n\n\n\n\nGit-Friendly Jupyter\n\n\nHow to use nbdev hooks for git-friendly Jupyter notebooks\n\n\n\n\nBlogging\n\n\nCreating a blog with notebooks\n\n\n\n\nPre-Commit Hooks\n\n\nHow to use nbdev’s git pre-commit hooks\n\n\n\n\nDocumentation Only Sites\n\n\nHow to create nbdev powered docs without a library!\n\n\n\n\nModular nbdev\n\n\nHow to use nbdev’s various tools separately\n\n\n\n\nWriting nbdev plugins\n\n\nHow to customize nbdev processors to do what you want\n\n\n\n\nnbdev1 Migration\n\n\nHow to change your nbdev1 repo to work with nbdev2\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Get Started",
      "Tutorials"
    ]
  },
  {
    "objectID": "tutorials/modular_nbdev.html",
    "href": "tutorials/modular_nbdev.html",
    "title": "Modular nbdev",
    "section": "",
    "text": "While nbdev_new gets you started with everything you need to create a delightful Python package, you can also use each of nbdev’s components listed below on their own. You might find this useful if you’re porting a large system over to nbdev, documenting an existing code base, or if you’d like to customize the nbdev workflow for your own project. Note that all of the commands below work without a settings.ini file unless otherwise noted.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Modular nbdev"
    ]
  },
  {
    "objectID": "tutorials/modular_nbdev.html#document-existing-code-show_doc",
    "href": "tutorials/modular_nbdev.html#document-existing-code-show_doc",
    "title": "Modular nbdev",
    "section": "Document existing code: show_doc",
    "text": "Document existing code: show_doc\nnbdev allows you to document existing code, even code that is not written in nbdev! nbdev.showdoc.show_doc allows you to render beautiful API documentation in notebooks and on Quarto sites. For example, you can render API documentation for numpy.all like this:\n\nfrom nbdev.showdoc import show_doc\nfrom numpy import all\nshow_doc(all)\n\n\nall\n\n all (a, axis=None, out=None, keepdims=&lt;no value&gt;, where=&lt;no value&gt;)\n\nTest whether all array elements along a given axis evaluate to True.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\narray_like\n\nInput array or object that can be converted to an array.\n\n\naxis\nNoneType\nNone\nAxis or axes along which a logical AND reduction is performed.The default (axis=None) is to perform a logical AND over allthe dimensions of the input array. axis may be negative, inwhich case it counts from the last to the first axis... versionadded:: 1.7.0If this is a tuple of ints, a reduction is performed on multipleaxes, instead of a single axis or all the axes as before.\n\n\nout\nNoneType\nNone\nAlternate output array in which to place the result.It must have the same shape as the expected output and itstype is preserved (e.g., if dtype(out) is float, the resultwill consist of 0.0’s and 1.0’s). See :ref:ufuncs-output-type for moredetails.\n\n\nkeepdims\n_NoValueType\n\nIf this is set to True, the axes which are reduced are leftin the result as dimensions with size one. With this option,the result will broadcast correctly against the input array.If the default value is passed, then keepdims will not bepassed through to the all method of sub-classes ofndarray, however any non-default value will be. If thesub-class’ method does not implement keepdims anyexceptions will be raised.\n\n\nwhere\n_NoValueType\n\nElements to include in checking for all True values.See ~numpy.ufunc.reduce for details... versionadded:: 1.20.0\n\n\nReturns\nndarray, bool\n\nA new boolean or array is returned unless out is specified,in which case a reference to out is returned.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nshow_doc automatically parses docstrings that are written in the numpy style. For more information read here.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Modular nbdev"
    ]
  },
  {
    "objectID": "tutorials/modular_nbdev.html#testing-notebooks-nbdev_test",
    "href": "tutorials/modular_nbdev.html#testing-notebooks-nbdev_test",
    "title": "Modular nbdev",
    "section": "Testing notebooks: nbdev_test",
    "text": "Testing notebooks: nbdev_test\nTesting notebooks can be very useful outside of nbdev, especially if you are documenting an existing code base and want to incorporate tests for your docs. The nbdev_test CLI utility allows you to accomplish this:\nYou can test an individual notebook with the terminal command:\nnbdev_test --path notebook.ipynb\n…or a folder of notebooks:\nnbdev_test --path tests/",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Modular nbdev"
    ]
  },
  {
    "objectID": "tutorials/modular_nbdev.html#export-code-to-modules-nb_export",
    "href": "tutorials/modular_nbdev.html#export-code-to-modules-nb_export",
    "title": "Modular nbdev",
    "section": "Export code to modules: nb_export",
    "text": "Export code to modules: nb_export\nYou can export a notebook to a module with the Python function:\nnb_export('notebook.ipynb', 'pkg')\n…provided the notebook specifies a default_exp directive at the top, and export directives above each cell to be exported. We recommend including this in a code cell at the bottom of your notebook for convenience.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Modular nbdev"
    ]
  },
  {
    "objectID": "tutorials/modular_nbdev.html#jupyter-git-integration",
    "href": "tutorials/modular_nbdev.html#jupyter-git-integration",
    "title": "Modular nbdev",
    "section": "Jupyter-git integration",
    "text": "Jupyter-git integration\nJupyter and Git don’t normally play well together, especially for things like merge conflicts. We have outlined all of these problems, and our solutions in this blog post. You can install our merge driver and hooks with the following command:\nnbdev_install_hooks\nWe describe what nbdev_install_hooks does in detail on this page.\nYou can also directly use any of its underlying commands, for example, to implement your own hooks or extensions:\n\nnbdev_clean\nnbdev_fix\nnbdev_merge\nnbdev_trust\n\nTo configure your own hooks, Check out the pre-commit hooks tutorial.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Modular nbdev"
    ]
  },
  {
    "objectID": "tutorials/modular_nbdev.html#python-packaging",
    "href": "tutorials/modular_nbdev.html#python-packaging",
    "title": "Modular nbdev",
    "section": "Python packaging",
    "text": "Python packaging\nnbdev.releaseprovides utlities for easy packaging on PyPI, conda, and GitHub. Check out the nbdev.release docs for more information. Note that this functionality requires a settings.ini file.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Modular nbdev"
    ]
  },
  {
    "objectID": "tutorials/extensions.html",
    "href": "tutorials/extensions.html",
    "title": "Writing nbdev plugins",
    "section": "",
    "text": "With nbdev, it’s possible to customize and extend it further beyond the standard capabilities through a well thoughtout and scalable framework. Does your particular library or need require you to inject custom quarto additives in certain cells? What about if you want to do something more trivial such as finding shortcuts to replace complicated quarto directives more easily (such as replacing ::: {.column-margin} with #| margin)?\nWriting custom plugins with nbdev is the easiest method to achieve this, and with this tutorial we will bring you up to speed on how you can use this to create your own plugins to expand and simplify your literate-programming experience with nbdev and quarto.\nSpecifically, we will be building a processor (something that processes a notebook cell) that will let us quickly write out any quarto-specific headers (that ::: {.some_annotation}) and replace it with a div shortcut. This is of course one example very specific to quarto that happens when building the documentation, but this technique can be used to have custom behaviors occur during library exportation as well.\n\nNote: We are using div here is it more closely resembles how each of the related Quarto directives do and behave as they act like &lt;div&gt;s in HTML code\n\nThis tutorial won’t cover some of the basics when it comes to nbdev, and instead comes with the understanding you know how to navigate nbdev (such as what are directives, export, etc).",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Writing nbdev plugins"
    ]
  },
  {
    "objectID": "tutorials/extensions.html#what-will-this-cover",
    "href": "tutorials/extensions.html#what-will-this-cover",
    "title": "Writing nbdev plugins",
    "section": "",
    "text": "With nbdev, it’s possible to customize and extend it further beyond the standard capabilities through a well thoughtout and scalable framework. Does your particular library or need require you to inject custom quarto additives in certain cells? What about if you want to do something more trivial such as finding shortcuts to replace complicated quarto directives more easily (such as replacing ::: {.column-margin} with #| margin)?\nWriting custom plugins with nbdev is the easiest method to achieve this, and with this tutorial we will bring you up to speed on how you can use this to create your own plugins to expand and simplify your literate-programming experience with nbdev and quarto.\nSpecifically, we will be building a processor (something that processes a notebook cell) that will let us quickly write out any quarto-specific headers (that ::: {.some_annotation}) and replace it with a div shortcut. This is of course one example very specific to quarto that happens when building the documentation, but this technique can be used to have custom behaviors occur during library exportation as well.\n\nNote: We are using div here is it more closely resembles how each of the related Quarto directives do and behave as they act like &lt;div&gt;s in HTML code\n\nThis tutorial won’t cover some of the basics when it comes to nbdev, and instead comes with the understanding you know how to navigate nbdev (such as what are directives, export, etc).",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Writing nbdev plugins"
    ]
  },
  {
    "objectID": "tutorials/extensions.html#getting-started-how-does-nbdev-make-this-easy",
    "href": "tutorials/extensions.html#getting-started-how-does-nbdev-make-this-easy",
    "title": "Writing nbdev plugins",
    "section": "Getting started, how does nbdev make this easy?",
    "text": "Getting started, how does nbdev make this easy?\nFirst let’s visualize just what we’re trying to achieve.\nInstead of doing the following code which will add \"Some text\" to the sidebar (as shown off to the side currently):\n\n\nSome text\n::: {.column-margin}\nSome text\n:::\nWe will create a shorter way to write this out, making use of how nbdev and quarto writes their directives\nBy the end of this tutorial we will create something that looks like the following:\n#| div column-margin\n\nSome text\nAnd this will include cases where a div should be put across multiple cells as well, by specifying a start and an end.\n\nNote: Check out the article layout Quarto documentation to find the best examples of use cases for this custom directive, including the column-margin just shown\n\nThis can be achieved in under 50 lines of code!\nnbdev let’s us create what are called processors (this is how #| export will shove code into modules, for example). These processors are acted on each cell of a notebook and can modify its contents. These can then be wrapped into a module the same way that nbdev will do nbdev_export or nbdev_docs. Thanks to the power of writing custom nbdev extensions, going deep into the inner-workings of the framework isn’t required!",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Writing nbdev plugins"
    ]
  },
  {
    "objectID": "tutorials/extensions.html#bringing-in-what-we-need",
    "href": "tutorials/extensions.html#bringing-in-what-we-need",
    "title": "Writing nbdev plugins",
    "section": "Bringing in what we need",
    "text": "Bringing in what we need\nThe actual imports we need to use from nbdev is truly not that many! We just need two: - extract_directives, to read in the list of #| written - The Processor class that will actually perform what we want on notebook cells.\nThe rest of the imports are there to make some of our lives easier as will be explained later\n\nfrom nbdev.process import extract_directives\nfrom nbdev.processors import Processor\n\nfrom fastcore.basics import listify\n\nfrom string import Template\n\nLastly for testing purposes we’ll utilize nbdev’s mk_cell function and the NBProcessor class, which will let us mock running our processor on a “real” notebook!\n\nfrom nbdev.processors import mk_cell, NBProcessor",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Writing nbdev plugins"
    ]
  },
  {
    "objectID": "tutorials/extensions.html#writing-a-converter",
    "href": "tutorials/extensions.html#writing-a-converter",
    "title": "Writing nbdev plugins",
    "section": "Writing a converter",
    "text": "Writing a converter\nThe first step is creating a quick and easy way to take the nbdev directive we want to use (such as #| div column-margin) and convert it quickly into something quarto will then read (such as ::: {.column-margin}).\nWe can create a string Template to perform this for us:\n\n_LAYOUT_STR = Template(\"::: {.$layout}\\n${content}\\n\")\n\n\n\n\n\n\n\nTip\n\n\n\nThis doesn’t have to be a string template, I just found this the easiest to use!\n\n\n\n_LAYOUT_STR.substitute(\n    layout=\"column-margin\",\n    content=\"Some text to go on the sidebar\"\n)\n\n'::: {.column-margin}\\nSome text to go on the sidebar\\n'\n\n\nNext we need to write a simple converter that operates at the cell level:\n\ndef convert_layout(\n    cell:dict, # A single cell from a Jupyter Notebook\n    is_multicell=False # Whether the div should be wrapped around multiple cells\n):\n    \"Takes a code cell that contains `div` in the directives and modifies the contents to the proper Quarto format\"\n    content = cell.source\n    code = cell.source.splitlines(True)\n    div_ = cell.directives_[\"div\"]\n    # We check if end is in the first line of the cell source\n    if \"end\" in div_:\n        # If it is, just fill the text with `:::` if no code exists there\n        cell.source = \":::\" if len(code) == 1 else f'{code.source}:::'\n    else:\n        # Actually modify the code\n        cell.source = _LAYOUT_STR.substitute(layout=\" \".join(div_), content=content)\n        if not is_multicell: cell.source += \":::\"\n\nLet’s go into detail on what’s happening here.\n    content = cell.source\nThe source text of whatever exists in a notebook cell will live in .source.\n    code = cell.source.splitlines(True)\nThen I want to extract the content of the cell and split them into multiple lines, seperated by newlines. This let’s us check if a cell just contains #| div end, which means that the div that was started earlier should stop.\n    div_ = cell.directives_[\"div\"]\nAny directives (comments in any cell marked with #|) will exist in the directives_ attribute as a dictionary. For our particular processor we only care about the div directive\n    if \"end\" in div_:\n        # If it is, just fill the text with `:::` if no code exists there\n        cell.source = \":::\" if len(code) == 1 else f'{code.source}:::'\n    else:\n        # Actually modify the code\n        cell.source = _LAYOUT_STR.substitute(layout=\" \".join(div_), content=content)\n        if not is_multicell: cell.source += \":::\"\nFrom there this last part checks whether to add the ending ::: block to the cell or to use the _LAYOUT_STR and inject the boilerplate div CSS code in for Quarto.\nLet’s see it in action:\n\ncell = mk_cell(\n    \"\"\"#| div margin-column\nHere is something for the sidebar!\"\"\",\n    cell_type=\"markdown\"\n)\n\nnbdev will pull out those directives and store them in the cell’s directives_ attribute using the extract_directives function:\n\ncell.directives_ = extract_directives(cell, \"#\")\ncell.directives_\n\n{'div': ['margin-column']}\n\n\nAnd now we can test out if our convert_layout function works!\n\nconvert_layout(cell)\nprint(cell.source)\n\n::: {.margin-column}\nHere is something for the sidebar!\n:::\n\n\n\nNote: I print the cell.source here so that it’s text looks cleaner and what we would visually see in a Markdown cell\n\nLooks exactly like we wanted earlier! Great!\nHow do we tell nbdev to use this and create this Processor class mentioned earlier?",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Writing nbdev plugins"
    ]
  },
  {
    "objectID": "tutorials/extensions.html#writing-a-processor",
    "href": "tutorials/extensions.html#writing-a-processor",
    "title": "Writing nbdev plugins",
    "section": "Writing a Processor",
    "text": "Writing a Processor\nThe second-to-last step here is to create the custom Processor nbdev utilizes to apply procs (things that modify the contents of cells). The basic understanding of these is simply that you should create a class, have it inherit Processor, and any modifications that should be done must be defined in a cell function which takes in a cell and modifies it in-place.\n\nclass LayoutProc(Processor):\n    \"A processor that will turn `div` based tags into proper quarto ones\"\n    has_multiple_cells = False\n    def cell(self, cell):\n        if cell.cell_type == \"markdown\" and \"div\" in cell.directives_:\n            div_ = cell.directives_[\"div\"]\n            if self.has_multiple_cells and \"end\" in div_:\n                convert_layout(cell)\n            else:\n                is_start = div_[-1] == \"start\"\n                if is_start:\n                    self.has_multiple_cells = True\n                    div_.remove(\"start\")\n                convert_layout(cell, is_start)\n\nHow can we test if this will work or not?\nA minimal Jupyter Notebook is just a dictionary where the cells are in a cells key and the cells themselves are a list of notebook cells following a special format. We’ve created one of these above. nbdev has a dict2nb function which let’s us convert this minimal idea of a Jupyter Notebook into the true thing quickly.\nAfterwards, we can apply the processor to those cells though the NBProcessor class (what nbdev uses to apply these)\n\nfrom nbdev.process import NBProcessor, dict2nb\n\n\nnb = {\n    \"cells\":[\n    mk_cell(\"\"\"#| div column-margin\nA test\"\"\", \"markdown\"),\n    mk_cell(\"\"\"#| div column-margin start\nA test\"\"\", \"markdown\"),\n    mk_cell(\"\"\"#| div end\"\"\", \"markdown\"),\n]}\n\n\n\nThe mk_cell function will create a cell based on some content and a cell type. The particular extension we’ve built works off Markdown cells, so we set the type as markdown.\nThe NBProcessor takes in a list of procs (processors) that should be applied, and an opened Jupyter Notebook:\n\nprocessor = NBProcessor(procs=LayoutProc, nb=dict2nb(nb))\n\nThe act of applying these processors is done through calling the .process(): function\n\nprocessor.process()\n\nAnd now we can see that those code cells were changed:\n\nfor i in range(3):\n    print(f\"Before:\\n{nb['cells'][i].source}\\n\")\n    print(f\"After:\\n{processor.nb.cells[i].source}\\n\")\n\nBefore:\n#| div column-margin\nA test\n\nAfter:\n::: {.column-margin}\nA test\n:::\n\nBefore:\n#| div column-margin start\nA test\n\nAfter:\n::: {.column-margin}\nA test\n\n\nBefore:\n#| div end\n\nAfter:\n:::\n\n\n\nGreat! We’ve successfully created a plugin for nbdev that will let us lazily write markdown quarto directives easily. How can we actually use this in our projects?",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Writing nbdev plugins"
    ]
  },
  {
    "objectID": "tutorials/extensions.html#how-to-enable-the-plugin-on-your-project",
    "href": "tutorials/extensions.html#how-to-enable-the-plugin-on-your-project",
    "title": "Writing nbdev plugins",
    "section": "How to enable the plugin on your project",
    "text": "How to enable the plugin on your project\nThis requires two changes to your settings.ini.\nFirst, if say this were code that lived in nbdev, we can add a special procs key and specify where the processor comes from:\nprocs = \n    nbdev.extensions:LayoutProc\nIt follows the format of library.module:processor_name\nIf this were being used from an external library (such as how this processor is based on the one that lives in nbdev-extensions, you should add that to the requirements of your project:\nrequirements = nbdev-extensions\nAnd you’re done! Now when calling nbdev_docs or nbdev_preview the processor we just made will be automatically applied to your notebooks and perform this conversion!",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Writing nbdev plugins"
    ]
  },
  {
    "objectID": "tutorials/extensions.html#conclusion-nbdev-extensions-and-a-bit-about-me",
    "href": "tutorials/extensions.html#conclusion-nbdev-extensions-and-a-bit-about-me",
    "title": "Writing nbdev plugins",
    "section": "Conclusion, nbdev-extensions and a bit about me!",
    "text": "Conclusion, nbdev-extensions and a bit about me!\nBasically if there’s any part of a cell and how it should look either from exporting modules, building documentation, or creating your own special command to perform post-processing it can be done quickly and efficiently with this Processor class nbdev provides!\nIf you’re interested in seeing more examples of nbdev-extensions and where you can take it I’ve (Zachary Mueller) written a library dedicated to it called nbdev-extensions where any ideas that may benefit how I approach nbdev I then turn into an extension for the world to use.\nThanks for reading!",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Writing nbdev plugins"
    ]
  },
  {
    "objectID": "tutorials/docs_only.html",
    "href": "tutorials/docs_only.html",
    "title": "Documentation Only Sites",
    "section": "",
    "text": "While nbdev is great for authoring software, you may wish to utilize the power of nbdev for the purposes of documenting existing code, or use various utilities of nbdev without having to write a python library. For example, you can use the following features of nbdev without creating a python package:\n\nCustom nbdev directives such as #|hide_line.\nTesting with nbdev_test.\nAutomated entity linking with doclinks.\nRendering API documentation with docments and show_doc.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Documentation Only Sites"
    ]
  },
  {
    "objectID": "tutorials/docs_only.html#background",
    "href": "tutorials/docs_only.html#background",
    "title": "Documentation Only Sites",
    "section": "",
    "text": "While nbdev is great for authoring software, you may wish to utilize the power of nbdev for the purposes of documenting existing code, or use various utilities of nbdev without having to write a python library. For example, you can use the following features of nbdev without creating a python package:\n\nCustom nbdev directives such as #|hide_line.\nTesting with nbdev_test.\nAutomated entity linking with doclinks.\nRendering API documentation with docments and show_doc.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Documentation Only Sites"
    ]
  },
  {
    "objectID": "tutorials/docs_only.html#setup",
    "href": "tutorials/docs_only.html#setup",
    "title": "Documentation Only Sites",
    "section": "Setup",
    "text": "Setup\nTo setup a documentation only site, you can follow these steps:\n\nCreate a nbdev repo the usual way, using nbdev_new\nRemove library files\n\nrm setup.py .github/workflows/test.yaml nbs/00_core.ipynb\n\nRemove your library folder (this will be the lib_path field in settings.ini):\n\nrm -rf &lt;lib_path&gt;",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Documentation Only Sites"
    ]
  },
  {
    "objectID": "tutorials/docs_only.html#usage",
    "href": "tutorials/docs_only.html#usage",
    "title": "Documentation Only Sites",
    "section": "Usage",
    "text": "Usage\nAfter setting up your project, you can use various nbdev utilities per usual:\n\nnbdev_preview for previewing your site\nnbdev_test for testing your docs locally\nCustom nbdev directives will be available to you (but you must be careful not to use irrelevant ones like #|export).\nIf you created your nbdev docs site on GitHub, GitHub Actions will publish your docs for you automatically as described here.\nYou can publish your docs on other platforms as described here.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Documentation Only Sites"
    ]
  },
  {
    "objectID": "tutorials/docs_only.html#demo",
    "href": "tutorials/docs_only.html#demo",
    "title": "Documentation Only Sites",
    "section": "Demo",
    "text": "Demo\nA minimal example of a documentation-only site is located here.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Documentation Only Sites"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html",
    "href": "tutorials/best_practices.html",
    "title": "Notebook Best Practices",
    "section": "",
    "text": "The flexibility offered by notebooks can be overwhelming. While there are industry standards for writing Python packages—like numpy and sphinx docstrings, and pytest and unittest testing frameworks—they weren’t designed for notebooks.\nThis article walks you through the practices we’ve learned to leverage the full power of notebooks with nbdev1. Our approach weaves code, tests, and docs into a single interactive context that invites experimentation. If you prefer to learn by example, you might want to start with the annotated example and branch out from there.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#know-which-form-of-notebook-youre-writing",
    "href": "tutorials/best_practices.html#know-which-form-of-notebook-youre-writing",
    "title": "Notebook Best Practices",
    "section": "Know which form of notebook you’re writing",
    "text": "Know which form of notebook you’re writing\nFirst of all, decide which form of notebook you’re writing. We’re fans of the Diátaxis system which classifies documentation into four forms: tutorials, how-to guides, explanations, and references. They’ve laid this out beautifully in the following diagram:",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#start-with-a-great-title-and-subtitle",
    "href": "tutorials/best_practices.html#start-with-a-great-title-and-subtitle",
    "title": "Notebook Best Practices",
    "section": "Start with a great title and subtitle",
    "text": "Start with a great title and subtitle\nStart with a markdown cell at the top of your notebook with its title in an H1 header, and subtitle in a blockquote. For example:\n# Great title\n\n&gt; And an even better subtitle\nThe title will also be used to reference your page in the sidebar. You can also optionally add frontmatter to this cell to customize nbdev and Quarto.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#introduce-your-notebook",
    "href": "tutorials/best_practices.html#introduce-your-notebook",
    "title": "Notebook Best Practices",
    "section": "Introduce your notebook",
    "text": "Introduce your notebook\nIntroduce your notebook with markdown cells below the title. We recommend a slightly different approach depending on the form of documentation:\n\nReference: Start with a brief description of the technical component, and an overview that links to the main symbols in the page (you might want to use doclinks)\nTutorials and how-to guides: Describe what the reader will learn and how. Keep it short and get to the subject matter quickly\nExplanations: Since these are typically very focused, a short description of the topic is often sufficient.\n\n\n\n\n\n\n\nNote that Markdown lists such as the one above require a blank line above them to be rendered as lists in the documentation, even though the notebook viewer will render lists that are not preceded by a blank line.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#use-lots-of-code-examples-pictures-plots-and-videos",
    "href": "tutorials/best_practices.html#use-lots-of-code-examples-pictures-plots-and-videos",
    "title": "Notebook Best Practices",
    "section": "Use lots of code examples, pictures, plots, and videos",
    "text": "Use lots of code examples, pictures, plots, and videos\nTake advantage of the richness of notebooks by including code examples, pictures, plots, and videos.\nHere are a few examples to get you started:\n\nfastai’s documentation makes extensive use of code examples, plots, images, and tables, for example, the computer vision intro\nnbdev.release opens with a terminal screencast demo in SVG format created with asciinema and svg-term-cli\nThe documentation explanation describes a complex data pipeline using a Mermaid diagram\nThe directives explanation showcases all of nbdev’s directives with executable examples in call-out cards (and makes great use of emojis too!)\nRDKit renders beautiful molecule diagrams",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#keep-docstrings-short-elaborate-in-separate-cells",
    "href": "tutorials/best_practices.html#keep-docstrings-short-elaborate-in-separate-cells",
    "title": "Notebook Best Practices",
    "section": "Keep docstrings short; elaborate in separate cells",
    "text": "Keep docstrings short; elaborate in separate cells\nWhile nbdev renders docstrings as markdown, they aren’t rendered correctly when using symbol? or help(symbol) and they can’t include executed code. By splitting longer docstrings across separate code and markdown cells you can use code examples, pictures, plots, and videos.\nWe find a single-line summary sufficient for most docstrings.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#document-parameters-with-docments",
    "href": "tutorials/best_practices.html#document-parameters-with-docments",
    "title": "Notebook Best Practices",
    "section": "Document parameters with docments",
    "text": "Document parameters with docments\nfastcore.docments is a concise way to document parameters that is beautifully rendered by nbdev. For example, this function:\n\ndef draw_n(n:int, # Number of cards to draw\n           replace:bool=True # Draw with replacement?\n          )-&gt;list: # List of cards\n    \"Draw `n` cards.\"\n\n…would include the following table as part of its documentation:\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\nint\n\nNumber of cards to draw\n\n\nreplace\nbool\nTrue\nDraw with replacement?\n\n\nReturns\nlist\n\nList of cards\n\n\n\n\nnbdev also supports some numpy docstring sections. For example, this code snippet would produce the same table (there’s no need to include types like in the docstring if you already have annotations):\n\ndef draw_n(n:int, replace:bool=True) -&gt; Cards:\n    \"\"\"\n    Draw `n` cards.\n    \n    Parameters\n    ----------\n    n\n        Number of cards to draw\n    replace\n        Draw with replacement?\n        \n    Returns\n    -------\n    cards\n        List of cards\n    \"\"\"\n\n\n\n\n\n\n\nYou can render a symbol’s parameters table directly with DocmentTbl. In fact, that’s how we rendered the table above.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#make-code-cells-short-and-demonstrate-them-immediately",
    "href": "tutorials/best_practices.html#make-code-cells-short-and-demonstrate-them-immediately",
    "title": "Notebook Best Practices",
    "section": "Make code cells short, and demonstrate them immediately",
    "text": "Make code cells short, and demonstrate them immediately\nIn notebooks, do not create long functions and classes with comments interspersed throughout them. Instead, split your code up into small separate cells with explanations and working examples after each. This lets the user understand how each part works and experiment with them straight away. It also helps you during development because you can explore the behavior of every part of your code interactively.\nIn non-notebook coding, the documentation, tests, code, and examples are all separate. This is not the case with nbdev. Take advantage of this by keeping all of these things as close together as possible. This is helpful both for exploration and for documentation.\nFor example, consider the section of the Claudette source notebook for implementing image support. The section immediately imports an image and displays it, showing how to work with a file format. It then creates a number of helper functions, describes and demonstrates them, and finally puts it all together to show how to use the complete feature in practice with real inputs and outputs running directly in the notebook.\nIn order to avoid long class definitions caused by many methods, consider using fastcore’s patch decorator to implement each method separately, and immediately document, demonstrate, and test it.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#consider-turning-code-examples-into-tests-by-adding-assertions",
    "href": "tutorials/best_practices.html#consider-turning-code-examples-into-tests-by-adding-assertions",
    "title": "Notebook Best Practices",
    "section": "Consider turning code examples into tests by adding assertions",
    "text": "Consider turning code examples into tests by adding assertions\nnbdev blurs the lines between code, docs, and tests. Every code cell is run as a test (unless it’s explicitly marked otherwise), and any error in the cell fails the test.\nConsider turning your code examples into tests by adding assertions – if they would make valuable tests and if it doesn’t hurt readability. fastcore.test provides a set of light wrappers around assert for better notebook tests (for example, they print both objects on error if they differ).\nHere’s an example using fastcore.test.test_eq:\n\ndef inc(x): return x + 1\ntest_eq(inc(3), 4)",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#document-error-cases-as-tests",
    "href": "tutorials/best_practices.html#document-error-cases-as-tests",
    "title": "Notebook Best Practices",
    "section": "Document error-cases as tests",
    "text": "Document error-cases as tests\nDocstring-driven approaches typically document the errors raised by an object using plaintext descriptions, for example, in a “raises” section.\nIn nbdev, we recommend documenting errors with actual failing code using fastcore.test.test_fail. For example:\n\ndef divide(x, y): return x / y\ntest_fail(lambda: divide(1, 0), contains=\"division by zero\")\n\nThe first argument is a lambda since we need to allow test_fail to control its execution and catch any errors.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#reference-related-symbols-with-doclinks",
    "href": "tutorials/best_practices.html#reference-related-symbols-with-doclinks",
    "title": "Notebook Best Practices",
    "section": "Reference related symbols with doclinks",
    "text": "Reference related symbols with doclinks\nIf you surround a symbol with backticks, nbdev will automatically link to that symbol’s reference page. We call these doclinks.\nPrefer fully qualified symbol paths, like package.module.symbol instead of symbol. It may be more verbose but it helps users know which module a symbol originates from, which is especially important for third-party packages.\nAny package created with nbdev will automatically support doclinks. Non-nbdev packages can be supported by creating a minimal nbdev-index package. nbdev-index is a collection of such packages, which already supports django, numpy, pandas, pytorch, scipy, sphinx, the Python standard library, and even other programming languages like APL!",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#add-rich-representations-to-your-classes",
    "href": "tutorials/best_practices.html#add-rich-representations-to-your-classes",
    "title": "Notebook Best Practices",
    "section": "Add rich representations to your classes",
    "text": "Add rich representations to your classes\nThis is another way to take advantage of the rich display feature of notebooks. You can provide rich representations to your object by defining a _repr_markdown_ method that returns markdown text (which may also include HTML/CSS).\nHere’s a simple example to get you started:\n\nclass Color:\n    def __init__(self, color): self.color = color\n    def _repr_markdown_(self):\n        style = f'background-color: {self.color}; width: 50px; height: 50px; margin: 10px'\n        return f'&lt;div style=\"{style}\"&gt;&lt;/div&gt;'\n\n\nColor('green')\n\n\n\n\n\n\n\nColor('blue')\n\n\n\n\n\n\nAlso see the earlier list of example projects that make use of beautiful visual representations.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#document-class-methods-with-show_doc-or-fastcore.basics.patch",
    "href": "tutorials/best_practices.html#document-class-methods-with-show_doc-or-fastcore.basics.patch",
    "title": "Notebook Best Practices",
    "section": "Document class methods with show_doc or fastcore.basics.patch",
    "text": "Document class methods with show_doc or fastcore.basics.patch\nnbdev automatically documents exported function and class definitions with show_doc. However, it’s up to you to document class methods. There are two ways to do that: calling show_doc on the method, or defining the method with the fastcore.basics.patch decorator.\n\nNotebook (show_doc)Notebook (@patch)Docs\n\n\nIf your class is defined in a single cell, use show_doc. Here’s what your notebook might look like:\n\n#| export\nclass Number:\n    \"A number.\"\n    def __init__(self, num): self.num = num\n    def __add__(self, other):\n        \"Sum of this and `other`.\"\n        return Number(self.num + other.num)\n    def __repr__(self): return f'Number({self.num})'\nFor example, here is the number 5:\nNumber(5)\nshow_doc(Number.__add__)\nFor example:\nNumber(3) + Number(4)\n\n\n\nIf you split your class definition across cells with fastcore.basics.patch, here’s what your notebook might look like:\n\n#| export\nclass Number:\n    \"A number.\"\n    def __init__(self, num): self.num = num\n    def __repr__(self): return f'Number({self.num})'\nFor example, here is the number 5:\nNumber(5)\n#| export\n@patch\ndef __add__(self:Number, other):\n    \"Sum of this and `other`.\"\n    return Number(self.num + other.num)\nFor example:\nNumber(3) + Number(4)\n\n\n\nIn either case, this is how the documentation would be rendered:\n\n\n\nNumber\n\n Number (num)\n\nA number.\nFor example, here is the number 5:\n\nNumber(5)\n\nNumber(5)\n\n\n\n\n\nNumber.__add__\n\n Number.__add__ (other)\n\nSum of this and other.\nFor example:\n\nNumber(3) + Number(4)\n\nNumber(7)",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#group-symbols-with-h2-sections",
    "href": "tutorials/best_practices.html#group-symbols-with-h2-sections",
    "title": "Notebook Best Practices",
    "section": "Group symbols with H2 sections",
    "text": "Group symbols with H2 sections\nAs your notebooks grow, consider grouping related symbols using markdown cells with level 2 headers. Since nbdev displays documented symbols as level 3 headers, this would group all symbols below your level 2 header.\nHere is the markdown syntax:\n## Section title",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#split-long-explanations-with-h4-sections",
    "href": "tutorials/best_practices.html#split-long-explanations-with-h4-sections",
    "title": "Notebook Best Practices",
    "section": "Split long explanations with H4 sections",
    "text": "Split long explanations with H4 sections\nSimilar to the previous section, as a symbol’s explanation grows, consider grouping its cells using level 4 headers. This is the recommended way to structure your reference docs, for example, to achieve numpy-style structures with sections like notes, examples, methods, and so on.\nHere’s the markdown syntax:\n#### Section title",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#putting-it-all-together-an-annotated-example",
    "href": "tutorials/best_practices.html#putting-it-all-together-an-annotated-example",
    "title": "Notebook Best Practices",
    "section": "Putting it all together: an annotated example",
    "text": "Putting it all together: an annotated example\nIn this section, we’ll guide you through a full example of writing a documented and tested function in a notebook using all of the principles described above. We’ll use the numpy.all function since it follows the widely-known numpy-docstring standard for .py files.\nBelow is the definition of the numpy.all function. Take note of how all of the information is included in the docstring. While this works well for .py files, it doesn’t let us weave executable code with rich markdown as we can in notebooks:\n\ndef all(a, axis=None, out=None, keepdims=np._NoValue, *, where=np._NoValue):\n    \"\"\"\n    Test whether all array elements along a given axis evaluate to True.\n    Parameters\n    ----------\n    a : array_like\n        Input array or object that can be converted to an array.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which a logical AND reduction is performed.\n        The default (``axis=None``) is to perform a logical AND over all\n        the dimensions of the input array. `axis` may be negative, in\n        which case it counts from the last to the first axis.\n        .. versionadded:: 1.7.0\n        If this is a tuple of ints, a reduction is performed on multiple\n        axes, instead of a single axis or all the axes as before.\n    out : ndarray, optional\n        Alternate output array in which to place the result.\n        It must have the same shape as the expected output and its\n        type is preserved (e.g., if ``dtype(out)`` is float, the result\n        will consist of 0.0's and 1.0's). See :ref:`ufuncs-output-type` for more\n        details.\n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n        If the default value is passed, then `keepdims` will not be\n        passed through to the `all` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n    where : array_like of bool, optional\n        Elements to include in checking for all `True` values.\n        See `~numpy.ufunc.reduce` for details.\n        .. versionadded:: 1.20.0\n    Returns\n    -------\n    all : ndarray, bool\n        A new boolean or array is returned unless `out` is specified,\n        in which case a reference to `out` is returned.\n    See Also\n    --------\n    ndarray.all : equivalent method\n    any : Test whether any element along a given axis evaluates to True.\n    Notes\n    -----\n    Not a Number (NaN), positive infinity and negative infinity\n    evaluate to `True` because these are not equal to zero.\n    Examples\n    --------\n    &gt;&gt;&gt; np.all([[True,False],[True,True]])\n    False\n    &gt;&gt;&gt; np.all([[True,False],[True,True]], axis=0)\n    array([ True, False])\n    &gt;&gt;&gt; np.all([-1, 4, 5])\n    True\n    &gt;&gt;&gt; np.all([1.0, np.nan])\n    True\n    &gt;&gt;&gt; np.all([[True, True], [False, True]], where=[[True], [False]])\n    True\n    &gt;&gt;&gt; o=np.array(False)\n    &gt;&gt;&gt; z=np.all([-1, 4, 5], out=o)\n    &gt;&gt;&gt; id(z), id(o), z\n    (28293632, 28293632, array(True)) # may vary\n    \"\"\"\n    ...\n\nAlternatively, Here is how we’d write numpy.all in a notebook using nbdev. The first step is to define the function:\n\n#| export\ndef all(a, # Input array or object that can be converted to an array.\n        axis:int|tuple|None=None, # Axis or axes along which a logical AND reduction is performed (default: all).\n        out:np.ndarray|None=None, # Alternate output array in which to place the result.\n        keepdims:bool=np._NoValue, # Leave reduced one-dimensional axes in the result?\n        where=np._NoValue, # Elements to include in reduction. See `numpy.ufunc.reduce` for details. New in version 1.20.0.\n        ) -&gt; np.ndarray|bool: # A new boolean or array, or a reference to `out` if its specified.\n    \"Test whether all array elements along a given axis evaluate to `True`.\"\n    ...\n\nWe can observe the following differences between this code and numpy-docstrings:\n\nThe definition uses simple type annotations, which will be rendered in the function’s parameters table below\nParameters are described with a short comment, called docments – a concise alternative to numpy and sphinx docstring formats (although nbdev does support numpy docstrings see this example)\nThe docstring and parameter descriptions are all short, single-line summaries. We prefer to keep docstrings short and instead elaborate in separate cells, where we can use markdown and real code examples.\n\nNote: the use of | syntax for unions e.g. int|tuple|None (equivalent to Union[int, tuple, None]) requires using Python 3.10 or by treating all annotations as strings using from __future__ import annotations which is available from Python 3.7.\nOur function definition is automatically rendered in the docs like this. Note that parameter names, types, defaults, and details are all parsed from the definition which means you don’t have to repeat yourself.\n\n\n\nall\n\n all (a, axis:Union[int,tuple,NoneType]=None,\n      out:Optional[numpy.ndarray]=None, keepdims:bool=&lt;no value&gt;,\n      where=&lt;no value&gt;)\n\nTest whether all array elements along a given axis evaluate to True.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\nInput array or object that can be converted to an array.\n\n\naxis\nint | tuple | None\nNone\nAxis or axes along which a logical AND reduction is performed (default: all).\n\n\nout\nnp.ndarray | None\nNone\nAlternate output array in which to place the result.\n\n\nkeepdims\nbool\n\nLeave reduced one-dimensional axes in the result?\n\n\nwhere\n_NoValueType\n\nElements to include in reduction. See numpy.ufunc.reduce for details. New in version 1.20.0.\n\n\nReturns\nnp.ndarray | bool\n\nA new boolean or array, or a reference to out if its specified.\n\n\n\n\n\nNext, describe how to use your function using markdown cells and lots of code examples. This is the biggest benefit to developing in notebooks: instead of copying and pasting code examples into plaintext, you can include real executeable code examples.\nWe start with basic usage first:\n\nFor example:\n\nx = [[True,False],[True,True]]\ntest_eq(np.all(x), False)\n\n\nOur code examples use assertion functions from fastcore.test, so that they serve as both docs and tests. nbdev_test runs every code cell as a test (unless it’s explicitly marked otherwise), and any error in the cell fails the test.\nHaving described basic usage, we now elaborate on more advanced functionality for each parameter. This differs from numpy’s approach which includes all parameter docs in the table and where not all parameters have code examples.\n\nWith axis:\n\ntest_eq(np.all(x, axis=0), [True,False])\n\naxis may be negative, in which case it counts from the last to the first axis:\n\ntest_eq(np.all(x, axis=-1), [False,True])\n\nIf axis is a tuple of ints, a reduction is performed on multiple axes, instead of a single axis or all the axes as before.\n\ntest_eq(np.all(x, axis=(0,1)), False)\n\nIntegers, floats, not a number (nan), and infinity all evaluate to True because they’re not equal to zero:\n\ntest_eq(np.all([-1, 1, -1.0, 1.0, np.nan, np.inf, -np.inf]), True)\n\nYou can use where to test specific elements. For example, this tests only the second column:\n\ntest_eq(np.all(x, where=[[False],[True]]), True)\n\nThe output can be stored in an optional out array. If provided, a reference to out will be returned:\n\no = np.array(False)\nz = np.all([-1, 4, 5], out=o)\ntest_is(z, o)\ntest_eq(z, True)\n\nout must have the same shape as the expected output and its type is preserved (e.g., if dtype(out) is float, the result will consist of 0.0’s and 1.0’s). See Output type determination for more details.\nWith keepdims, the result will broadcast correctly against the input array.\n\ntest_eq(np.all(x, axis=0, keepdims=True), [[True, False]]) # Note the nested list\n\nIf the default value is passed, then keepdims will not be passed through to the all method of sub-classes of ndarray, however any non-default value will be. If the sub-class’ method does not implement keepdims any exceptions will be raised.\n\nclass MyArray(np.ndarray):\n    def all(self, axis=None, out=None): ...\n\ny = MyArray((2,2))\ny[:] = x\nnp.all(y) # No TypeError since `keepdims` isn't passed\ntest_fail(lambda: np.all(y, keepdims=True), contains=\"all() got an unexpected keyword argument 'keepdims'\")\n\n\nSince we prefer to document via code examples, we also document error-cases with assertions using fastcore.test.test_fail. This differs from docstring-based approaches which usually document error-cases in prose, usually in a “raises” section of the docstring.\nFinally, we link to related symbols with doclinks (symbols surrounded in backticks are automatically linked) and describe their relation using code examples.\n\nThe numpy.ndarray.all method is equivalent to calling numpy.all with the array:\n\ntest_eq(np.array(x).all(), np.all(x))\n\nIn contrast, numpy.any tests whether any element evaluates to True (rather than all elements):\n\ntest_eq(np.any(x), True)\n\n\n\nRecap\nIn summary, here is how the nbdev version of numpy.all differs from the numpy docstring. nbdev uses:\n\nType annotations and docments instead of the numpy docstring format (although nbdev supports numpy docstrings too)\nShort parameter descriptions, with details in separate cells with markdown and code example\nDoclinks to related symbols instead of a “See also” section\nLots of code examples (which are also tests) mixed with prose to describe how to use the function\nCode examples with assertions to document error-cases instead of a “Raises” section.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/best_practices.html#footnotes",
    "href": "tutorials/best_practices.html#footnotes",
    "title": "Notebook Best Practices",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe’re always open to improving our workflows and don’t like to be too prescriptive about style. If you have any ideas, please feel free to post them in the forum.↩︎",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Notebook Best Practices"
    ]
  },
  {
    "objectID": "tutorials/renderscript.html",
    "href": "tutorials/renderscript.html",
    "title": "RenderScripts",
    "section": "",
    "text": "RenderScripts are regular Python scripts, except that:\n\nRather than just having the extension .py, they have an extension like .qmd.py\nThey contain a module docstring containing frontmatter (i.e three hyphens on a line, then some yaml, then another three hyphens on a line).\n\nThese scripts are run when your site is rendered. Anything that they print to stdout becomes a new file in your site. The name of the file is the same as the name of the .py script, but without the .py extension. For instance, the page you’re reading right now page is created by a script called renderscript.qmd.py, which you’ll find here.\nHot/live reloading even works with these .py scripts – so as soon as you save the script, you’ll see the new output in your web browser.\nThis approach can be particularly helpful for generating data-driven documents. For instance, consider this table, containing a list of the people with testimonials on nbdev’s home page:\n\n\n\n\n\n\n\n\n\nName\nPosition\n\n\n\n\n\nChris Lattner\nInventor of Swift and LLVM\n\n\n\nFernando Pérez\nCreator of Jupyter\n\n\n\nDavid Berg\nSoftware Engineer, Netflix\n\n\n\nErik Gaasedelen\nSoftware Engineer, Lyft\n\n\n\nRoxanna Pourzand\nProduct Manager, Transform\n\n\n\nHugo Bowne-Anderson\nHead of Developer Relations, Outerbounds\n\n\n\nWhen creating a table like this, it can be tricky to ensure that markdown is correct and consistent for every row. It can be easier and more maintainable to programatically generate it. The table above is generated from the following python list:\n\ntestimonials = [\n    ('chris-lattner.png', 'Chris Lattner', 'Inventor of Swift and LLVM'),\n    ('fernando-pérez.jpeg', 'Fernando Pérez', 'Creator of Jupyter'),\n    ('david-berg.jpeg', 'David Berg', 'Software Engineer, Netflix'),\n    ('erik-gaasedelen.jpeg', 'Erik Gaasedelen', 'Software Engineer, Lyft'),\n    ('roxanna-pourzand.jpeg', 'Roxanna Pourzand', 'Product Manager, Transform'),\n    ('hugo-bowne-anderson.jpeg', 'Hugo Bowne-Anderson', 'Head of Developer Relations, Outerbounds')\n]\n\nTo produce the table from this python list, the following four lines of code are used:\nprint(qmd.tbl_row(['','Name','Position']))\nprint(qmd.tbl_sep([1,3,4]))\nfor fname,name,position in testimonials:\n    print(qmd.tbl_row([im(fname, 60), name, position]))\ntbl_hdr and tbl_row are two functions imported from the module nbdev.qmd. nbdev.qmd is a small module that has some convenient functions for creating .qmd documents, such as the table creation functions used above. You can see more examples of their use in index.qmd.py, which is the RenderScript which creates the nbdev home page. The nbdev home page is a more idiomatic example of how to use RenderScripts than the current page’s source code – we’re only using RenderScript for the current page to provide a more simple example. In practice, we find that RenderScripts are best used for pages containing a lot of data-driven content, reusable components, and so forth.\nYou can use RenderScripts to create any kind of file. For instance, the SVG below is created dynamically using this script:\n\nOnce you’ve run nbdev_preview or nbdev_docs you’ll find your rendered document in the _proc directory, along with all of your processed notebooks. This can be helpful for debugging. You can also simply call your script directly from the shell (e.g. python renderscript.qmd.py) to view the printed output.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "RenderScripts"
    ]
  },
  {
    "objectID": "tutorials/migrating.html",
    "href": "tutorials/migrating.html",
    "title": "nbdev1 Migration",
    "section": "",
    "text": "nbdev v2 is a new from-scratch rewrite of nbdev that’s not backwards compatible. This page describes the changes you need to make to upgrade your nbdev v1 repo to work with the new version. The steps shown here should work on macOS or Linux (including Windows WSL)\nThe biggest change is that nbdev2 uses Quarto to generate your website, whereas nbdev1 used nbconvert and jekyll. You can use all of Quarto’s features directly in nbdev, so checkout the Quarto website to see all the amazing functionality it supports.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "nbdev1 Migration"
    ]
  },
  {
    "objectID": "tutorials/migrating.html#initial-setup",
    "href": "tutorials/migrating.html#initial-setup",
    "title": "nbdev1 Migration",
    "section": "Initial setup",
    "text": "Initial setup\nIf you’ve pinned nbdev in requirements.txt or settings.ini (e.g nbdev&lt;2) remove the version pin. (If you don’t know what this means, then you don’t have it, so you can ignore this step).\nInstall the latest version of nbdev by typing:\npip install -U nbdev\nor:\nconda install -c fastai nbdev\nYou may need to restart your terminal for the new commands to be visible to your shell.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "nbdev1 Migration"
    ]
  },
  {
    "objectID": "tutorials/migrating.html#upgrade-directives",
    "href": "tutorials/migrating.html#upgrade-directives",
    "title": "nbdev1 Migration",
    "section": "Upgrade directives",
    "text": "Upgrade directives\nnbdev has slightly changed how “directive comments” like export and default_exp work, in order to align with how Quarto does things. Now, instead of just adding a # to the start to indicate a directive (e.g #export), you now need to use #| (e.g #|export). You can also optionally add a space (e.g #| export).\nTo automatically upgrade your directives to the new format, run in the root of your repo:\nnbdev_migrate\nYou should now test that you can export your module by running:\nnbdev_export\nNote that nbdev_export replaces nbdev_build_lib. Run nbdev_export -h to see the options you can pass to it (normally you won’t need to pass any). To see a list of all the commands available in nbdev2, run nbdev_help.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "nbdev1 Migration"
    ]
  },
  {
    "objectID": "tutorials/migrating.html#add-and-remove-files",
    "href": "tutorials/migrating.html#add-and-remove-files",
    "title": "nbdev1 Migration",
    "section": "Add and remove files",
    "text": "Add and remove files\nFirst set a variable with the name of your library, by running the following (replacing “yourlib” with the name of your library’s subdirectory)\nexport LIBNAME=yourlib\nNow run the following:\ngit rm Makefile\ngit add $LIBNAME/_modidx.py\nrm -rf docs\nrm -f .gitconfig \nrm -f .git/hooks/post-merge\n\nrm -f setup.py\ncurl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/styles.css\ncurl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/setup.py\n\ncat &gt;&gt;.gitignore &lt;&lt;EOF\n_docs/\n_proc/\nEOF\nAs you see above, we’ve remove the Makefile – that’s because all the things done by make before are now handled by nbdev commands directly.\n\n\n\n\n\n\nNote\n\n\n\nAll documentation related files should be included in your nbs_path, and all paths should be relative to it. If you have set the nbs_path in your settings.ini file, then copy your styles.css file inside of your nbs_path folder.\n\n\nIf you use GitHub Actions for continuous integration (CI) you can update this to use nbdev too as follows:\nrm -f .github/workflows/main.yml\ncurl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/.github/workflows/test.yaml\ncurl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/.github/workflows/deploy.yaml\nmv deploy.yaml test.yaml .github/workflows/",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "nbdev1 Migration"
    ]
  },
  {
    "objectID": "tutorials/migrating.html#update-directive-names",
    "href": "tutorials/migrating.html#update-directive-names",
    "title": "nbdev1 Migration",
    "section": "Update directive names",
    "text": "Update directive names\nA number of directives have changed names. We’ll use perl to fix them. Run these lines in the root of your repo:\nfind . -name '*.ipynb' -exec perl -pi -e 's/#\\|\\s*hide_input/#| echo: false/' {} +\nfind . -name '*.ipynb' -exec perl -pi -e 's/#\\|\\s*hide_output/#| output: false/' {} +\nfind . -name '*.ipynb' -exec perl -pi -e 's/#\\|\\s*skip/#| eval: false/' {} +\nfind . -name '*.ipynb' -exec perl -pi -e 's/from nbdev.export import notebook2script/from nbdev import nbdev_export/' {} +\nfind . -name '*.ipynb' -exec perl -pi -e 's/notebook2script/nbdev_export/' {} +\nThese change the following directives to use functionality built into Quarto:\n\nhide_input –&gt; echo: false\nhide_output –&gt; output: false\nskip –&gt; eval: false\n\nThey also update the new location and name of the nbdev_export python function.\nIf you have any notebooks that you’ve asked nbdev1 to skip (using all_slow), you’ll need to add a raw cell to the top of your notebook containing YAML frontmatter. The frontmatter needs to include skip_showdoc: true to avoid running cells when rendering docs, and skip_exec: true to skip this notebook when running tests. E.g to do both, you would add a raw cell (or update your existing frontmatter raw cell) to contain:\n---\nskip_showdoc: true\nskip_exec: true\n---\nOr you can also add these flags in a markdown cell,\n# title\n&gt; description\n\n- skip_showdoc: true\n- skip_exec: true",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "nbdev1 Migration"
    ]
  },
  {
    "objectID": "tutorials/migrating.html#edit-workflow-permissions",
    "href": "tutorials/migrating.html#edit-workflow-permissions",
    "title": "nbdev1 Migration",
    "section": "Edit Workflow Permissions",
    "text": "Edit Workflow Permissions\nMake sure your workflow permissions are set to “Read and write permissions”, which you can find in Settings → Actions → General → Workflow permissions:\n\n\n\nGitHub Pages settings\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFailure to set the correct permissions may result in an error message like this:\n fatal: unable to access 'https://github.com/user/repo.git/': The requested URL returned error: 403\n  Error: Action failed with \"The process '/usr/bin/git' failed with exit code 128\"",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "nbdev1 Migration"
    ]
  },
  {
    "objectID": "tutorials/migrating.html#edit-github-pages-permissions",
    "href": "tutorials/migrating.html#edit-github-pages-permissions",
    "title": "nbdev1 Migration",
    "section": "Edit GitHub Pages Permissions",
    "text": "Edit GitHub Pages Permissions\nAt this point you will want to commit the files with the changes you made to GitHub. Wait for GitHub Actions to run and pass. A new branch in your repo will automatically be created called gh-pages. You want to enable GitHub Pages to work off this branch by configuring your Pages to settings to look like this:\nAccess this screen under Settings → Pages\n\nSelect “Deploy from a branch” in the drop down list for Source.\nSpecify gh-pages as the branch\nSpecify the /root as the location\nClick save\n\n\n\n\nActions workflow permissions",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "nbdev1 Migration"
    ]
  },
  {
    "objectID": "tutorials/migrating.html#final-steps",
    "href": "tutorials/migrating.html#final-steps",
    "title": "nbdev1 Migration",
    "section": "Final steps",
    "text": "Final steps\nYou should now edit settings.ini, and change doc_path from docs to _docs, since that’s where nbdev2 will build your website.\nIf you use a custom domain for your website, you should move your CNAME file into the directory containing your notebooks.\nBefore pushing to GitHub, check that your website looks OK locally by running:\nnbdev_preview\nNow prepare to commit to GitHub:\nnbdev_prepare\nYou can now commit to GitHub as usual. Finally, update Github Pages by clicking on the Settings tab in your repo, then click Pages on the left side bar. Set “Source” to gh-pages branch and the /root folder.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "nbdev1 Migration"
    ]
  },
  {
    "objectID": "tutorials/blogging.html",
    "href": "tutorials/blogging.html",
    "title": "Blogging",
    "section": "",
    "text": "Blogging with notebooks can offer a dramatic quality of life improvement over writing in Markdown, especially for blog posts that contain code. Previously, there were no static site generators that supported Jupyter Notebooks as a first-class authoring medium. This previously led us to create fastpages (now deprecated), which extended Jekyll to enable blogging directly with Jupyter.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Blogging"
    ]
  },
  {
    "objectID": "tutorials/blogging.html#background",
    "href": "tutorials/blogging.html#background",
    "title": "Blogging",
    "section": "",
    "text": "Blogging with notebooks can offer a dramatic quality of life improvement over writing in Markdown, especially for blog posts that contain code. Previously, there were no static site generators that supported Jupyter Notebooks as a first-class authoring medium. This previously led us to create fastpages (now deprecated), which extended Jekyll to enable blogging directly with Jupyter.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Blogging"
    ]
  },
  {
    "objectID": "tutorials/blogging.html#enter-quarto",
    "href": "tutorials/blogging.html#enter-quarto",
    "title": "Blogging",
    "section": "Enter Quarto",
    "text": "Enter Quarto\nHowever, there now exists Quarto, a wonderful publishing system with rich support for authoring via Jupyter Notebooks.\nSome helpful resources on getting started with Quarto:\n\nThe Quarto Homepage\nCreating A Blog With Quarto: This page helps you get started with creating a blog.\nA Gallery of Quarto Sites: Good reference examples of using Quarto.\nThe Quarto Website: The Quarto website is built with Quarto and they use some of its advanced functionality. It is instructive to look through this project to understand how Quarto works.\n\n\n\n\n\n\n\nYou don’t need nbdev to blog with notebooks\n\n\n\nYou do not need to use nbdev to create a blog with notebooks. However, you may wish to:\n\nIncorporate a blog in your nbdev project’s website\nUse some nbdev functionality in your blog (testing, exporting etc)\n\nWe will discuss these subjects in this article.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Blogging"
    ]
  },
  {
    "objectID": "tutorials/blogging.html#migrating-from-fastpages",
    "href": "tutorials/blogging.html#migrating-from-fastpages",
    "title": "Blogging",
    "section": "Migrating from fastpages",
    "text": "Migrating from fastpages\nIf you previously had a fastpages site, we offer some utilities to help migrate you to Quarto. The migration is not holistic: you will likely have to manually correct some things that we are not able to automate.\nInstructions:\n\nInstall Quarto\nCreate a new repo or directory to migrate your blog to\nIn this new repo, create a quarto blog and install required extensions with the following terminal commands. This will create a minimal project structure for you:\n\nquarto create-project --type website:blog .\nquarto install extension quarto-ext/video\n\nYour new repo will have a posts/ directory. This is where you will copy all of your notebook and markdown posts from fastpages. For example, let’s say your fastpages blog repo is in a sibling directory located at ../blog/, you would copy all the relevant posts like this:\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure you are in root of your quarto directory before executing the below commands. Furthermore, change the commands as appropriate depending on the location of your fastpages repo relative to your current directory.\n\n\ncp -r ../blog/_notebooks/* posts\ncp -r ../blog/_posts/* posts\n\nCopy all images associated with your posts into the posts/ directory. We have to get our images from several places (due to the way Jekyll and fastpages work):\n\ncp ../blog/images/* posts\ncp -r ../blog/images/copied_from_nb/* posts/\n\nMake your posts Quarto compatible with the following command:\n\nnbdev_migrate --path posts\n\n\n\n\n\n\nWhat does nbdev_migrate do?\n\n\n\n\n\nnbdev_migrate does the following things:\n\nFor notebooks\n\nMigrates markdown front matter to raw cell front matter as described here.\nnbdev v1 directives are automatically converted to Quarto directives. Note that we convert everything to Quarto directives (nbdev-specific directives are not relevant for this context)\nMarkdown shortcut for embedding youtube videos and callouts are automatically converted to work with Quarto.\n\n\n\nFor markdown and notebooks\n\nAutomatically creates link aliases so that old links will not break. Jekyll automatically generates URLs differently than Quarto, so this ensures that the Jekyll way is aliased.\nAutomatically corrects image paths\nMakes front matter compatible with Quarto by changing field names and values where necessary\n\n\n\n\n\n\nUpdate the following files:\n\n\n./.gitignore: we suggest adding_site/ as well as dot files .*\n./about.qmd: Add some information about yourself.\n./profile.jpg: optionally change the profile picture.\n\n\nPreview your site with the command quarto preview, and make any necessary adjustments and fix for broken links or Jekyll shortcodes (things with {% ... %}) that need to be converted to Quarto. Search the the Quarto documentation if you need help locating specific Quarto features.\n\n\nConfiguration options: fastpages vs. Quarto\nfastpages (which is based on Jekyll) and Quarto offer different options and configurations for individual posts and at a site level. The tables below enumerate some of the most important features of fastpages and how they map to Quarto. Each link in the last column is specific to the relevant feature.\n\nPost-level options\n\n\n\nJekyll Front Matter\nQuarto\nNotes\n\n\n\n\ntoc: false\nSame\nThere are more options in the Quarto docs\n\n\nbadges: true\nn/a\nNo support yet\n\n\ncomments: true\nsee notes\nQuarto docs\n\n\ncategories: [fastpages, jupyter]\nSame\nQuarto docs\n\n\nimage: images/some_folder/your_image.png\nSame\nQuarto docs\n\n\nhide: false\ndraft: true\nQuarto docs\n\n\nsearch_exclude: true\nsee notes\nQuarto docs\n\n\ntitle\nSame\n \n\n\ndescription\nSame\n \n\n\nsticky_rank\nNot supported\nQuarto docs\n\n\n\n\n\nSite-level options\n\n\n\nJekyll site config\nQuarto\nNotes\n\n\n\n\ntitle\nsee notes\nQuarto docs\n\n\ndescription\nsee notes\nQuarto docs\n\n\ngithub_repo\nsee notes\nQuarto docs\n\n\nurl\nn/a\nDon’t need this\n\n\nbaseurl\nn/a\nDon’t need this\n\n\ntwitter_username\nsearch page in notes for “twitter”\nQuarto docs\n\n\nuse_math\nsee notes \nQuarto docs\n\n\ngoogle_analytics\nwebsite: google-analytics: “UA-XXXXXXXX”\nQuarto docs\n\n\nshow_image\nn/a\nQuarto docs\n\n\nshow_tags\nsee title-block-categories of page in notes\nQuarto docs\n\n\npagination\nwebsite: page-navigation: true\nQuarto docs\n\n\nannotations\ncomments: hypothesis: …\nQuarto docs",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Blogging"
    ]
  },
  {
    "objectID": "tutorials/blogging.html#publishing-your-blog",
    "href": "tutorials/blogging.html#publishing-your-blog",
    "title": "Blogging",
    "section": "Publishing your blog",
    "text": "Publishing your blog\n\n\n\n\n\n\nWarning\n\n\n\nThis section is for stand-alone blogs that are not part of a nbdev documentation site. If you want to create a blog within a nbdev documentation site, see this section.\n\n\nYou can publish your site with the quarto publish command. See the docs for more details.\n\n\n\n\n\n\nGitHub Pages\n\n\n\nIf using GitHub Pages, commit your files to GitHub before publish your site. No GitHub Actions are needed, you can use quarto publish instead. If you want to automate your workflow with GitHub Actions, you can follow these instructions",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Blogging"
    ]
  },
  {
    "objectID": "tutorials/blogging.html#creating-a-blog-within-a-nbdev-project",
    "href": "tutorials/blogging.html#creating-a-blog-within-a-nbdev-project",
    "title": "Blogging",
    "section": "Creating a blog within a nbdev project",
    "text": "Creating a blog within a nbdev project\nIn addition to a stand-alone blog that you might build with Quarto, you might want to include a blogging site in your nbdev project. This website has a blog as well! The easiest way to implement a blog is to emulate the directory structure of this folder. The general steps are:\n\nCreate a blog/ directory in your notebooks folder.\nCreate a index.qmd file in the root of the blog/ directory. Here is an example.\n\nThe frontmatter the index.qmd file signals to Quarto that you intend to create a blog. For example, here is our front matter:\n---\ntitle: nbdev Blog\nsubtitle: News, tips, and commentary about all things nbdev\nlisting:\n  sort: \"date desc\"\n  contents: \"posts\"\n  sort-ui: false\n  filter-ui: false\n  categories: true\n  feed: true\npage-layout: full\n---\nThe listing: field specifies how you want to structure your blog. Feel free to copy ours as-is, but we encourage you to consult the documentation for additional options.\n\nCreate a link to your blog on your site’s navbar so people can find it: To add a link to your blog on your site’s navbar, you must edit the navbar section of _quarto.yml to include a link to your blog’s listing page, which is blog/index.qmd in our example. For nbdev, the relevant part of our _quarto.yml file looks like this: \n\nThe yaml snippet shown below is an abbreviated version of nbdev’s _quarto.yml file.website:\n  navbar:\n    left:\n      - text: \"Blog\"\n        href: blog/index.qmd\nYou can read more about the navbar in the Quarto docs.\n\nCreate a folder for each blog post: This is not strictly required, but we recommend this as a way to keep your blog posts and related assets (pictures, videos etc) organized.\nCreate your first blog post: You can emulate our example or create your own. In each folder, create a index.qmd or index.ipynb file. You can also put images and related assets in the same folder.\n\n\nFolder structure\nBelow is an overview of the general folder structure for a blog within a nbdev site:\nnbs/blog\n├── index.qmd\n└── posts\n    ├── 2022-07-28-nbdev2\n    │   ├── cover.png\n    │   ├── index.qmd\n    │   ├── ...\n    └── 2022-08-25-jupyter-git\n        ├── friendly-conflict.png\n        ├── index.qmd\n        └── ...\n    ...\n\nnbs/blog: this is the folder inside your notebook folder that contains the blog.\nindex.qmd: this is at the root of your blog folder and is the listings page for your blog.\nposts/: this a subdirectory for each blog post.\nYYYY-MM-DD-.../index.{qmd,ipynb}: this is where you author the content of each individual blog post.\n\n\n\nSpecial considerations for nbdev blogs\nIn contrast to standalone Quarto blogs, when you embed a blog in a nbdev website there are the following differences:\n\nYou can use all nbdev directives in addition to Quarto ones. All nbdev features will be available in your nbdev blog in the same way they work for other pages.\nYour site will automatically deploy with GitHub Actions or whatever deployment mechanism you have for your nbdev site, so you do not have to use quarto publish.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Blogging"
    ]
  },
  {
    "objectID": "tutorials/blogging.html#using-nbdev-features-in-blogs-outside-nbdev-projects",
    "href": "tutorials/blogging.html#using-nbdev-features-in-blogs-outside-nbdev-projects",
    "title": "Blogging",
    "section": "Using nbdev features in blogs outside nbdev projects",
    "text": "Using nbdev features in blogs outside nbdev projects\n\n\n\n\n\n\nWarning\n\n\n\nThis section is for stand-alone blogs that are not part of a nbdev documentation site. If you create a blog within a nbdev documentation site, all nbdev features will automatically work.\n\n\nIf you create a standalone blog with Quarto, a limited number of nbdev features can still assist you. For example, we recommend installing Jupyter git hooks. A list of nbdev features available to you are listed in this article.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Blogging"
    ]
  },
  {
    "objectID": "tutorials/blogging.html#creating-a-new-blog-site-from-scratch",
    "href": "tutorials/blogging.html#creating-a-new-blog-site-from-scratch",
    "title": "Blogging",
    "section": "Creating A New Blog Site From Scratch",
    "text": "Creating A New Blog Site From Scratch\nYou can use the quarto CLI to setup a new blog project called myblog with the following command:\nquarto create-project myblog --type website:blog\nYou can then preview your blog project with quarto preview. You can also publish your blog using the quarto publish command.\n\n\n\n\n\n\nAdding a notebook blog post\n\n\n\nTo add a notebook blog post to a blog project created with the above commands, you can add an additional folder under posts/ and name the notebook index.ipynb. You will see existing example blog posts that are index.qmd files in sibling folders you can look at for examples. You will need to add yaml front matter to the first cell of your notebook in the form of a raw cell.\n\n\nFor more information about creating a blog with Quarto, see this guide.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Blogging"
    ]
  },
  {
    "objectID": "tutorials/pre_commit.html",
    "href": "tutorials/pre_commit.html",
    "title": "Pre-Commit Hooks",
    "section": "",
    "text": "We provide hooks for the pre-commit framework to catch and fix uncleaned and unexported notebooks, locally, without having to wait for continuous integration pipelines to run.\nThey might also be useful as an alternative to the Jupyter clean hook if you’re using a notebook editor that isn’t yet supported (e.g. VSCode).",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Pre-Commit Hooks"
    ]
  },
  {
    "objectID": "tutorials/pre_commit.html#install-pre-commit",
    "href": "tutorials/pre_commit.html#install-pre-commit",
    "title": "Pre-Commit Hooks",
    "section": "Install pre-commit",
    "text": "Install pre-commit\n…Install pre-commit (check their latest instructions if you have any difficulty with these commands):\n\npipcondahomebrew (macOS)\n\n\npip install pre-commit\n\n\nconda install -c conda-forge pre-commit\n\n\nbrew install pre-commit",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Pre-Commit Hooks"
    ]
  },
  {
    "objectID": "tutorials/pre_commit.html#configure-pre-commit-for-your-repo",
    "href": "tutorials/pre_commit.html#configure-pre-commit-for-your-repo",
    "title": "Pre-Commit Hooks",
    "section": "Configure pre-commit for your repo",
    "text": "Configure pre-commit for your repo\nCreate a file named .pre-commit-config.yaml in the root of your repo, with the following contents:\nrepos:\n- repo: https://github.com/fastai/nbdev\n  rev: 2.2.10\n  hooks:\n  - id: nbdev_clean\n  - id: nbdev_export\nInclude only the hook(s) you’d like to run, as well as any other supported hooks.\n\n\n\n\n\n\nTip\n\n\n\nIf you expect all collaborators to use pre-commit, add the .pre-commit-config.yaml file to your repo. Otherwise, add it to your .gitignore.\n\n\nInstall pre-commit hooks into your repo:\npre-commit install",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Pre-Commit Hooks"
    ]
  },
  {
    "objectID": "tutorials/pre_commit.html#make-a-commit-and-enjoy-pre-commit-in-action",
    "href": "tutorials/pre_commit.html#make-a-commit-and-enjoy-pre-commit-in-action",
    "title": "Pre-Commit Hooks",
    "section": "Make a commit and enjoy pre-commit in action",
    "text": "Make a commit and enjoy pre-commit in action\nWhen you do a git commit in a repo that has pre-commit hooks installed, your new workflow will be as follows:\n\npre-commit runs each hook on your staged changes (as in, changes that you git added)\nIf a hook changes files – for example, if a commited notebook wasn’t cleaned – pre-commit stops the commit, leaving those changes as unstaged\nYou can now stage those changes and make any edits required to get pre-commit to pass\nRedo the git commit, and if it succeeds, your commit will be created.\n\nUsing it in practice isn’t as complicated as it might sound. The best way to figure out if it works for you is to give it a try.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Pre-Commit Hooks"
    ]
  },
  {
    "objectID": "tutorials/pre_commit.html#how-to-override-pre-commit-if-you-get-stuck",
    "href": "tutorials/pre_commit.html#how-to-override-pre-commit-if-you-get-stuck",
    "title": "Pre-Commit Hooks",
    "section": "How to override pre-commit if you get stuck",
    "text": "How to override pre-commit if you get stuck\nIf you struggle to get pre-commit to pass a commit that you absolutely think is correct, you can temporarily disable a hook like this:\nSKIP=hook git commit\n…where hook refers to a valid hook in your configuration, for example, to disable the nbdev_export hook:\nSKIP=nbdev_export git commit\nYou can also disable pre-commit entirely with the --no-verify flag:\ngit commit --no-verify\nFinally, if you decide it’s not for you, you can completely remove pre-commit hooks from your repo with:\npre-commit uninstall",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "Pre-Commit Hooks"
    ]
  },
  {
    "objectID": "tutorials/tutorial.html",
    "href": "tutorials/tutorial.html",
    "title": "End-To-End Walkthrough",
    "section": "",
    "text": "The written tutorial below shows you how to create a Python package from scratch using nbdev.\nAlternatively, you can watch this video tutorial where Jeremy Howard and Hamel Husain guide you through a similar process step by step:",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "End-To-End Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/tutorial.html#installation",
    "href": "tutorials/tutorial.html#installation",
    "title": "End-To-End Walkthrough",
    "section": "Installation",
    "text": "Installation\nYou’ll need the following software to complete the tutorial, read on for specific installation instructions:\n\nPython\nA Python package manager: we recommend conda or pip\nJupyter Notebook\nnbdev\nQuarto\n\nIf you haven’t worked with Python before, we recommend getting started with the Anaconda Individual Edition and using the conda package manager.\nNote that you will only need to follow the steps in the installation section once per environment. If you create a new repo, you won’t need to redo these.\n\nInstall JupyterLab\nLaunch a terminal and install JupyterLab by entering:\nconda install -c conda-forge -y jupyterlab\n…or\npip install jupyterlab\n…if you’re using the pip package manager.\nYou can now launch Jupyter by entering:\njupyter lab\nThis should open JupyterLab in a new browser tab:\n\n\n\n\n\n\n\nInstall nbdev\nThe next step is to install nbdev itself. JupyterLab comes with its own terminal, so we’ll use that moving forward.\nIn the Launcher, scroll down to the “Other” section, then click “Terminal”. If the Launcher isn’t opened, you can open it by clicking “File” → “New Launcher”.\nA new tab should open with a blank terminal – it might not look exactly the same, depending on how your shell is configured:\n\n\n\n\n\nFor Mac and Linux, enter:\nconda install -c fastai -y nbdev\n…or for Mac, Linux and Windows:\npip install nbdev\n…if you’re using pip.\n\n\nInstall Quarto\nnbdev provides a command to install the latest version of Quarto. In the terminal, enter:\nnbdev_install_quarto\nYour password may be requested at this point. Since nbdev is open source, you can read the source code of this command to verify that it isn’t doing anything malicious. Or, if you prefer, you may instead follow Quarto’s official installation instructions.\n\n\nInstall Quarto JupyterLab extension\nQuarto provides its own JupyterLab extension that allows it to render Quarto markdown content.\nFor example, here is their notebook demonstrating some of its features:\n\nInstall the extension by entering:\npip install jupyterlab-quarto\nNote that the jupyterlab-quarto package is not currently available via conda.\n\nYou’re all setup and ready to go! Installing these tools may take some time, but you’ll only need to do it once. Next, we’ll setup an nbdev repo for your specific project.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "End-To-End Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/tutorial.html#first-steps",
    "href": "tutorials/tutorial.html#first-steps",
    "title": "End-To-End Walkthrough",
    "section": "First steps",
    "text": "First steps\nBy the end of this section you’ll have your own nbdev repo with tests, continuous integration, streamlined PyPI & conda packaging, and a documentation website.\n\nCreate an empty GitHub repo\nCreate an empty GitHub repo using the convenient link github.com/new. If you get stuck, you might find GitHub’s Create a repo page helpful.\nRemember to add a description, since nbdev will use that later. Don’t add a README file, .gitignore, or license just yet.\nIf you’re using the web interface, it should look something like this (with your own repository name and description) before you click “Create Repository”:\n\n\n\n\n\nYou should then be redirected to your new repo:\n\n\n\n\n\n\n\n\n\n\n\nTry GitHub’s powerful CLI\n\n\n\n\n\nGitHub’s web interface is a great way to get started. As you grow more experienced, you might want to explore the GitHub CLI (command line interface). We often prefer to use command line tools for repetitive tasks where we’re likely to make mistakes. Having those tasks written as small scripts in your terminal means that you can repeat them with little effort.\n\n\n\n\n\nInitialise your repo with nbdev\nNow clone your repo from the Jupyter terminal you started earlier (or create a new terminal following those instructions if needed). If you get stuck here, you might find GitHub’s Cloning a repository page helpful.\nSince we created a repo named nbdev-hello-world with the fastai user, we can clone it as follows:\ngit clone https://github.com/fastai/nbdev-hello-world.git\nThen cd (change directory) to our repo:\ncd nbdev-hello-world\nYou may have seen this message while cloning:\nYou appear to have cloned an empty repository.\n…since the repo is completely empty. Let’s add some files!\nnbdev provides the nbdev_new command to initialise an empty git repository. It’ll infer information about your project from git and GitHub, and ask you to input anything remaining. It will create files in your repo that:\n\nStreamline publishing Python packages to PyPI and conda.\nConfigure Quarto for publication-grade technical documentation.\nSetup GitHub actions to test notebooks and build and deploy Quarto docs to GitHub pages.\n\nInitialise your nbdev repo by entering:\nnbdev_new\nIt may ask you to enter information that it couldn’t infer from git or GitHub.\n\n\n\n\n\n\nNote\n\n\n\nnbdev_new assumes that your package name is the same as your repo name (with - replaced by _). Use the --lib_name option if that isn’t the case.\n\n\nDouble-check your settings.ini file to ensure that it has all of the correct information. Then commit and push your additions to GitHub:\ngit add .\ngit commit -m'Initial commit'\ngit push\n\n\nEnable GitHub Pages\nnbdev hosts your docs on GitHub Pages—an excellent (and free!) way to host websites.\n\n\n\n\n\n\nNote\n\n\n\nnbdev uses GitHub Pages by default because its easily accessible. However, you can use any host you like. See these docs for more information.\n\n\nYou need to enable GitHub Pages for your repo by clicking on the “Settings” tab near the top-right of your repo page, then “Pages” on the left, then setting the “Branch” to “gh-pages”, and finally clicking “Save”.\nIt should look similar to this after you click “Save”:\n\n\n\n\n\nIf you don’t see a “gh-pages” branch, wait a few minutes and reload the page. It should automatically be set up for you.\nNow it’s time to see all of the goodies nbdev gives you!\n\n\nCheck out your workflows\nOpen GitHub Actions by clicking the “Actions” tab near the top of your repo page. You should see two workflow runs:\n\n\n\n\n\nIf you opened this page shortly after pushing your initial commit, the runs may not have a green check (✅) because they’re still “In progress” or “Queued”. That’s no problem, they shouldn’t take much more than a minute to complete.\nIf you see a red cross (❌), that means something failed. Click on the cross, then click “Details”, and you’ll be able to see what failed. If you can’t figure out what’s wrong, search the forum in case someone else resolved the same issue, otherwise create a new post describing your issue in as much detail as you can, and we’ll try our best to help you. Remember that including a link to an actual repo and/or GitHub Action is the best way for us to quickly identify what’s wrong.\nWhat do these workflows do?\n\nCI – The CI (continuous integration) workflow streamlines your developer workflow, particularly with multiple collaborators. Every time you push to GitHub, it ensures that:\n\nYour notebooks and libraries are in sync\nYour notebooks are cleaned of unwanted metadata (which pollute pull requests and git histories and lead to merge conflicts)\nYour notebook tests all pass\n\nDeploy to GitHub Pages – Builds your docs with Quarto and deploys it to GitHub Pages.\n\nWe provide these basic workflows out-of-the-box, however, you can edit their corresponding YAML files in the .github/workflows/ folder to your liking.\n\n\nCheck out your docs\nWhen you enable GitHub Pages you should see a new workflow run: “pages build and deployment”. As the name suggests, this workflow deploys your website contents to GitHub Pages.\n\n\n\n\n\nWait for the workflow run to complete, then open your website. By default it should be available at: https://{user}.github.io/{repo}. For example, you can view fastai’s nbdev-hello-world docs at https://fastai.github.io/nbdev-hello-world.\n\n\n\n\n\n\n\nRecap\nYou now have a base nbdev repo with continuous integration and hosted documentation! Here’s a recap of the steps you took:\n\nCreated a GitHub repo (with GitHub Pages enabled)\nInitialised your repo with nbdev_new\nPushed to GitHub.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "End-To-End Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/tutorial.html#make-your-first-edit",
    "href": "tutorials/tutorial.html#make-your-first-edit",
    "title": "End-To-End Walkthrough",
    "section": "Make your first edit",
    "text": "Make your first edit\nIn this section, you’ll make your first edit to the repo you created in First steps.\n\nInstall hooks for git-friendly notebooks\nStep one when working with Jupyter notebooks in a new repo is to install nbdev’s hooks (you can think of “hooks” as plugins or extensions to an application).\nInstall them by entering this command in your terminal:\nnbdev_install_hooks\n\n\n\n\n\n\nNote\n\n\n\nThe clean hook currently only supports Jupyter Notebook and JupyterLab. If you’re using VSCode, you can try the experimental nbdev VSCode extension. Otherwise, you might also want to try nbdev’s pre-commit hooks.\n\n\nSee Git-friendly Jupyter for more about how nbdev hooks work and how to customise them. Here’s a short summary:\n\nFix broken notebooks due to git merge conflicts so that they can be opened and resolved directly in Jupyter.\nEach time you save a Jupyter notebook, automatically clean unwanted metadata to remove unnecessary changes in pull requests and reduce the chance of git merge conflicts.\nAutomatically trust notebooks in the repo so that you can view widgets from collaborators’ commits. For this reason, you should not install hooks into a repo you don’t trust.\n\n\n\n\n\n\n\nTip\n\n\n\nnbdev’s git hooks work on any git repo, even if it doesn’t use the broader nbdev system.\n\n\n\n\nBuild your library\nYou should now create your package from your notebook by running:\nnbdev_export\nThis will create Python modules for your notebooks. These modules will make up the contents of your Python package.\n\n\nInstall your package\nYou might have noticed that nbdev_new created a Python package in your repo. In our case, it was automatically named nbdev_hello_world by using our repo name nbdev-hello-world and replacing - with _ to make it a valid Python package.\nThe next step is to install your package by entering this into your terminal:\npip install -e '.[dev]'\nThis is the recommended way to make a Python package importable from anywhere in your current environment:\n\n-e – short for “editable”, lets you immediately use changes made to your package without having to reinstall, which is convenient for development.\n. – refers to the current directory.\n[dev] – includes “development” requirements: other packages that your notebooks use solely for documentation or testing.\n\n\n\nPreview your docs\nnbdev is an interactive programming environment that values fast feedback loops. The nbdev_preview command helps achieve this by using Quarto to render your docs on your computer and keep them updated as your edit your notebooks.\nStart the preview by entering this into your terminal:\nnbdev_preview\nIt may say Preparing to preview for a few seconds while it gets started, and will eventually display something like:\nWatching files for changes\nBrowse at http://localhost:3000/\nClick the link to open the preview in a new browser tab. It should look exactly like your online docs.\n\n\n\n\n\n\nTip\n\n\n\nWe often find it useful to keep a preview window open on the side while we’re editing our notebooks in Jupyter.\n\n\n\n\nEdit 00_core.ipynb\nNow, open the nbs/00_core.ipynb file (generated by running nbdev_new earlier) in Jupyter. You don’t have to start your notebook names with a number, but we find it helpful to show the order that your project should be read in – even though it could have been created in a different order.\n\nAdd your own frontmatter\nYou’ll see something that looks a bit like this:\n\ncore\n\nFill in a module description here\n\n#| default_exp core\n\nLet’s explain what these special cells means:\n\nThe first is a markdown cell with nbdev’s markdown frontmatter syntax that defines notebook metadata used by Quarto, our documentation engine (see the frontmatter reference page for more). It contains:\n\nH1 header (“core”) – defining the page title\nQuote (“Fill in a module description here”) – defining the page description\n\nThe second is a code cell with a directive default_exp which decides which module this notebook will export to (see the Directives explanation for more). Currently, it exports to the core module.\n\nNext, rename the notebook, replace the title and description, and change the default export module for your own project.\nOnce you’re done, save the notebook. The live preview started in the previous section should update with your latest changes.\nRerun all cells in your notebook to ensure that they work, and to export the updated modules.\n\n\n\n\n\n\nTip\n\n\n\nWe find the “restart kernel and run all cells” Jupyter command (the ⏩ button) so invaluable that we bind it to a keyboard shortcut. A common criticism of notebooks is that out-of-order execution leads to irreproducible notebooks. In our experience, making “restart and rerun” a habit solves this problem.\n\n\nRunning the notebook exports Python modules because of the last cell which contains:\n#| hide\nimport nbdev; nbdev.nbdev_export()\nWhat does this mean?\n\n#| hide is a directive (like #| default_exp) which excludes a cell from both your exported module and docs\nnbdev_export is the command used to export your notebooks to Python modules.\n\nWe recommend including a cell like this at the bottom of all of the notebooks you want to export.\n\n\n\n\n\n\nWarning\n\n\n\nRemember to delete any unused modules that aren’t exported by a notebook or otherwise needed by your package. This is likely to happen if you change the default export of a notebook – nbdev doesn’t remove the old module. This is intended, since nbdev is designed to work with hybrid packages that use .py modules (with no corresponding notebook) as well as those exported from notebooks.\n\n\n\n\nAdd your own function\nAdd a new code cell below the #| default_exp cell with a function. For example:\n#| export\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nNotice how it includes #| export at the top – this is a directive (like #| default_exp) that tells nbdev to include the cell in your exported module and in your documentation.\nThe documentation should look like this:\n\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody\n\n\n\n\nAdd your own examples, tests, and docs\nOne of the superpowers of notebook-driven development is that you can very easily add examples, tests, and documentation right below your code.\nInclude regular code cells, and they’ll appear (with output) in your docs, for example:\n\nsay_hello(\"Isaac\")\n\n'Hello Isaac!'\n\n\nThis is a test too! When you run nbdev_test it will execute this cell (and all other test cells) and fail if they raise any exceptions.\nFor tests, it’s preferred to use more explicit asserts:\n\nassert say_hello(\"Hamel\") == \"Hello Hamel!\"\n\n…or functions from fastcore.test, which behave like assert but also display the actual and expected values if they differ:\n\nfrom fastcore.test import *\n\n\ntest_eq(say_hello(\"Hamel\"), \"Hello Hamel!\")\n\nAnother superpower of notebook-driven development is that your examples can include plots, images, and even JavaScript widgets. For example, here’s an SVG circle:\n\nfrom IPython.display import display,SVG\n\n\ndisplay(SVG('&lt;svg height=\"100\" xmlns=\"http://www.w3.org/2000/svg\"&gt;&lt;circle cx=\"50\" cy=\"50\" r=\"40\"/&gt;&lt;/svg&gt;'))\n\n\n\n\n\n\n\n\n\n\n\nPrepare your changes\nBefore commiting your changes to GitHub we recommend running nbdev_prepare in the terminal, which bundles the following commands:\n\nnbdev_export: Builds the .py modules from Jupyter notebooks\nnbdev_test: Tests your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extreanous output for git\nnbdev_readme: Updates your repo’s README.md file from your index notebook.\n\n\n\nEdit index.ipynb\nNow you’re ready to personalize your documentation home page and README.md file; these are both generated automatically from index.ipynb. Open Jupyter, then click on nbs/index.ipynb to open it.\nWe recommend including a longer description about what your package does, how to install it, and how to use it (with a few examples which import and use your package). Remember, examples can be code cells with real outputs rather than plain markdown text – they’ll double as tests too!\n\n\nPush to Github\nYou can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then:\ngit add .\ngit commit -m 'Add `say_hello`; update index' # Update this text with your own message\ngit push\nThis will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation.\n\n\nRecap\nCongratulations, you’ve used all of the basics needed to build delightful projects with nbdev! Here’s a recap of the steps you took:\n\nInstalled hooks for git-friendly notebooks with nbdev_install_hooks\nInstalled your package with pip install -e '.[dev]'\nPreviewed your docs with nbdev_preview\nAdded your own frontmatter, function, tests, and docs to nbs/00_core.ipynb\nPrepared your changes with nbdev_prepare\nUpdated nbs/index.ipynb with your own information\nPushed to GitHub.\n\nRead on to learn about more advanced nbdev functionality. Also see our explanations for deep-dives on specific topics, as well as our other tutorials.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "End-To-End Walkthrough"
    ]
  },
  {
    "objectID": "tutorials/tutorial.html#advanced-functionality",
    "href": "tutorials/tutorial.html#advanced-functionality",
    "title": "End-To-End Walkthrough",
    "section": "Advanced functionality",
    "text": "Advanced functionality\n\nAdd a class\nCreate a class in 00_core.ipynb as follows:\n#| export\nclass HelloSayer:\n    \"Say hello to `to` using `say_hello`\"\n    def __init__(self, to): self.to = to\n        \n    def say(self):\n        \"Do the saying\"\n        return say_hello(self.to)\nThis will automatically appear in the docs like this:\n\n\n\nHelloSayer\n\n HelloSayer (to)\n\nSay hello to to using say_hello\n\nDocument with show_doc\nHowever, methods aren’t automatically documented. To add method docs, use show_doc:\nshow_doc(HelloSayer.say)\n\n\n\n\nHelloSayer.say\n\n HelloSayer.say ()\n\nDo the saying\nAnd add some examples and/or tests:\n\no = HelloSayer(\"Alexis\")\no.say()\n\n'Hello Alexis!'\n\n\n\n\nAdd links with backticks\nNotice above there is a link from our new class documentation to our function. That’s because we used backticks in the docstring:\n    \"Say hello to `to` using `say_hello`\"\nThese are automatically converted to hyperlinks wherever possible. For instance, here are hyperlinks to HelloSayer and say_hello created using backticks.\n\n\nSet up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2\n\n\nSet up prerequisites\nIf your module requires other modules as dependencies, you can add those prerequisites to your settings.ini in the requirements section. The requirements should be separated by a space and if the module requires at least or at most a specific version of the requirement this may be specified here, too.\nFor example if your module requires the fastcore module of at least version 1.0.5, the torchvision module of at most version 0.7 and any version of matplotlib, then the prerequisites would look like this:\nrequirements = fastcore&gt;=1.0.5 torchvision&lt;0.7 matplotlib\nIn addition to requirements you can specify dependencies with other keywords that have different scopes. Below is a list of all possible dependency keywords:\n\nrequirements: Passed to both pip and conda setup\npip_requirements: Passed to pip setup only\nconda_requirements: Passed to conda setup only\ndev_requirements: Passed to pip setup as a development requirement\n\nFor more information about the format of dependencies, see the pypi and conda docs on creating specifications in setup.py and meta.yaml, respectively.\n\n\nSet up console scripts\nBehind the scenes, nbdev uses that standard package setuptools for handling installation of modules. One very useful feature of setuptools is that it can automatically create cross-platform console scripts. nbdev surfaces this functionality; to use it, use the same format as setuptools, with whitespace between each script definition (if you have more than one).\nconsole_scripts = nbdev_export=nbdev.cli:nbdev_export\n\n\nUpload to pypi\nIf you want people to be able to install your project by just typing pip install your-project then you need to upload it to pypi. The good news is, we’ve already created a fully pypi compliant installer for your project! So all you need to do is register at pypi (click “Register” on pypi) if you haven’t previously done so, generate an API token (go to Account settings and click “Add API token”) and then create a file called ~/.pypirc with your token details. It should have these contents:\n[pypi]\nusername = __token__\npassword = your_pypi_token\nAnother thing you will need is twine, so you should run once\npip install twine\nTo upload your project to pypi, just type nbdev_pypi in your project root directory. Once it’s complete, a link to your project on pypi is displayed.\n\n\nUpload to conda\nSimilar to pip install support, we have provided an anaconda compliant installer to upload your project to anaconda. Once uploaded, your package can be installed by typing conda install -c your_anaconda_username your-project.\nYou need to register at anaconda (fill out the form to Sign Up) which will create a username and password. You will then need to install the following packages\npip install anaconda-client conda-build conda-verify\nBefore running the anaconda uploader, you need to login to conda using the CLI command (you will be prompted to enter your username and password)\nanaconda login\nTo upload to anaconda, just type nbdev_conda in your project root directory.\n\n\nUpload to pypi and conda\nThe command nbdev_release_both from the root of your nbdev repo will upload your project to both conda and pypi.\n\n\nInstall collapsible headings and toc2\nThere are two jupyter notebook extensions that I highly recommend when working with projects like this. They are:\n\nCollapsible headings: This lets you fold and unfold each section in your notebook, based on its markdown headings. You can also hit left to go to the start of a section, and right to go to the end\nTOC2: This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks, or the TOC sidebar it adds. These can be modified and/or hidden using its settings.\n\n\n\nMath equation support\nnbdev supports equations (using Quarto). You can include math in your notebook’s documentation using the following methods.\nUsing $$, e.g.:\n\\sum_{i=1}^{k+1}i\nWhich is rendered as:\n\n_{i=1}^{k+1}i\n\nUsing $, e.g.:\nThis version is displayed inline: \\sum_{i=1}^{k+1}i . You can include text before and after.\nWhich is rendered as:\n\nThis version is displayed inline: _{i=1}^{k+1}i . You can include text before and after.\n\nFor more information, see the Quarto Docs\n\n\nLook at nbdev “source” for more ideas\nDon’t forget that nbdev itself is written in nbdev! It’s a good place to look to see how fast.ai uses it in practice, and get a few tips. You’ll find the nbdev notebooks here in the nbs folder on Github.\n\n\nQuarto Features\nnbdev supports most Quarto features. We encourage you to read the Quarto documentation to discover all the features available to you. For example, this is how you can incorporate Graphviz:\n\n\n\n\n\n\n\nG\n\n\n\nrun\n\nrun\n\n\n\nintr\n\nintr\n\n\n\nrun--intr\n\n\n\n\nkernel\n\nkernel\n\n\n\nrun--kernel\n\n\n\n\nrunbl\n\nrunbl\n\n\n\nintr--runbl\n\n\n\n\nrunbl--run\n\n\n\n\nzombie\n\nzombie\n\n\n\nkernel--zombie\n\n\n\n\nsleep\n\nsleep\n\n\n\nkernel--sleep\n\n\n\n\nrunmem\n\nrunmem\n\n\n\nkernel--runmem\n\n\n\n\nsleep--runmem\n\n\n\n\nswap\n\nswap\n\n\n\nsleep--swap\n\n\n\n\nrunswap\n\nrunswap\n\n\n\nswap--runswap\n\n\n\n\nrunswap--runmem\n\n\n\n\nnew\n\nnew\n\n\n\nrunswap--new\n\n\n\n\nnew--runmem\n\n\n\n\n\n\n\n\n\nIt is worth taking a look at the documentation for figures, callouts, markdown, widgets, layouts, conditional content and quarto extensions to name a few useful things we have encountered.",
    "crumbs": [
      "Get Started",
      "Tutorials",
      "End-To-End Walkthrough"
    ]
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "nbdev Blog",
    "section": "",
    "text": "Create A 🤗 Space From A Notebook\n\n\n\n\n\nA demo of using nbdev with Hugging Face Spaces & Gradio.\n\n\n\n\n\nNov 7, 2022\n\n\nHamel Husain\n\n\n\n\n\n\n\n\n\n\n\n\nThe Jupyter+git problem is now solved\n\n\n\n\n\nPreviously, using git with Jupyter could create conflicts and break notebooks. With nbdev2, the problem has been totally solved.\n\n\n\n\n\nAug 25, 2022\n\n\nJeremy Howard\n\n\n\n\n\n\n\n\n\n\n\n\nnbdev+Quarto: A new secret weapon for productivity\n\n\n\n\n\nOur favorite tool for software engineering productivity–nbdev, now re-written with Quarto\n\n\n\n\n\nJul 28, 2022\n\n\nHamel Husain, Jeremy Howard\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html",
    "title": "The Jupyter+git problem is now solved",
    "section": "",
    "text": "Originally posted on the fast.ai blog"
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html#the-jupytergit-problem",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html#the-jupytergit-problem",
    "title": "The Jupyter+git problem is now solved",
    "section": "The Jupyter+git problem",
    "text": "The Jupyter+git problem\nJupyter notebooks are a powerful tool for scientists, engineers, technical writers, students, teachers, and more. They provide an ideal notebook environment for interactively exploring data and code, writing programs, and documenting the results as dashboards, books, or blogs.\nBut when collaborating with others, this ideal environment goes up in smoke. That’s because tools such as git, which are the most popular approaches for asynchronous collaboration, makes notebooks unusable. Literally. Here’s what it looks like if you and a colleague both modify a notebook cell (including, in many cases, simply executing a cell withuout changing it), and then try to open that notebook later:\n\n\n\nWhat merge conflicts normally do to Jupyter Notebooks\n\n\nThe reason for this stems from a fundamental incompatibility between the format Jupyter notebooks use (JSON) and the format that git conflict markers assume by default (plain lines of text). This is what it looks like when git adds its conflict markers to a notebook:\n\n   \"source\": [\n&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n    \"z=3\\n\",\n======\n    \"z=2\\n\",\n&gt;&gt;&gt;&gt;&gt;&gt; a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n    \"z\"\n   ]\n\nThat’s not valid JSON, and therefore Jupyter can’t open it. Conflicts are particularly common in notebooks, because Jupyter changes the following every time you run a notebook:\n\nEvery cell includes a number indicating what order it was run in. If you and a colleague run the cells in different orders, you’ll have a conflict in every single cell! This would take a very long time to fix manually\nFor every figure, such as a plot, Jupyter includes not only the image itself in the notebook, but also a plain text description that includes the id (like a memory address) of the object, such as &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbc113dbe90&gt;. This changes every time you execute a notebook, and therefore will create a conflict every time two people execute this cell\nSome outputs may be non-deterministic, such as a notebook that uses random numbers, or that interacts with a service that provides different outputs over time (such as a weather service)\nJupyter adds metadata to the notebook describing the environment it was last run in, such as the name of the kernel. This often varies across installations, and therefore two people saving a notebook (even without and other changes) will often end up with a conflict in the metadata.\n\nAll these changes to notebook files also make git diffs of notebooks very verbose. This can make code reviews a challenge, and make git repos more bulky than necessary.\nThe result of these problems is that many Jupyter users feel that collaborating with notebooks is a clunky, error-prone, and frustrating experience. (We’ve even seen people on social media describe Jupyter’s notebook format as “stupid” or “terrible”, despite otherwise professing their love for the software!)\nIt turns out, however, that Jupyter and git can work together extremely well, with none of the above problems at all. All that’s needed is a bit of special software…"
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html#the-solution",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html#the-solution",
    "title": "The Jupyter+git problem is now solved",
    "section": "The solution",
    "text": "The solution\nJupyter and git are both well-designed software systems that provide many powerful extensibility mechanisms. It turns out that we can use these to fully and automatically solve the Jupyter+git problem. We identified two categories of problems in the previous section:\n\ngit conflicts lead to broken notebooks\nUnnecessary conflicts due to metadata and outputs.\n\nIn our newly released nbdev2, an open source Jupyter-based development platform, we’ve solve each of the problems:\n\nA new merge driver for git provides “notebook-native” conflict markers, resulting in notebooks that can be opened directly in Jupyter, even when there are git conflicts\nA new save hook for Jupyter automatically removes all unnecessary metadata and non-deterministic cell output.\n\nHere’s what a conflict looks like in Jupyter with nbdev’s merge driver:\n\n\n\nAs you see, the local and remote change are each clearly displayed as separate cells in the notebook, allowing you to simply delete the version you don’t want to keep, or combine the two cells as needed.\nThe techniques used to make the merge driver work are quite fascinating – let’s dive into the details!\n\nThe nbdev2 git merge driver\nWe provide here a summary of the git merge driver – for full details and source code see the nbdev.merge docs. Amazingly enough, the entire implementation is just 58 lines of code!\nThe basic idea is to first “undo” the original git merge which created the conflict, and then “redo” it at a cell level (instead of a line level) and looking only at cell source (not outputs or metadata). The “undoing” is straightforward: just create two copies of the conflicted file (representing the local and remove versions of the file), go through each git conflict marker, and replace the conflict section with either the local or remote version of the code.\nNow that we’ve got the original local and remote notebooks, we can load the json using execnb.nbio, which will then give us an array of cells for each notebook. Now we’re up to the interesting bit – creating cell-level diffs based only on the cell source.\nThe Python standard library contains a very flexible and effective implementation of a diff algorithm in the difflib module. In particular, the SequenceMatcher class provides the fundamental building blocks for implementing your own conflict resolution system. We pass the two sets of cells (remote and local) to SequenceMatcher(...).get_matching_blocks(), and it returns a list of each section of cells that match (i.e. have no conflicts/differences). We can then go through each matching section and copy them into the final notebook, and through each non-matching section and copy in each of the remote and local cells (add cells between them to mark the conflicts).\nMaking SequenceMatcher work with notebook cells (represented in nbdev by the NbCell class) requires only adding __hash__ and __eq__ methods to NbCell. In each case, these methods are defined to look only at the actual source code, and not at any metadata or outputs. As a result, SequenceMatcher will only show differences in source code, and will ignore differences in everything else.\nWith a single line of configuration, we can ask git to call our python script, instead of its default line-based implementation, any time it is merging changes. nbdev_install_hooks sets up this configuration automatically, so after running it, git conflicts become much less common, and never result in broken notebooks.\n\n\nThe nbdev2 Jupyter save hook\nSolving git merges locally is extremely helpful, but we need to solve them remotely as well. For instance, if a contributor submits a pull request (PR), and then someone else commits to the same notebook before the PR is merged, the PR might now have a conflict like this:\n\n   \"outputs\": [\n    {\n&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n     \"execution_count\": 7,\n======\n     \"execution_count\": 5,\n&gt;&gt;&gt;&gt;&gt;&gt; a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n     \"metadata\": {},\n\nThis conflict shows that the two contributors have run cells in different orders (or perhaps one added a couple of cells above in the notebook), so their commits have conflicting execution counts. GitHub will refuse to allow this PR to be merged until this conflict is fixed.\nBut of course we don’t really care about the conflict at all – it doesn’t matter what, if any, execution count is stored in the notebook. So we’d really prefer to ignore this difference entirely!\nThankfully, Jupyter provides a “pre-save” hook which allows code to be run every time a notebook is saved. nbdev uses this to set up a hook which removes all unnecessary metadata (including execution_count) on saving. That means there’s no pointless conflicts like the one above, because no commits will have this information stored in the first place."
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html#background",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html#background",
    "title": "The Jupyter+git problem is now solved",
    "section": "Background",
    "text": "Background\nHere at fast.ai we use Jupyter for everything. All our tests, documentation, and module source code for all of our many libraries is entirely developed in notebooks (using nbdev, of course!) And we use git for all our libraries too. Some of our repositories have many hundreds of contributors. Therefore solving the Jupyter+git problem has been critical for us. The solution presented here is the result of years of work by many people.\nOur first approach, developed by Stas Bekman and me, was to use git “smudge” and “clean” filters that automatically rewrote all notebook json to remove unneeded metadata when committing. This helped a bit, but git quite often ended up in an odd state where it was impossible to merge.\nIn nbdev v1 Sylvain Gugger created an amazing tool called nbdev_fix_merge which used very clever custom logic to manually fix merge conflicts in notebooks, to ensure that they could opened in Jupyter. For nbdev v2 I did a from-scratch rewrite of every part of the library, and I realised that we could replace the custom logic with the SequenceMatcher approach described above.\nNone of these steps fully resolved the Jupyter+git problem, since we were getting frequent merge errors caused by the smudge/clean git filters, and conflicts required manually running nbdev_fix_merge. Wasim Lorgat realised that we could resolve the smudge/clean issue by moving that logic into an nbdev save hook, and avoid the manual fix step by moving that logic into a git merge driver. This resolved the final remaining issues! (I was actually quite stunned that Wasim went from our first discussion of the outstanding problems, to figuring out how to solve all of them, in the space of about two days…)"
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html#the-result",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html#the-result",
    "title": "The Jupyter+git problem is now solved",
    "section": "The result",
    "text": "The result\nThe new tools in nbdev2, which we’ve been using internally for the last few months, have been transformational to our workflow. The Jupyter+git problem has been totally solved. I’ve seen no unnecessary conflicts, cell-level merges have worked like magic, and on the few occassions where I’ve changed the source in the same cell as a collaborator, fixing the conflict in Jupyter has been straightforward and convenient."
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html#postscript-other-jupytergit-tools",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html#postscript-other-jupytergit-tools",
    "title": "The Jupyter+git problem is now solved",
    "section": "Postscript: other Jupyter+git tools",
    "text": "Postscript: other Jupyter+git tools\n\nReviewNB\nThere is one other tool which we’ve found very helpful in using Jupyter with git, which is ReviewNB. ReviewNB solves the problem of doing pull requests with notebooks. GitHub’s code review GUI only works well for line-based file formats, such as plain python scripts. This works fine with the Python modules that nbdev exports, and I often do reviews directly on the Python files, instead of the source notebooks.\nHowever, much of the time I’d rather do reviews on the source notebooks, because:\n\nI want to review the documentation and tests, not just the implementation\nI want to see the changes to cell outputs, such as charts and tables, not just the code.\n\nFor this purpose, ReviewNB is perfect. Just like nbdev makes git merges and commits Jupyter-friendly, ReviewNB makes code reviews Jupyter-friendly. A picture is worth a thousand words, so rather than trying to explain, I’ll just show this picture from the ReviewNB website of what PRs look like in their interface:\n\n\n\nAn alternative solution: Jupytext\nAnother potential solution to the Jupyter+git problem might be to use Jupytext. Jupytext saves notebooks in a line-based format, instead of in JSON. This means that all the usual git machinery, such as merges and PRs, works fine. Jupytext can even use Quarto’s format, qmd, as a format for saving notebooks, which then can be used to generate a website.\nJupytext can be a bit tricky to manage when you want to save your cell outputs (which I generally want to do, since many of my notebooks take a long time to run – e.g training deep learning models.) Whilst Jupytext can save outputs in a linked ipynb file, managing this linkage gets complex, and ends up with the Jupyter+git problem all over again! If you don’t need to save outputs, then you might find Jupytext sufficient – although of course you’ll miss out on the cell-based code reviews of ReviewNB and your users won’t be able to read your notebooks properly when they’re browsing GitHub.\n\n\nnbdime\nThere’s also an interesting project called nbdime which has its own git drivers and filters. Since they’re not really compatible with nbdev (partly because they tackle some of the same problems in different ways) I haven’t used them much, so haven’t got an informed opinion about them. However I do use nbdime’s Jupyter extension sometimes, which provides a view similar to ReviewNB, but for local changes instead of PRs.\nIf you want to try to yourself, follow the directions on Git-friendly Jupyter to get started."
  },
  {
    "objectID": "api/cli.html",
    "href": "api/cli.html",
    "title": "cli",
    "section": "",
    "text": "source",
    "crumbs": [
      "Get Started",
      "API",
      "cli"
    ]
  },
  {
    "objectID": "api/cli.html#help",
    "href": "api/cli.html#help",
    "title": "cli",
    "section": "Help",
    "text": "Help\n\nsource\n\nchelp\n\n chelp ()\n\nShow help for all console scripts\n\nchelp()\n\nnb_export                 Export a single nbdev notebook to a python script.\nnbdev_bump_version        Increment version in settings.ini by one\nnbdev_changelog           Create a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_clean               Clean all notebooks in `fname` to avoid merge conflicts\nnbdev_conda               Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it\nnbdev_create_config       Create a config file.\nnbdev_docs                Create Quarto docs and README.md\nnbdev_export              Export notebooks in `path` to Python modules\nnbdev_filter              A notebook filter for Quarto\nnbdev_fix                 Create working notebook from conflicted notebook `nbname`\nnbdev_help                Show help for all console scripts\nnbdev_install             Install Quarto and the current library\nnbdev_install_hooks       Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nnbdev_install_quarto      Install latest Quarto on macOS or Linux, prints instructions for Windows\nnbdev_merge               Git merge driver for notebooks\nnbdev_migrate             Convert all markdown and notebook files in `path` from v1 to v2\nnbdev_new                 Create an nbdev project.\nnbdev_prepare             Export, test, and clean notebooks, and render README if needed\nnbdev_preview             Preview docs locally\nnbdev_proc_nbs            Process notebooks in `path` for docs rendering\nnbdev_pypi                Create and upload Python package to PyPI\nnbdev_readme              Create README.md from readme_nb (index.ipynb by default)\nnbdev_release_both        Release both conda and PyPI packages\nnbdev_release_gh          Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\nnbdev_release_git         Tag and create a release in GitHub for the current version\nnbdev_requirements        Writes a `requirements.txt` file to `directory` based on settings.ini.\nnbdev_sidebar             Create sidebar.yml\nnbdev_test                Test in parallel notebooks matching `path`, passing along `flags`\nnbdev_trust               Trust notebooks matching `fname`\nnbdev_update              Propagate change in modules matching `fname` to notebooks that created them\nnbdev_update_license      Allows you to update the license of your project.\nwatch_export              Use `nb_export` on ipynb files in `nbs` directory on changes using nbdev config if available",
    "crumbs": [
      "Get Started",
      "API",
      "cli"
    ]
  },
  {
    "objectID": "api/serve.html",
    "href": "api/serve.html",
    "title": "serve",
    "section": "",
    "text": "source\n\nproc_nbs\n\n proc_nbs (path:str='', n_workers:int=4, force:bool=False,\n           file_glob:str='', file_re:str='', symlinks:bool=False,\n           folder_re:str=None, skip_file_glob:str=None,\n           skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nProcess notebooks in path for docs rendering\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nPath to notebooks\n\n\nn_workers\nint\n4\nNumber of workers\n\n\nforce\nbool\nFalse\nIgnore cache and build all\n\n\nfile_glob\nstr\n\nOnly include files matching glob\n\n\nfile_re\nstr\n\nOnly include files matching glob\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex",
    "crumbs": [
      "Get Started",
      "API",
      "serve"
    ]
  },
  {
    "objectID": "api/release.html",
    "href": "api/release.html",
    "title": "release",
    "section": "",
    "text": "nbdev.release provides 3 commands that you can run from your shell to manage your changelog file and git releases:\n\nnbdev_changelog: creates a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_release_git: tags and creates a release in GitHub for the current version\nnbdev_release_gh: calls nbdev_changelog, lets you edit the result, then pushes to git and calls nbdev_release_git\n\nIt provides 3 futher commands for releasing packages on pypi or conda:\n\nnbdev_pypi: Create and upload a pypi installer\nnbdev_conda: Create and upload a conda installer\nnbdev_release_both: Create and upload both pypi and conda installers\n\nHere’s a brief demonstration of how to use the changelog and git release tools in nbdev.release. This demo first creates an issue using the gh command line tool, and then closes it using git; you can also use GitHub’s web interface for both of these tasks. (Note that this functionality used to be in a project called fastrelease, so in the video the command line tools have different names, starting with fastrelease_ instead of nbdev_).\n\n\n\nYou’ll need to get a GitHub personal access token if you haven’t already. To do so, click here and enter “nbdev” in the “Note” section, and click the repo checkbox.\nThen click “Generate Token” at the bottom of the screen, and copy the token (the long string of letters and numbers shown). You can easily do that by clicking the little clipboard icon next to the token.\n\nIt’s easiest to save the token as an environment variable GITHUB_TOKEN that can be automatically accessed. We recommend you do this is by adding the following to the end of your .bashrc or .zshrc file:\nexport GITHUB_TOKEN=xxx\n…and then replace the xxx with the token you just copied. It will automatically be avaialble whenever you start a new shell (but don’t forget to source that file or open a new shell after you change it.).\n\n\n\nNow you’re ready to create your release notes. These are created in a file called CHANGELOG.md. Here’s an example of what it creates: nbdev CHANGELOG.\nAll issues with the label bug, enhancement, or breaking that have been closed in your repo since your last release will be added to the top of this file. If you haven’t made any releases before, then all issues with those labels will be included.\nTherefore, before you create or update CHANGELOG.md, go to your GitHub issues page, remove is:open from the filter, and label any issues you want included with one of the labels above. When you’ve done that, you can create or update your release notes by running in your terminal:\nnbdev_changelog\nThe titles and bodies of each issue will be added. Open CHANGELOG.md in your editor and make any edits that you want, and then commit the file to your repo (remember to git add it!)\n\n\n\nYou should now tag a release. This will create a tag in GitHub with your current version number in settings.ini, and will then make it into a release, using your latest release notes as the description of the release:\nnbdev_release_git\nAfter you run this, be sure to increment your version number in settings.ini. You can either edit it manually, or if you use nbdev it can be done for you by running:\nnbdev_bump_version\n\n\n\nTo complete both of the steps above, run:\nnbdev_release_gh\nSee the screencast above for a demonstration of this.",
    "crumbs": [
      "Get Started",
      "API",
      "release"
    ]
  },
  {
    "objectID": "api/release.html#overview",
    "href": "api/release.html#overview",
    "title": "release",
    "section": "",
    "text": "nbdev.release provides 3 commands that you can run from your shell to manage your changelog file and git releases:\n\nnbdev_changelog: creates a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_release_git: tags and creates a release in GitHub for the current version\nnbdev_release_gh: calls nbdev_changelog, lets you edit the result, then pushes to git and calls nbdev_release_git\n\nIt provides 3 futher commands for releasing packages on pypi or conda:\n\nnbdev_pypi: Create and upload a pypi installer\nnbdev_conda: Create and upload a conda installer\nnbdev_release_both: Create and upload both pypi and conda installers\n\nHere’s a brief demonstration of how to use the changelog and git release tools in nbdev.release. This demo first creates an issue using the gh command line tool, and then closes it using git; you can also use GitHub’s web interface for both of these tasks. (Note that this functionality used to be in a project called fastrelease, so in the video the command line tools have different names, starting with fastrelease_ instead of nbdev_).\n\n\n\nYou’ll need to get a GitHub personal access token if you haven’t already. To do so, click here and enter “nbdev” in the “Note” section, and click the repo checkbox.\nThen click “Generate Token” at the bottom of the screen, and copy the token (the long string of letters and numbers shown). You can easily do that by clicking the little clipboard icon next to the token.\n\nIt’s easiest to save the token as an environment variable GITHUB_TOKEN that can be automatically accessed. We recommend you do this is by adding the following to the end of your .bashrc or .zshrc file:\nexport GITHUB_TOKEN=xxx\n…and then replace the xxx with the token you just copied. It will automatically be avaialble whenever you start a new shell (but don’t forget to source that file or open a new shell after you change it.).\n\n\n\nNow you’re ready to create your release notes. These are created in a file called CHANGELOG.md. Here’s an example of what it creates: nbdev CHANGELOG.\nAll issues with the label bug, enhancement, or breaking that have been closed in your repo since your last release will be added to the top of this file. If you haven’t made any releases before, then all issues with those labels will be included.\nTherefore, before you create or update CHANGELOG.md, go to your GitHub issues page, remove is:open from the filter, and label any issues you want included with one of the labels above. When you’ve done that, you can create or update your release notes by running in your terminal:\nnbdev_changelog\nThe titles and bodies of each issue will be added. Open CHANGELOG.md in your editor and make any edits that you want, and then commit the file to your repo (remember to git add it!)\n\n\n\nYou should now tag a release. This will create a tag in GitHub with your current version number in settings.ini, and will then make it into a release, using your latest release notes as the description of the release:\nnbdev_release_git\nAfter you run this, be sure to increment your version number in settings.ini. You can either edit it manually, or if you use nbdev it can be done for you by running:\nnbdev_bump_version\n\n\n\nTo complete both of the steps above, run:\nnbdev_release_gh\nSee the screencast above for a demonstration of this.",
    "crumbs": [
      "Get Started",
      "API",
      "release"
    ]
  },
  {
    "objectID": "api/release.html#python-api",
    "href": "api/release.html#python-api",
    "title": "release",
    "section": "Python API",
    "text": "Python API\n\nsource\n\nRelease\n\n Release (owner=None, repo=None, token=None, **groups)\n\nCreate CHANGELOG.md from GitHub issues\nTo create a markdown changelog, first create a Release object, optionally passing a mapping from GitHub labels to markdown titles. Put your github token in a file named token at the root of your repo. Release attempts to fetch values for arguments from the following locations if not supplied:\n\nowner: fetched from the field user in settings.ini. This is the owner name of the repository on GitHub. For example for the repo fastai/fastcore the owner would be fastai.\nrepo: fetched from the field lib_name in settings.ini. This is the name of the repository on GitHub. For example for the repo fastai/fastcore the owner would be fastcore.\ntoken: fetched from a file named token at the root of your repo. Creating a token is discussed in the setup section.\ngroups: (optional) fetched from the field label_groups in settings.ini, which is a JSON string. This is a mapping from label names to titles in your release notes. If not specified, this defaults to:\n\n{\"breaking\": \"Breaking Changes\", \"enhancement\":\"New Features\", \"bug\":\"Bugs Squashed\"}\n\nsource\n\n\nRelease.changelog\n\n Release.changelog (debug=False)\n\nCreate the CHANGELOG.md file, or return the proposed text if debug is True\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndebug\nbool\nFalse\nJust print the latest changes, instead of updating file\n\n\n\n\nrel = Release()\n# print(rel.changelog(debug=True))\n\n\nsource\n\n\nRelease.release\n\n Release.release ()\n\nTag and create a release in GitHub for the current version\nThis uses the version information from your settings.ini.\n\nsource\n\n\nRelease.latest_notes\n\n Release.latest_notes ()\n\nLatest CHANGELOG entry\nAll relevant pull requests and issues are fetched from the GitHub API, and are categorized according to a user-supplied mapping from labels to markdown headings.",
    "crumbs": [
      "Get Started",
      "API",
      "release"
    ]
  },
  {
    "objectID": "api/release.html#cli-functions",
    "href": "api/release.html#cli-functions",
    "title": "release",
    "section": "CLI functions",
    "text": "CLI functions\n\nsource\n\nchangelog\n\n changelog (debug:&lt;function store_true&gt;=False, repo:str=None)\n\nCreate a CHANGELOG.md file from closed and labeled GitHub issues\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndebug\nstore_true\nFalse\nPrint info to be added to CHANGELOG, instead of updating file\n\n\nrepo\nstr\nNone\nrepo to use instead of lib_name from settings.ini\n\n\n\n\nsource\n\n\nrelease_git\n\n release_git (token:str=None)\n\nTag and create a release in GitHub for the current version\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntoken\nstr\nNone\nOptional GitHub token (otherwise token file is used)\n\n\n\n\nsource\n\n\nrelease_gh\n\n release_gh (token:str=None)\n\nCalls nbdev_changelog, lets you edit the result, then pushes to git and calls nbdev_release_git\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntoken\nstr\nNone\nOptional GitHub token (otherwise token file is used)",
    "crumbs": [
      "Get Started",
      "API",
      "release"
    ]
  },
  {
    "objectID": "api/release.html#publish-packages",
    "href": "api/release.html#publish-packages",
    "title": "release",
    "section": "Publish Packages",
    "text": "Publish Packages\n\nsource\n\npypi_json\n\n pypi_json (s)\n\nDictionary decoded JSON for PYPI path s\n\nsource\n\n\nlatest_pypi\n\n latest_pypi (name)\n\nLatest version of name on pypi\n\nsource\n\n\npypi_details\n\n pypi_details (name)\n\nVersion, URL, and SHA256 for name from pypi\n\nsource\n\n\nconda_output_path\n\n conda_output_path (name, build='build')\n\nOutput path for conda build\n\nsource\n\n\nwrite_conda_meta\n\n write_conda_meta (path='conda')\n\nWrites a meta.yaml file to the conda directory of the current directory\nThis function is used in the conda_package CLI command.\nNB: you need to first of all upload your package to PyPi, before creating the conda package.\n\nsource\n\n\nwrite_requirements\n\n write_requirements (path:str='')\n\nWrites a requirements.txt file to directory based on settings.ini.\nThis function can be used in situations where you need to generate a requirements.txt file for a project.\n\nsource\n\n\nanaconda_upload\n\n anaconda_upload (name, loc=None, user=None, token=None, env_token=None)\n\nUpload name to anaconda\n\nfrom fastcore.xtras import globtastic\n\n\nsource\n\n\nrelease_conda\n\n release_conda (path:str='conda', do_build:&lt;function bool_arg&gt;=True,\n                build_args:str='', skip_upload:&lt;function\n                store_true&gt;=False, mambabuild:&lt;function store_true&gt;=False,\n                upload_user:str=None)\n\nCreate a meta.yaml file ready to be built into a package, and optionally build and upload it\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nconda\nPath where package will be created\n\n\ndo_build\nbool_arg\nTrue\nRun conda build step\n\n\nbuild_args\nstr\n\nAdditional args (as str) to send to conda build\n\n\nskip_upload\nstore_true\nFalse\nSkip anaconda upload step\n\n\nmambabuild\nstore_true\nFalse\nUse mambabuild (requires boa)\n\n\nupload_user\nstr\nNone\nOptional user to upload package to\n\n\n\n\nsource\n\n\nchk_conda_rel\n\n chk_conda_rel (nm:str, apkg:str=None, channel:str='fastai',\n                force:&lt;function store_true&gt;=False)\n\nPrints GitHub tag only if a newer release exists on Pypi compared to an Anaconda Repo.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnm\nstr\n\nPackage name on pypi\n\n\napkg\nstr\nNone\nAnaconda Package (defaults to {nm})\n\n\nchannel\nstr\nfastai\nAnaconda Channel\n\n\nforce\nstore_true\nFalse\nAlways return github tag\n\n\n\nTo build and upload a conda package, cd to the root of your repo, and then:\nnbdev_conda_package\nOr to do things more manually:\nnbdev_conda_package --do_build false\ncd conda\nconda build --no-anaconda-upload --output-folder build {name}\nanaconda upload build/noarch/{name}-{ver}-*.tar.bz2\nAdd --debug to the conda build command to debug any problems that occur. Note that the build step takes a few minutes. Add -u {org_name} to the anaconda upload command if you wish to upload to an organization, or pass upload_user to nbdev_conda_package.\nNB: you need to first of all upload your package to PyPi, before creating the conda package.\n\nsource\n\n\nrelease_pypi\n\n release_pypi (repository:str='pypi')\n\nCreate and upload Python package to PyPI\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepository\nstr\npypi\nRespository to upload to (defined in ~/.pypirc)\n\n\n\nUse --repository flag to upload to TestPypi (e.g. nbdev_pypi --repository testpypi) and custom/private repositories.\nThe ~/.pypirc file can be updated to configure the additional repositories, see example below:\n[distutils]\nindex-servers =\n    pypi\n    testpypi\n    private-repository\n\n[pypi]\nusername = __token__\npassword = &lt;PyPI token&gt;\n\n[testpypi]\nusername = __token__\npassword = &lt;TestPyPI token&gt;\n\n[private-repository]\nrepository = &lt;private-repository URL&gt;\nusername = &lt;private-repository username&gt;\npassword = &lt;private-repository password&gt;\nUse nbdev_pypi --repository private-repository to upload to the private repository.\n\nsource\n\n\nrelease_both\n\n release_both (path:str='conda', do_build:&lt;function bool_arg&gt;=True,\n               build_args:str='', skip_upload:&lt;function store_true&gt;=False,\n               mambabuild:&lt;function store_true&gt;=False,\n               upload_user:str=None, repository:str='pypi')\n\nRelease both conda and PyPI packages\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nconda\nPath where package will be created\n\n\ndo_build\nbool_arg\nTrue\nRun conda build step\n\n\nbuild_args\nstr\n\nAdditional args (as str) to send to conda build\n\n\nskip_upload\nstore_true\nFalse\nSkip anaconda upload step\n\n\nmambabuild\nstore_true\nFalse\nUse mambabuild (requires boa)\n\n\nupload_user\nstr\nNone\nOptional user to upload package to\n\n\nrepository\nstr\npypi\nPypi respository to upload to (defined in ~/.pypirc)",
    "crumbs": [
      "Get Started",
      "API",
      "release"
    ]
  },
  {
    "objectID": "api/release.html#bump-version",
    "href": "api/release.html#bump-version",
    "title": "release",
    "section": "Bump Version",
    "text": "Bump Version\n\nsource\n\nbump_version\n\n bump_version (version, part=2, unbump=False)\n\n\nsource\n\n\nnbdev_bump_version\n\n nbdev_bump_version (part:int=2, unbump:bool=False)\n\nIncrement version in settings.ini by one\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npart\nint\n2\nPart of version to bump\n\n\nunbump\nbool\nFalse\nReduce version instead of increasing it",
    "crumbs": [
      "Get Started",
      "API",
      "release"
    ]
  },
  {
    "objectID": "api/quarto.html",
    "href": "api/quarto.html",
    "title": "quarto",
    "section": "",
    "text": "Helpful background on how Quarto fits in here: https://nbdev.fast.ai/explanations/docs.html",
    "crumbs": [
      "Get Started",
      "API",
      "quarto"
    ]
  },
  {
    "objectID": "api/quarto.html#install",
    "href": "api/quarto.html#install",
    "title": "quarto",
    "section": "Install",
    "text": "Install\n\nsource\n\ninstall_quarto\n\n install_quarto ()\n\nInstall latest Quarto on macOS or Linux, prints instructions for Windows\n\nsource\n\n\ninstall\n\n install ()\n\nInstall Quarto and the current library",
    "crumbs": [
      "Get Started",
      "API",
      "quarto"
    ]
  },
  {
    "objectID": "api/quarto.html#sidebar",
    "href": "api/quarto.html#sidebar",
    "title": "quarto",
    "section": "Sidebar",
    "text": "Sidebar\n\nsource\n\nIndentDumper\n\n IndentDumper (stream, default_style=None, default_flow_style=False,\n               canonical=None, indent=None, width=None,\n               allow_unicode=None, line_break=None, encoding=None,\n               explicit_start=None, explicit_end=None, version=None,\n               tags=None, sort_keys=True)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nnbdev_sidebar\n\n nbdev_sidebar (path:str=None, printit:bool=False, force:bool=False,\n                skip_folder_re:str='(?:^[_.]|^www\\\\$)',\n                file_glob:str=None, file_re:str='\\\\.(?:ipynb|qmd|html)$',\n                symlinks:bool=False, folder_re:str=None,\n                skip_file_glob:str=None, skip_file_re:str='^[_.]')\n\nCreate sidebar.yml\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nprintit\nbool\nFalse\nPrint YAML for debugging\n\n\nforce\nbool\nFalse\nCreate sidebar even if settings.ini custom_sidebar=False\n\n\nskip_folder_re\nstr\n(?:^[_.]|^www$)\nSkip folders matching regex\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb|qmd|html)$\nOnly include files matching regex\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\n\n\n# nbdev_sidebar(printit=True, force=True)",
    "crumbs": [
      "Get Started",
      "API",
      "quarto"
    ]
  },
  {
    "objectID": "api/quarto.html#render-docs",
    "href": "api/quarto.html#render-docs",
    "title": "quarto",
    "section": "Render docs",
    "text": "Render docs\n\nsource\n\nrefresh_quarto_yml\n\n refresh_quarto_yml ()\n\nGenerate _quarto.yml from settings.ini.\n\nsource\n\n\nnbdev_proc_nbs\n\n nbdev_proc_nbs (path:str='', n_workers:int=4, force:bool=False,\n                 file_glob:str='', file_re:str='', symlinks:bool=False,\n                 folder_re:str=None, skip_file_glob:str=None,\n                 skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nProcess notebooks in path for docs rendering\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nPath to notebooks\n\n\nn_workers\nint\n4\nNumber of workers\n\n\nforce\nbool\nFalse\nIgnore cache and build all\n\n\nfile_glob\nstr\n\nOnly include files matching glob\n\n\nfile_re\nstr\n\nOnly include files matching glob\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\nsource\n\n\nnbdev_readme\n\n nbdev_readme (path:str=None, chk_time:bool=False)\n\nCreate README.md from readme_nb (index.ipynb by default)\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nchk_time\nbool\nFalse\nOnly build if out of date\n\n\n\nnbdev_readme calls “quarto render,” which is explained in the Quarto guide here.\n\nsource\n\n\nnbdev_docs\n\n nbdev_docs (path:str=None, n_workers:int=4, file_glob:str=None,\n             file_re:str='\\\\.(?:ipynb|qmd|html)$', symlinks:bool=False,\n             folder_re:str=None, skip_file_glob:str=None,\n             skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nCreate Quarto docs and README.md\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nn_workers\nint\n4\nNumber of workers\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb|qmd|html)$\nOnly include files matching regex\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\nsource\n\n\nprepare\n\n prepare ()\n\nExport, test, and clean notebooks, and render README if needed",
    "crumbs": [
      "Get Started",
      "API",
      "quarto"
    ]
  },
  {
    "objectID": "api/quarto.html#preview",
    "href": "api/quarto.html#preview",
    "title": "quarto",
    "section": "Preview",
    "text": "Preview\n\nsource\n\nfs_watchdog\n\n fs_watchdog (func, path, recursive:bool=True)\n\nFile system watchdog dispatching to func\n\nsource\n\n\nnbdev_preview\n\n nbdev_preview (path:str=None, port:int=None, host:str=None,\n                no_browser:bool=False, n_workers:int=4,\n                file_glob:str=None, file_re:str='\\\\.(?:ipynb|qmd|html)$',\n                symlinks:bool=False, folder_re:str=None,\n                skip_file_glob:str=None, skip_file_re:str='^[_.]',\n                skip_folder_re:str='^[_.]')\n\nPreview docs locally\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nPath to notebooks\n\n\nport\nint\nNone\nThe port on which to run preview\n\n\nhost\nstr\nNone\nThe host on which to run preview\n\n\nno_browser\nbool\nFalse\nDo not open a browser\n\n\nn_workers\nint\n4\nNumber of workers\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb|qmd|html)$\nOnly include files matching regex\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex",
    "crumbs": [
      "Get Started",
      "API",
      "quarto"
    ]
  },
  {
    "objectID": "api/merge.html",
    "href": "api/merge.html",
    "title": "merge",
    "section": "",
    "text": "When working with jupyter notebooks (which are json files behind the scenes) and GitHub, it is very common that a merge conflict (that will add new lines in the notebook source file) will break some notebooks you are working on. This module defines the function nbdev_fix to fix those notebooks for you, and attempt to automatically merge standard conflicts. The remaining ones will be delimited by markdown cells like this:\n&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n\n# local code here\n\n======\n\n# remote code here\n\n&gt;&gt;&gt;&gt;&gt;&gt; a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\nBelow is an example of broken notebook. The json format is broken by the lines automatically added by git. Such a file can’t be opened in jupyter notebook.\n\nbroken = Path('../../tests/example.ipynb.broken')\ntst_nb = broken.read_text(encoding='utf-8')\nprint(tst_nb)\n\n{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 6,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"3\"\n      ]\n     },\n     \"execution_count\": 6,\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n    \"z=3\\n\",\n=======\n    \"z=2\\n\",\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n    \"z\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 7,\n   \"execution_count\": 5,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"6\"\n      ]\n     },\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n     \"execution_count\": 7,\n=======\n     \"execution_count\": 5,\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n    \"x=3\\n\",\n    \"y=3\\n\",\n    \"x+y\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": []\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n\n\n\nNote that in this example, the second conflict is easily solved: it just concerns the execution count of the second cell and can be solved by choosing either option without really impacting your notebook. This is the kind of conflict we will fix automatically. The first conflict is more complicated as it spans across two cells and there is a cell present in one version, not the other. Such a conflict (and generally the ones where the inputs of the cells change form one version to the other) aren’t automatically fixed, but we will return a proper json file where the annotations introduced by git will be placed in markdown cells.",
    "crumbs": [
      "Get Started",
      "API",
      "merge"
    ]
  },
  {
    "objectID": "api/merge.html#introduction",
    "href": "api/merge.html#introduction",
    "title": "merge",
    "section": "",
    "text": "When working with jupyter notebooks (which are json files behind the scenes) and GitHub, it is very common that a merge conflict (that will add new lines in the notebook source file) will break some notebooks you are working on. This module defines the function nbdev_fix to fix those notebooks for you, and attempt to automatically merge standard conflicts. The remaining ones will be delimited by markdown cells like this:\n&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n\n# local code here\n\n======\n\n# remote code here\n\n&gt;&gt;&gt;&gt;&gt;&gt; a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\nBelow is an example of broken notebook. The json format is broken by the lines automatically added by git. Such a file can’t be opened in jupyter notebook.\n\nbroken = Path('../../tests/example.ipynb.broken')\ntst_nb = broken.read_text(encoding='utf-8')\nprint(tst_nb)\n\n{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 6,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"3\"\n      ]\n     },\n     \"execution_count\": 6,\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n    \"z=3\\n\",\n=======\n    \"z=2\\n\",\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n    \"z\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 7,\n   \"execution_count\": 5,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"6\"\n      ]\n     },\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n     \"execution_count\": 7,\n=======\n     \"execution_count\": 5,\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n    \"x=3\\n\",\n    \"y=3\\n\",\n    \"x+y\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": []\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n\n\n\nNote that in this example, the second conflict is easily solved: it just concerns the execution count of the second cell and can be solved by choosing either option without really impacting your notebook. This is the kind of conflict we will fix automatically. The first conflict is more complicated as it spans across two cells and there is a cell present in one version, not the other. Such a conflict (and generally the ones where the inputs of the cells change form one version to the other) aren’t automatically fixed, but we will return a proper json file where the annotations introduced by git will be placed in markdown cells.",
    "crumbs": [
      "Get Started",
      "API",
      "merge"
    ]
  },
  {
    "objectID": "api/merge.html#creating-a-merged-notebook",
    "href": "api/merge.html#creating-a-merged-notebook",
    "title": "merge",
    "section": "Creating a merged notebook",
    "text": "Creating a merged notebook\nThe approach we use is to first “unpatch” the conflicted file, regenerating the two files it was originally created from. Then we redo the diff process, but using cells instead of text lines.\n\nsource\n\nunpatch\n\n unpatch (s:str)\n\nTakes a string with conflict markers and returns the two original files, and their branch names\nThe result of “unpatching” our conflicted test notebook is the two original notebooks it would have been created from. Each of these original notebooks will contain valid JSON:\n\na,b,branch1,branch2 = unpatch(tst_nb)\ndict2nb(loads(a))\n\n{ 'cells': [ { 'cell_type': 'code',\n               'execution_count': 6,\n               'idx_': 0,\n               'metadata': {},\n               'outputs': [ { 'data': {'text/plain': ['3']},\n                              'execution_count': 6,\n                              'metadata': {},\n                              'output_type': 'execute_result'}],\n               'source': 'z=3\\nz'},\n             { 'cell_type': 'code',\n               'execution_count': 5,\n               'idx_': 1,\n               'metadata': {},\n               'outputs': [ { 'data': {'text/plain': ['6']},\n                              'execution_count': 7,\n                              'metadata': {},\n                              'output_type': 'execute_result'}],\n               'source': 'x=3\\ny=3\\nx+y'},\n             { 'cell_type': 'code',\n               'execution_count': None,\n               'idx_': 2,\n               'metadata': {},\n               'outputs': [],\n               'source': ''}],\n  'metadata': { 'kernelspec': { 'display_name': 'Python 3',\n                                'language': 'python',\n                                'name': 'python3'}},\n  'nbformat': 4,\n  'nbformat_minor': 2}\n\n\n\ndict2nb(loads(b))\n\n{ 'cells': [ { 'cell_type': 'code',\n               'execution_count': 6,\n               'idx_': 0,\n               'metadata': {},\n               'outputs': [ { 'data': {'text/plain': ['3']},\n                              'execution_count': 6,\n                              'metadata': {},\n                              'output_type': 'execute_result'}],\n               'source': 'z=2\\nz'},\n             { 'cell_type': 'code',\n               'execution_count': 5,\n               'idx_': 1,\n               'metadata': {},\n               'outputs': [ { 'data': {'text/plain': ['6']},\n                              'execution_count': 5,\n                              'metadata': {},\n                              'output_type': 'execute_result'}],\n               'source': 'x=3\\ny=3\\nx+y'},\n             { 'cell_type': 'code',\n               'execution_count': None,\n               'idx_': 2,\n               'metadata': {},\n               'outputs': [],\n               'source': ''}],\n  'metadata': { 'kernelspec': { 'display_name': 'Python 3',\n                                'language': 'python',\n                                'name': 'python3'}},\n  'nbformat': 4,\n  'nbformat_minor': 2}\n\n\n\nbranch1,branch2\n\n('HEAD', 'a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35')\n\n\n\nsource\n\n\nnbdev_fix\n\n nbdev_fix (nbname:str, outname:str=None, nobackup:&lt;function\n            bool_arg&gt;=True, theirs:bool=False, noprint:bool=False)\n\nCreate working notebook from conflicted notebook nbname\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnbname\nstr\n\nNotebook filename to fix\n\n\noutname\nstr\nNone\nFilename of output notebook (defaults to nbname)\n\n\nnobackup\nbool_arg\nTrue\nDo not backup nbname to nbname.bak if outname not provided\n\n\ntheirs\nbool\nFalse\nUse their outputs and metadata instead of ours\n\n\nnoprint\nbool\nFalse\nDo not print info about whether conflicts are found\n\n\n\nThis begins by optionally backing the notebook fname to fname.bak in case something goes wrong. Then it parses the broken json, solving conflicts in cells. Every conflict that only involves metadata or outputs of cells will be solved automatically by using the local (theirs==False) or the remote (theirs==True) branch. Otherwise, or for conflicts involving the inputs of cells, the json will be repaired by including the two version of the conflicted cell(s) with markdown cells indicating the conflicts. You will be able to open the notebook again and search for the conflicts (look for &lt;&lt;&lt;&lt;&lt;&lt;&lt;) then fix them as you wish.\nA message will be printed indicating whether the notebook was fully merged or if conflicts remain.\n\nnbdev_fix(broken, outname='tmp.ipynb')\nchk = read_nb('tmp.ipynb')\ntest_eq(len(chk.cells), 7)\nos.unlink('tmp.ipynb')\n\nOne or more conflict remains in the notebook, please inspect manually.",
    "crumbs": [
      "Get Started",
      "API",
      "merge"
    ]
  },
  {
    "objectID": "api/merge.html#git-merge-driver",
    "href": "api/merge.html#git-merge-driver",
    "title": "merge",
    "section": "Git merge driver",
    "text": "Git merge driver\n\nsource\n\nnbdev_merge\n\n nbdev_merge (base:str, ours:str, theirs:str, path:str)\n\nGit merge driver for notebooks\nThis implements a git merge driver for notebooks that automatically resolves conflicting metadata and outputs, and splits remaining conflicts as separate cells so that the notebook can be viewed and fixed in Jupyter. The easiest way to install it is by running nbdev_install_hooks.\nThis works by first running Git’s default merge driver, and then nbdev_fix if there are still conflicts. You can set nbdev_fix’s theirs argument using the THEIRS environment variable, for example:\nTHEIRS=True git merge branch",
    "crumbs": [
      "Get Started",
      "API",
      "merge"
    ]
  },
  {
    "objectID": "api/maker.html#variable-helpers",
    "href": "api/maker.html#variable-helpers",
    "title": "maker",
    "section": "Variable helpers",
    "text": "Variable helpers\nThese functions let us find and modify the definitions of variables in Python modules.\n\nsource\n\nfind_var\n\n find_var (lines, varname)\n\nFind the line numbers where varname is defined in lines\n\nt = '''a_=(1,\n  2,\n  3)\n\nb_=3'''\ntest_eq(find_var(t.splitlines(), 'a_'), (0,3))\ntest_eq(find_var(t.splitlines(), 'b_'), (4,5))\n\n\nsource\n\n\nread_var\n\n read_var (code, varname)\n\nEval and return the value of varname defined in code\n\ntest_eq(read_var(t, 'a_'), (1,2,3))\ntest_eq(read_var(t, 'b_'), 3)\n\n\nsource\n\n\nupdate_var\n\n update_var (varname, func, fn=None, code=None)\n\nUpdate the definition of varname in file fn, by calling func with the current definition\n\ng = exec_new(t)\ntest_eq((g['a_'],g['b_']), ((1,2,3),3))\nt2 = update_var('a_', lambda o:0, code=t)\nexec(t2, g)\ntest_eq((g['a_'],g['b_']), (0,3))\nt3 = update_var('b_', lambda o:0, code=t)\nexec(t3, g)\ntest_eq((g['a_'],g['b_']), ((1,2,3),0))\n\n\nsource\n\n\nModuleMaker\n\n ModuleMaker (dest, name, nb_path, is_new=True, parse=True)\n\nHelper class to create exported library from notebook source cells\nIn order to export a notebook, we need an way to create a Python file. ModuleMaker fills that role. Pass in the directory where you want to module created, the name of the module, the path of the notebook source, and set is_new to True if this is a new file being created (rather than an existing file being added to). The location of the saved module will be in fname. Finally, if the source in the notebooks should not be parsed by Python (such as partial class declarations in cells), parse should be set to False.\n\nNote: If doing so, then the __all__ generation will be turned off as well.\n\n\nmm = ModuleMaker(dest='tmp', name='test.testing', nb_path=Path.cwd()/'04_export.ipynb', is_new=True)\nmm.fname\n\nPath('tmp/test/testing.py')\n\n\n\nsource\n\n\ndecor_id\n\n decor_id (d)\n\nid attr of decorator, regardless of whether called as function or bare\n\nsource\n\n\nModuleMaker.make_all\n\n ModuleMaker.make_all (cells)\n\nCreate __all__ with all exports in cells\n\nsource\n\n\nmake_code_cells\n\n make_code_cells (*ss)\n\nWe want to add an __all__ to the top of the exported module. This methods autogenerates it from all code in cells.\n\nnb = make_code_cells(\"from __future__ import print_function\", \"def a():...\", \"def b():...\",\n                      \"c=d=1\", \"_f=1\", \"_g=1\", \"_h=1\", \"_all_=['_g', _h]\", \"@patch\\ndef h(self:ca):...\")\ntest_eq(set(mm.make_all(nb)), set(['a','b','c','d', '_g', '_h']))\n\n\nsource\n\n\nrelative_import\n\n relative_import (name, fname, level=0)\n\nConvert a module name to a name relative to fname\n\ntest_eq(relative_import('nbdev.core', \"xyz\"), 'nbdev.core')\ntest_eq(relative_import('nbdev.core', 'nbdev'), '.core')\n_p = Path('fastai')\ntest_eq(relative_import('fastai.core', _p/'vision'), '..core')\ntest_eq(relative_import('fastai.core', _p/'vision/transform'), '...core')\ntest_eq(relative_import('fastai.vision.transform', _p/'vision'), '.transform')\ntest_eq(relative_import('fastai.notebook.core', _p/'data'), '..notebook.core')\ntest_eq(relative_import('fastai.vision', _p/'vision'), '.')\ntest_eq(relative_import('fastai', _p), '.')\ntest_eq(relative_import('fastai', _p/'vision'), '..')\ntest_eq(relative_import('fastai', _p/'vision/transform'), '...')\n\n\nsource\n\n\nNbCell.import2relative\n\n NbCell.import2relative (cell:execnb.nbio.NbCell, libname)\n\n\nsource\n\n\nupdate_import\n\n update_import (source, tree, libname, f=&lt;function relative_import&gt;)\n\n\nss = \"from nbdev.export import *\\nfrom nbdev.a.b import *\"\ncell = make_code_cells([ss])[0]\ncell.import2relative('nbdev')\ntest_eq(cell.source, 'from .export import *\\nfrom .a.b import *')\n\ncell = make_code_cells([ss])[0]\ncell.import2relative('nbdev/a')\ntest_eq(cell.source, 'from ..export import *\\nfrom .b import *')\n\n\nsource\n\n\nModuleMaker.make\n\n ModuleMaker.make (cells, all_cells=None, lib_path=None)\n\nWrite module containing cells with __all__ generated from all_cells\n\ncells = make_code_cells(\"from __future__ import print_function\",\n                        \"#|export\\ndef a(): ...\", \"def b(): ...\")\nmm.make(cells, L([cells[2]]))\nshow_src(Path('tmp/test/testing.py').read_text(encoding='utf-8'))\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../../04_export.ipynb.\n\n# %% ../../04_export.ipynb 0\nfrom __future__ import print_function\n\n# %% auto 0\n__all__ = ['b']\n\n# %% ../../04_export.ipynb\n#|export\ndef a(): ...\n\n# %% ../../04_export.ipynb\ndef b(): ...\n\n\nPass all_cells=[] or parse=False if you don’t want any __all__ added.\nPassing parse=False is also handy for when writing broken up functions or classes that ast.parse might not like but still want it to be exported, such as having a cell with:\n#|export\nclass A:\nNote that by doing so we cannot properly generate a __all__, so we assume that it is unwanted.\n\nam = ModuleMaker(dest='tmp', name='test.testing_noall', nb_path=Path.cwd()/'01_export.ipynb', is_new=True, parse=False)\nam.fname\n\nPath('tmp/test/testing_noall.py')\n\n\n\ncells = make_code_cells(\"from __future__ import print_function\", \"#|export\\ndef a(): ...\", \"#|export\\nclass A:\")\nam.make(cells)\nshow_src(Path('tmp/test/testing_noall.py').read_text(encoding='utf-8'))\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../../01_export.ipynb.\n\n# %% ../../01_export.ipynb\nfrom __future__ import print_function\n\n# %% ../../01_export.ipynb\n#|export\ndef a(): ...\n\n# %% ../../01_export.ipynb\n#|export\nclass A:\n\n\nIf is_new=False then the additional definitions are added to the bottom, and any existing __all__ is updated with the newly-added symbols.\n\nc2 = make_code_cells(\"def c(): ...\", \"def d(): ...\")\nmm = ModuleMaker(dest='tmp', name='test.testing', nb_path=Path.cwd()/'04_export.ipynb', is_new=False)\nmm.make(c2, c2)\n\n\nshow_src(Path('tmp/test/testing.py').read_text(encoding='utf-8'))\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../../04_export.ipynb.\n\n# %% ../../04_export.ipynb 0\nfrom __future__ import print_function\n\n# %% auto 0\n__all__ = ['b', 'c', 'd']\n\n# %% ../../04_export.ipynb\n#|export\ndef a(): ...\n\n# %% ../../04_export.ipynb\ndef b(): ...\n\n# %% ../../04_export.ipynb 0\ndef c(): ...\n\n# %% ../../04_export.ipynb 1\ndef d(): ...\n\n\n\ntry:\n    g = exec_import('tmp.test.testing', '*')\n    for s in \"b c d\".split(): assert s in g, s\n    assert 'a' not in g\n    assert g['b']() is None\nfinally: shutil.rmtree('tmp')",
    "crumbs": [
      "Get Started",
      "API",
      "maker"
    ]
  },
  {
    "objectID": "api/showdoc.html",
    "href": "api/showdoc.html",
    "title": "showdoc",
    "section": "",
    "text": "Render nicely formatted tables that shows docments for any function or method.\n\nsource\n\n\n\n DocmentTbl (obj, verbose=True, returns=True)\n\nCompute the docment table string\nDocmentTbl can render a markdown table showing docments if appropriate. This is an example of how a docments table will render for a function:\n\ndef _f(a,      # description of param a\n       b=True, # description of param b\n       c:str=None\n       ) -&gt; int: ...\n\n_dm = DocmentTbl(_f)\n_dm\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\nReturns\nint\n\n\n\n\n\n\n\nIf one column in the table has no information, for example because there are no default values, that column will not be shown. In the below example, the Default column, will not be shown. Additionally, if the return of the function is not annotated the Returns row will not be rendered:\n\ndef _f(a,\n        b, #param b\n        c  #param c\n       ): ...\n\n_dm2 = DocmentTbl(_f)\n_dm2\n\n\n\n\n\nDetails\n\n\n\n\na\n\n\n\nb\nparam b\n\n\nc\nparam c\n\n\n\n\n\nDocmentTbl also works on classes. By default, the __init__ will be rendered:\n\nclass _Test:\n    def __init__(self,\n                 a,      # description of param a\n                 b=True, # description of param b\n                 c:str=None):\n        ...\n\n    def foo(self,\n            c:int,      # description of param c\n            d=True, # description of param d\n           ):\n        ...\n\n\nDocmentTbl(_Test)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\n\n\n\nYou can also pass a method to be rendered as well:\n\nDocmentTbl(_Test.foo)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nc\nint\n\ndescription of param c\n\n\nd\nbool\nTrue\ndescription of param d",
    "crumbs": [
      "Get Started",
      "API",
      "showdoc"
    ]
  },
  {
    "objectID": "api/showdoc.html#rendering-docment-tables",
    "href": "api/showdoc.html#rendering-docment-tables",
    "title": "showdoc",
    "section": "",
    "text": "Render nicely formatted tables that shows docments for any function or method.\n\nsource\n\n\n\n DocmentTbl (obj, verbose=True, returns=True)\n\nCompute the docment table string\nDocmentTbl can render a markdown table showing docments if appropriate. This is an example of how a docments table will render for a function:\n\ndef _f(a,      # description of param a\n       b=True, # description of param b\n       c:str=None\n       ) -&gt; int: ...\n\n_dm = DocmentTbl(_f)\n_dm\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\nReturns\nint\n\n\n\n\n\n\n\nIf one column in the table has no information, for example because there are no default values, that column will not be shown. In the below example, the Default column, will not be shown. Additionally, if the return of the function is not annotated the Returns row will not be rendered:\n\ndef _f(a,\n        b, #param b\n        c  #param c\n       ): ...\n\n_dm2 = DocmentTbl(_f)\n_dm2\n\n\n\n\n\nDetails\n\n\n\n\na\n\n\n\nb\nparam b\n\n\nc\nparam c\n\n\n\n\n\nDocmentTbl also works on classes. By default, the __init__ will be rendered:\n\nclass _Test:\n    def __init__(self,\n                 a,      # description of param a\n                 b=True, # description of param b\n                 c:str=None):\n        ...\n\n    def foo(self,\n            c:int,      # description of param c\n            d=True, # description of param d\n           ):\n        ...\n\n\nDocmentTbl(_Test)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\n\n\n\nYou can also pass a method to be rendered as well:\n\nDocmentTbl(_Test.foo)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nc\nint\n\ndescription of param c\n\n\nd\nbool\nTrue\ndescription of param d",
    "crumbs": [
      "Get Started",
      "API",
      "showdoc"
    ]
  },
  {
    "objectID": "api/showdoc.html#documentation-for-an-object",
    "href": "api/showdoc.html#documentation-for-an-object",
    "title": "showdoc",
    "section": "Documentation For An Object",
    "text": "Documentation For An Object\nRender the signature as well as the docments to show complete documentation for an object.\n\nsource\n\nShowDocRenderer\n\n ShowDocRenderer (sym, name:str|None=None, title_level:int=3)\n\nShow documentation for sym\n\nsource\n\n\nBasicMarkdownRenderer\n\n BasicMarkdownRenderer (sym, name:str|None=None, title_level:int=3)\n\nMarkdown renderer for show_doc\n\nsource\n\n\nshow_doc\n\n show_doc (sym, renderer=None, name:str|None=None, title_level:int=3)\n\nShow signature and docstring for sym\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsym\n\n\nSymbol to document\n\n\nrenderer\nNoneType\nNone\nOptional renderer (defaults to markdown)\n\n\nname\nstr | None\nNone\nOptionally override displayed name of sym\n\n\ntitle_level\nint\n3\nHeading level to use for symbol name\n\n\n\nYou can use show_doc to document apis of functions, classes or methods.\n\n\nNumpy Docstrings\nif you have numpy docstrings instead of docments, show_doc will attempt to parse and render those just like docments.\n\n\n\n\n\n\nWarning\n\n\n\nNumpy docstring formatting is very strict. If your docstrings do not strictly adhere to the numpy format, it will not be parsed properly and information about parameters and return values may not properly be rendered in the table below the signature. Where possible, we recommend using docments to annonate your function instead.",
    "crumbs": [
      "Get Started",
      "API",
      "showdoc"
    ]
  },
  {
    "objectID": "api/showdoc.html#show_doc-on-classes",
    "href": "api/showdoc.html#show_doc-on-classes",
    "title": "showdoc",
    "section": "show_doc on Classes",
    "text": "show_doc on Classes\nshow_doc works on Classes, too, including when you use @patch.\nYou can define methods for the class Foo with @patch which is convenient in allowing you to break up code for documentation in notebooks.\nClass properties also work with showdoc.",
    "crumbs": [
      "Get Started",
      "API",
      "showdoc"
    ]
  },
  {
    "objectID": "api/showdoc.html#pluggable-renderers",
    "href": "api/showdoc.html#pluggable-renderers",
    "title": "showdoc",
    "section": "Pluggable renderers",
    "text": "Pluggable renderers\nYou can replace the default markdown show_doc renderer with custom renderers. For instance, nbdev comes with a simple example for rendering with raw HTML.\n\nsource\n\nBasicHtmlRenderer\n\n BasicHtmlRenderer (sym, name:str|None=None, title_level:int=3)\n\nHTML renderer for show_doc\n\nsource\n\n\ndoc\n\n doc (elt)\n\nShow show_doc info along with link to docs\n\nsource\n\n\nshowdoc_nm\n\n showdoc_nm (tree)\n\nGet the fully qualified name for showdoc.",
    "crumbs": [
      "Get Started",
      "API",
      "showdoc"
    ]
  },
  {
    "objectID": "api/showdoc.html#other-helpers",
    "href": "api/showdoc.html#other-helpers",
    "title": "showdoc",
    "section": "Other helpers",
    "text": "Other helpers\n\nsource\n\ncolab_link\n\n colab_link (path)\n\nGet a link to the notebook at path on Colab\n\ncolab_link('index')\n\nOpen index in Colab",
    "crumbs": [
      "Get Started",
      "API",
      "showdoc"
    ]
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API",
    "section": "",
    "text": "This section contains API details for each of nbdev’s python submodules. This reference documentation is mainly useful for people looking to customise or build on top of nbdev, or wanting detailed information about how nbdev works.\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nconfig\n\n\nConfiguring nbdev and bootstrapping notebook export\n\n\n\n\nmaker\n\n\nCreate one or more modules from selected notebook cells\n\n\n\n\nprocess\n\n\nA notebook processor\n\n\n\n\nexport\n\n\nExporting a notebook to a library\n\n\n\n\ndoclinks\n\n\nGenerating a documentation index from a module\n\n\n\n\nsync\n\n\nPropagate small changes in the library back to notebooks\n\n\n\n\nmerge\n\n\nFix merge conflicts in jupyter notebooks\n\n\n\n\nshowdoc\n\n\nDisplay symbol documentation in notebook and website\n\n\n\n\nfrontmatter\n\n\nA YAML and formatted-markdown frontmatter processor\n\n\n\n\nprocessors\n\n\nSome processors for NBProcessor\n\n\n\n\nclean\n\n\nStrip superfluous metadata from notebooks\n\n\n\n\ntest\n\n\nRun unit tests on notebooks in parallel\n\n\n\n\ncli\n\n\nCLI commands\n\n\n\n\nquarto\n\n\nInstall and interact with Quarto from nbdev\n\n\n\n\nqmd\n\n\nBasic qmd generation helpers (experimental)\n\n\n\n\nmigrate\n\n\nUtilities for migrating to nbdev\n\n\n\n\nserve\n\n\nA parallel ipynb processor (experimental)\n\n\n\n\nrelease\n\n\nAuto-generated tagged releases and release notes from GitHub issues\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Get Started",
      "API"
    ]
  },
  {
    "objectID": "api/test.html",
    "href": "api/test.html",
    "title": "test",
    "section": "",
    "text": "source\n\ntest_nb\n\n test_nb (fn, skip_flags=None, force_flags=None, do_print=False,\n          showerr=True, basepath=None)\n\nExecute tests in notebook in fn except those with skip_flags\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfn\n\n\nfile name of notebook to test\n\n\nskip_flags\nNoneType\nNone\nlist of flags marking cells to skip\n\n\nforce_flags\nNoneType\nNone\nlist of flags marking cells to always run\n\n\ndo_print\nbool\nFalse\nprint completion?\n\n\nshowerr\nbool\nTrue\nprint errors to stderr?\n\n\nbasepath\nNoneType\nNone\npath to add to sys.path\n\n\n\ntest_nb can test a notebook, and skip over certain flags:\n\n_nb = Path('../../tests/directives.ipynb')\nsuccess,duration = test_nb(_nb, skip_flags=['notest'])\nassert success\n\nIn that notebook the cell flagged notest raises an exception, which will be returned as a bool:\n\n_nb = Path('../../tests/directives.ipynb')\nsuccess,duration = test_nb(_nb, showerr=False)\nassert not success\n\nSometimes you may wish to override one or more of the skip_flags, in which case you can use the argument force_flags which will remove the appropriate tag(s) from skip_flags. This is useful because skip_flags are meant to be set in the tst_flags field of settings.ini, whereas force_flags are usually passed in by the user.\n\nsource\n\n\nnbdev_test\n\n nbdev_test (path:str=None, flags:str='', n_workers:int=None,\n             timing:bool=False, do_print:bool=False, pause:float=0.01,\n             ignore_fname:str='.notest', symlinks:bool=False,\n             file_glob:str='*.ipynb', file_re:str=None,\n             folder_re:str=None, skip_file_glob:str=None,\n             skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]')\n\nTest in parallel notebooks matching path, passing along flags\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\nA notebook name or glob to test\n\n\nflags\nstr\n\nSpace separated list of test flags to run that are normally ignored\n\n\nn_workers\nint\nNone\nNumber of workers\n\n\ntiming\nbool\nFalse\nTime each notebook to see which are slow\n\n\ndo_print\nbool\nFalse\nPrint start and end of each notebook\n\n\npause\nfloat\n0.01\nPause time (in seconds) between notebooks to avoid race conditions\n\n\nignore_fname\nstr\n.notest\nFilename that will result in siblings being ignored\n\n\nsymlinks\nbool\nFalse\nFollow symlinks?\n\n\nfile_glob\nstr\n*.ipynb\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\n^[_.]\nSkip files matching regex\n\n\nskip_folder_re\nstr\n^[_.]\nSkip folders matching regex\n\n\n\n\nnbdev_test(n_workers=0)\n\nSuccess.\n\n\nYou can even run nbdev_test in non nbdev projects, for example, you can test an individual notebook like so:\nnbdev_test --path ../../tests/minimal.ipynb --do_print\nOr you can test an entire directory of notebooks filtered for only those that match a regular expression:\nnbdev_test --path ../../tests --file_re '.*test.ipynb' --do_print",
    "crumbs": [
      "Get Started",
      "API",
      "test"
    ]
  },
  {
    "objectID": "api/process.html",
    "href": "api/process.html",
    "title": "process",
    "section": "",
    "text": "Special comments at the start of a cell can be used to provide information to nbdev about how to process a cell, so we need to be able to find the location of these comments.\n\nminimal = read_nb('../../tests/minimal.ipynb')\n\n\nsource\n\nnb_lang\n\n nb_lang (nb)\n\n\nsource\n\n\nfirst_code_ln\n\n first_code_ln (code_list, re_pattern=None, lang='python')\n\nget first line number where code occurs, where code_list is a list of code\n\n_tst = \"\"\" \n#|default_exp\n #|export\n#|hide_input\nfoo\n\"\"\"\ntest_eq(first_code_ln(_tst.splitlines(True)), 4)\n\n\nsource\n\n\nextract_directives\n\n extract_directives (cell, remove=True, lang='python')\n\nTake leading comment directives from lines of code in ss, remove #|, and split\nComment directives start with #|, followed by whitespace delimited tokens, which extract_directives extracts from the start of a cell, up until a blank line or a line containing something other than comments. The extracted lines are removed from the source.\n\nexp  = AttrDict(source = \"\"\"#|export module\n#|eval:false\n#| hide\n# | foo bar\n# |woo: baz\n1+2\n#bar\"\"\")\n\n# this one has #|hide: with a colon at the end, wich is quarto compliant\nexp2  = AttrDict(source = \"\"\"#|export module\n#|eval:false\n#| hide:\n# | foo bar\n# |woo: baz\n1+2\n#bar\"\"\")\n\n_answer = {'export':['module'], 'hide':[], 'eval:': ['false'], 'foo': ['bar'], 'woo:': ['baz']}\n\ntest_eq(extract_directives(exp), _answer)\ntest_eq(extract_directives(exp2), _answer)\ntest_eq(exp.source, '#|eval: false\\n# |woo: baz\\n1+2\\n#bar')\n\n\nsource\n\n\nopt_set\n\n opt_set (var, newval)\n\nnewval if newval else var\n\nsource\n\n\ninstantiate\n\n instantiate (x, **kwargs)\n\nInstantiate x if it’s a type\n\nsource\n\n\nNBProcessor\n\n NBProcessor (path=None, procs=None, nb=None, debug=False,\n              rm_directives=True, process=False)\n\nProcess cells and nbdev comments in a notebook\nCell processors can be callables (e.g regular functions), in which case they are called for every cell (set a cell’s source to None to remove the cell):\n\neverything_fn = '../../tests/01_everything.ipynb'\n\ndef print_execs(cell):\n    if 'exec' in cell.source: print(cell.source)\n\nNBProcessor(everything_fn, print_execs).process()\n\n---\ntitle: Foo\nexecute:\n  echo: false\n---\nexec(\"o_y=1\")\nexec(\"p_y=1\")\n_all_ = [o_y, 'p_y']\n\n\nComment directives are put in a cell attribute directive_ as a dictionary keyed by directive name:\n\ndef printme_func(cell):\n    if cell.directives_ and 'printme' in cell.directives_: print(cell.directives_['printme'])\n\nNBProcessor(everything_fn, printme_func).process()\n\n['testing']\n\n\nHowever, a more convenient way to handle comment directives is to use a class as a processor, and include a method in your class with the same name as your directive, surrounded by underscores:\n\nclass _PrintExample:\n    def _printme_(self, cell, to_print): print(to_print)\n\nNBProcessor(everything_fn, _PrintExample()).process()\n\ntesting\n\n\nIn the case that your processor supports just one comment directive, you can just use a regular function, with the same name as your directive, but with an underscore appended – here printme_ is identical to _PrintExample above:\n\ndef printme_(cell, to_print): print(to_print)\n\nNBProcessor(everything_fn, printme_).process()\n\ntesting\n\n\n\nNBProcessor(everything_fn, _PrintExample()).process()\n\ntesting\n\n\n\nsource\n\n\nProcessor\n\n Processor (nb)\n\nBase class for processors\nFor more complex behavior, inherit from Processor, and override one of more of begin() (called before any cells are processed), cell() (called for each cell), and end() (called after all cells are processed). You can also include comment directives (such as the _printme example above) in these subclasses. Subclasses will automatically have access to self.nb, containing the processed notebook.\n\nclass CountCellProcessor(Processor):\n    def begin(self):\n        print(f\"First cell:\\n{self.nb.cells[0].source}\")\n        self.count=0\n    def cell(self, cell):\n        if cell.cell_type=='code': self.count += 1\n    def end(self): print(f\"* There were {self.count} code cells\")\n\n\nNBProcessor(everything_fn, CountCellProcessor).process()\n\nFirst cell:\n---\ntitle: Foo\nexecute:\n  echo: false\n---\n* There were 26 code cells",
    "crumbs": [
      "Get Started",
      "API",
      "process"
    ]
  },
  {
    "objectID": "explanations/why_nbdev.html",
    "href": "explanations/why_nbdev.html",
    "title": "Why nbdev",
    "section": "",
    "text": "Popular Python documentation standards such as numpy docstrings and sphinx facilitate documentation of source code with docstrings, which are limited in their expressiveness and functionality. Notebooks, on the other hand, offer a richer medium for authoring documentation (with markdown and code cells) compared to docstrings, and unlock new ways of documenting your code that are otherwhise infeasible.\nFurthermore, traditional testing frameworks such as pytest and unittest encourage writing tests in a separate context that is disjointed from the associated source code and documentation. With nbdev, you write tests in the same context as your source code and documentation, such that tests can optionally become part of the narrative within your documentation.\nSince nbdev allows your colleagues and users to view the tests, code and documentation in a single context with a REPL that invites experimentation, the way you author code, documentation and tests in nbdev are very different than traditional software development workflows.\nIn Notebook Best Practices we compare a function coded, tested, and documented in nbdev versus ordinary .py files. Here are a few of the challenges we faced with other approaches that led us to using nbdev. In .py files:\n\nDocstrings repeat information that is already contained in the function signature, such as names of parameters, default values, and types\nExamples are manually entered. This requires the author to copy and paste both the code and outputs. Furthermore, the author must manually re-enter or change these examples anytime the code changes, which is an error-prone process\nExamples are limited to short code snippets and cannot contain rich output like plots or graphics\nExamples cannot have prose interleaved with code except for code comments\nReaders of your code must copy and paste contents of the docstring if they wish to reproduce the examples.",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Why nbdev"
    ]
  },
  {
    "objectID": "explanations/config.html",
    "href": "explanations/config.html",
    "title": "Settings.ini",
    "section": "",
    "text": "All of nbdev’s configuration is done through a file called settings.ini which lives in the root of your repo. It’s in ConfigParser format. For example, here’s the first few lines of nbdev’s settings.ini file\n\n\n[DEFAULT]\nlib_name = nbdev\nrepo = nbdev\ndescription = Create delightful software with Jupyter Notebooks\ncopyright = 2020 onwards, Jeremy Howard\nkeywords = nbdev fastai jupyter notebook export\nuser = fastai\nauthor = Jeremy Howard and Hamel Husain\nauthor_email = j@fast.ai\nbranch = master\n\n\nYou can create this file with nbdev_create_config (in which case you pass the settings manually), or with nbdev_new (which sets it up automatically for you from your repo settings). Here are all of nbdev’s settings (excluding the path and cfg_name parameters which decide where the config file is saved):\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepo\nstr\nNone\nRepo name\n\n\nbranch\nstr\nNone\nRepo default branch\n\n\nuser\nstr\nNone\nRepo username\n\n\nauthor\nstr\nNone\nPackage author’s name\n\n\nauthor_email\nstr\nNone\nPackage author’s email address\n\n\ndescription\nstr\nNone\nShort summary of the package\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nlib_name\nstr\n%(repo)s\nPackage name\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(repo)s\nRepo URL\n\n\ncustom_sidebar\nbool_arg\nFalse\nUse a custom sidebar.yml?\n\n\nnbs_path\nPath\nnbs\nPath to notebooks\n\n\nlib_path\nPath\nNone\nPath to package root (default: repo with - replaced by _)\n\n\ndoc_path\nPath\n_docs\nPath to rendered docs\n\n\ntst_flags\nstr\nnotest\nTest flags\n\n\nversion\nstr\n0.0.1\nVersion of this release\n\n\ndoc_host\nstr\nhttps://%(user)s.github.io\nHostname for docs\n\n\ndoc_baseurl\nstr\n/%(repo)s\nBase URL for docs\n\n\nkeywords\nstr\nnbdev jupyter notebook python\nPackage keywords\n\n\nlicense\nstr\napache2\nLicense for the package\n\n\ncopyright\nstr\nNone\nCopyright for the package, defaults to ‘current_year onwards, author’\n\n\nstatus\nstr\n3\nDevelopment status PyPI classifier\n\n\nmin_python\nstr\n3.7\nMinimum Python version PyPI classifier\n\n\naudience\nstr\nDevelopers\nIntended audience PyPI classifier\n\n\nlanguage\nstr\nEnglish\nLanguage PyPI classifier\n\n\nrecursive\nbool_arg\nTrue\nInclude subfolders in notebook globs?\n\n\nblack_formatting\nbool_arg\nFalse\nFormat libraries with black?\n\n\nreadme_nb\nstr\nindex.ipynb\nNotebook to export as repo readme\n\n\ntitle\nstr\n%(lib_name)s\nQuarto website title\n\n\nallowed_metadata_keys\nstr\n\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nstr\n\nPreserve the list of keys in cell level metadata\n\n\njupyter_hooks\nbool_arg\nFalse\nRun Jupyter hooks?\n\n\nclean_ids\nbool_arg\nTrue\nRemove ids from plaintext reprs?\n\n\nclear_all\nbool_arg\nFalse\nRemove all cell metadata and cell outputs?\n\n\ncell_number\nbool_arg\nTrue\nAdd cell number to the exported file\n\n\nput_version_in_init\nbool_arg\nTrue\nAdd the version to the main init.py in nbdev_export\n\n\nskip_procs\nstr\n\nA comma-separated list of processors that you want to skip\n\n\n\n\n\nYou can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file.\nIn order for Git actions to run smoothly, add requirements and dev_requirements with required packages in settings.ini.\nsee here as a reference.",
    "crumbs": [
      "Get Started",
      "Explanations",
      "Settings.ini"
    ]
  }
]